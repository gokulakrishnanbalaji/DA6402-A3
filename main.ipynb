{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11817904,"sourceType":"datasetVersion","datasetId":7422957}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Added dataset manually, if you want to download it, you can access it from here https://github.com/google-research-datasets/dakshina. Here I have used Tamil language.","metadata":{}},{"cell_type":"markdown","source":"# Question 1","metadata":{}},{"cell_type":"code","source":"# Importing libraries\n\nimport torch\nimport torch.nn as nn","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T05:36:01.193106Z","iopub.execute_input":"2025-05-15T05:36:01.193514Z","iopub.status.idle":"2025-05-15T05:36:08.505851Z","shell.execute_reply.started":"2025-05-15T05:36:01.193479Z","shell.execute_reply":"2025-05-15T05:36:08.504876Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# Encoder RNN\n\nclass EncoderRNN(nn.Module):\n    def __init__(self, input_size, embed_size, hidden_size, cell_type='RNN', num_layers=1, dropout=0.0):\n        super(EncoderRNN, self).__init__()\n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n        self.embedding = nn.Embedding(input_size, embed_size)\n        self.cell_type = cell_type.upper()\n        \n        # Select RNN cell type\n        rnn_class = {'RNN': nn.RNN, 'LSTM': nn.LSTM, 'GRU': nn.GRU}[self.cell_type]\n        self.rnn = rnn_class(\n            input_size=embed_size,\n            hidden_size=hidden_size,\n            num_layers=num_layers,\n            batch_first=True,\n            dropout=dropout if num_layers > 1 else 0.0\n        )\n\n    def forward(self, input_seq):\n        embedded = self.embedding(input_seq)  # [batch_size, seq_len, embed_size]\n        if self.cell_type == 'LSTM':\n            outputs, (hidden, cell) = self.rnn(embedded)\n            return outputs, (hidden, cell)\n        else:\n            outputs, hidden = self.rnn(embedded)\n            return outputs, hidden","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T05:36:34.939477Z","iopub.execute_input":"2025-05-15T05:36:34.939834Z","iopub.status.idle":"2025-05-15T05:36:34.947186Z","shell.execute_reply.started":"2025-05-15T05:36:34.939811Z","shell.execute_reply":"2025-05-15T05:36:34.946219Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Decoder RNN\n\nclass DecoderRNN(nn.Module):\n    def __init__(self, output_size, embed_size, hidden_size, cell_type='RNN', num_layers=1, dropout=0.0):\n        super(DecoderRNN, self).__init__()\n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n        self.embedding = nn.Embedding(output_size, embed_size)\n        self.cell_type = cell_type.upper()\n        \n        # Select RNN cell type\n        rnn_class = {'RNN': nn.RNN, 'LSTM': nn.LSTM, 'GRU': nn.GRU}[self.cell_type]\n        self.rnn = rnn_class(\n            input_size=embed_size,\n            hidden_size=hidden_size,\n            num_layers=num_layers,\n            batch_first=True,\n            dropout=dropout if num_layers > 1 else 0.0\n        )\n        self.out = nn.Linear(hidden_size, output_size)\n\n    def forward(self, input_char, hidden):\n        embedded = self.embedding(input_char).unsqueeze(1)  # [batch_size, 1, embed_size]\n        if self.cell_type == 'LSTM':\n            output, (hidden, cell) = self.rnn(embedded, hidden)\n            output = self.out(output.squeeze(1))\n            return output, (hidden, cell)\n        else:\n            output, hidden = self.rnn(embedded, hidden)\n            output = self.out(output.squeeze(1))\n            return output, hidden\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T05:36:53.232666Z","iopub.execute_input":"2025-05-15T05:36:53.232974Z","iopub.status.idle":"2025-05-15T05:36:53.240718Z","shell.execute_reply.started":"2025-05-15T05:36:53.232951Z","shell.execute_reply":"2025-05-15T05:36:53.239745Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Seq2Seq model\n\nclass Seq2Seq(nn.Module):\n    def __init__(self, encoder, decoder):\n        super(Seq2Seq, self).__init__()\n        self.encoder = encoder\n        self.decoder = decoder\n\n    def forward(self, source, target, teacher_forcing_ratio=0.5):\n        batch_size = source.size(0)\n        target_len = target.size(1)\n        outputs = torch.zeros(batch_size, target_len, self.decoder.out.out_features).to(source.device)\n\n        encoder_outputs, hidden = self.encoder(source)\n        \n        # Initialize decoder input with <SOS> token (assuming 0 is <SOS>)\n        decoder_input = target[:, 0]\n        \n        # Handle hidden state for LSTM\n        if self.encoder.cell_type == 'LSTM':\n            hidden = (hidden[0], hidden[1])\n        \n        for t in range(1, target_len):\n            output, hidden = self.decoder(decoder_input, hidden)\n            outputs[:, t, :] = output\n            teacher_force = torch.rand(1).item() < teacher_forcing_ratio\n            top1 = output.argmax(1)\n            decoder_input = target[:, t] if teacher_force else top1\n\n        return outputs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T05:37:13.423967Z","iopub.execute_input":"2025-05-15T05:37:13.424930Z","iopub.status.idle":"2025-05-15T05:37:13.431772Z","shell.execute_reply.started":"2025-05-15T05:37:13.424899Z","shell.execute_reply":"2025-05-15T05:37:13.430858Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Wrapper function to create model\n\ndef create_model(input_vocab_size, output_vocab_size, embed_size=256, hidden_size=512, \n                 cell_type='RNN', num_layers=1, dropout=0.0):\n    encoder = EncoderRNN(input_vocab_size, embed_size, hidden_size, cell_type, num_layers, dropout)\n    decoder = DecoderRNN(output_vocab_size, embed_size, hidden_size, cell_type, num_layers, dropout)\n    model = Seq2Seq(encoder, decoder)\n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T05:37:56.983403Z","iopub.execute_input":"2025-05-15T05:37:56.983755Z","iopub.status.idle":"2025-05-15T05:37:56.989299Z","shell.execute_reply.started":"2025-05-15T05:37:56.983731Z","shell.execute_reply":"2025-05-15T05:37:56.988572Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"# Question 2","metadata":{}},{"cell_type":"markdown","source":"## Preparing dataset for training","metadata":{}},{"cell_type":"code","source":"# Importing Libraries\n\nimport pandas as pd\nimport numpy as np\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom collections import Counter\nimport os","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T05:43:41.218384Z","iopub.execute_input":"2025-05-15T05:43:41.219249Z","iopub.status.idle":"2025-05-15T05:43:41.581360Z","shell.execute_reply.started":"2025-05-15T05:43:41.219217Z","shell.execute_reply":"2025-05-15T05:43:41.580598Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# Vocabulary class to handle character-to-index mapping\nclass Vocabulary:\n    def __init__(self):\n        self.char2idx = {'<PAD>': 0, '<SOS>': 1, '<EOS>': 2, '<UNK>': 3}\n        self.idx2char = {0: '<PAD>', 1: '<SOS>', 2: '<EOS>', 3: '<UNK>'}\n        self.size = 4\n\n    def add_sequence(self, sequence):\n        for char in sequence:\n            if char not in self.char2idx:\n                self.char2idx[char] = self.size\n                self.idx2char[self.size] = char\n                self.size += 1\n\n    def get_indices(self, sequence):\n        indices = [self.char2idx.get(char, self.char2idx['<UNK>']) for char in sequence]\n        return indices","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T05:43:49.423989Z","iopub.execute_input":"2025-05-15T05:43:49.424414Z","iopub.status.idle":"2025-05-15T05:43:49.431954Z","shell.execute_reply.started":"2025-05-15T05:43:49.424391Z","shell.execute_reply":"2025-05-15T05:43:49.431032Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# Custom Dataset class\n\nclass DakshinaDataset(Dataset):\n    def __init__(self, data, src_vocab, tgt_vocab):\n        self.data = data\n        self.src_vocab = src_vocab\n        self.tgt_vocab = tgt_vocab\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        src = self.data.iloc[idx, 1]  # English (Latin)\n        tgt = self.data.iloc[idx, 0]  # Tamil\n        src_indices = [self.src_vocab.char2idx['<SOS>']] + self.src_vocab.get_indices(src) + [self.src_vocab.char2idx['<EOS>']]\n        tgt_indices = [self.tgt_vocab.char2idx['<SOS>']] + self.tgt_vocab.get_indices(tgt) + [self.tgt_vocab.char2idx['<EOS>']]\n        return torch.tensor(src_indices, dtype=torch.long), torch.tensor(tgt_indices, dtype=torch.long)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T05:44:04.557323Z","iopub.execute_input":"2025-05-15T05:44:04.557663Z","iopub.status.idle":"2025-05-15T05:44:04.564012Z","shell.execute_reply.started":"2025-05-15T05:44:04.557639Z","shell.execute_reply":"2025-05-15T05:44:04.563276Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# Function to load and preprocess data\ndef load_dakshina_data(train_path, val_path, test_path):\n    # Read TSV files without headers\n    train_df = pd.read_csv(train_path, sep='\\t', header=None, usecols=[0, 1])\n    val_df = pd.read_csv(val_path, sep='\\t', header=None, usecols=[0, 1])\n    test_df = pd.read_csv(test_path, sep='\\t', header=None, usecols=[0, 1])\n\n    # Ensure strings\n    train_df[0] = train_df[0].astype(str)\n    train_df[1] = train_df[1].astype(str)\n    val_df[0] = val_df[0].astype(str)\n    val_df[1] = val_df[1].astype(str)\n    test_df[0] = test_df[0].astype(str)\n    test_df[1] = test_df[1].astype(str)\n\n    # Build vocabularies\n    src_vocab = Vocabulary()  # English (Latin)\n    tgt_vocab = Vocabulary()  # Tamil\n\n    # Add characters to vocab from training data\n    for _, row in train_df.iterrows():\n        src_vocab.add_sequence(row[1])\n        tgt_vocab.add_sequence(row[0])\n\n    # Create datasets\n    train_dataset = DakshinaDataset(train_df, src_vocab, tgt_vocab)\n    val_dataset = DakshinaDataset(val_df, src_vocab, tgt_vocab)\n    test_dataset = DakshinaDataset(test_df, src_vocab, tgt_vocab)\n\n    return train_dataset, val_dataset, test_dataset, src_vocab, tgt_vocab\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T05:44:17.631733Z","iopub.execute_input":"2025-05-15T05:44:17.632012Z","iopub.status.idle":"2025-05-15T05:44:17.640309Z","shell.execute_reply.started":"2025-05-15T05:44:17.631994Z","shell.execute_reply":"2025-05-15T05:44:17.639148Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# Collate function for DataLoader\ndef collate_fn(batch):\n    src_batch, tgt_batch = zip(*batch)\n    # Pad sequences\n    src_padded = torch.nn.utils.rnn.pad_sequence(src_batch, batch_first=True, padding_value=0)\n    tgt_padded = torch.nn.utils.rnn.pad_sequence(tgt_batch, batch_first=True, padding_value=0)\n    return src_padded, tgt_padded","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T05:44:26.632191Z","iopub.execute_input":"2025-05-15T05:44:26.632474Z","iopub.status.idle":"2025-05-15T05:44:26.638127Z","shell.execute_reply.started":"2025-05-15T05:44:26.632455Z","shell.execute_reply":"2025-05-15T05:44:26.637067Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# Wrapper function for easier access\n\ndef prepare_data_loaders(train_path, val_path, test_path, batch_size=32):\n    train_dataset, val_dataset, test_dataset, src_vocab, tgt_vocab = load_dakshina_data(train_path, val_path, test_path)\n    \n    train_loader = DataLoader(\n        train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn, pin_memory=True\n    )\n    val_loader = DataLoader(\n        val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn, pin_memory=True\n    )\n    test_loader = DataLoader(\n        test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn, pin_memory=True\n    )\n    \n    return train_loader, val_loader, test_loader, src_vocab, tgt_vocab","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T05:44:46.874955Z","iopub.execute_input":"2025-05-15T05:44:46.875268Z","iopub.status.idle":"2025-05-15T05:44:46.881284Z","shell.execute_reply.started":"2025-05-15T05:44:46.875245Z","shell.execute_reply":"2025-05-15T05:44:46.880229Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# Paths to your local TSV files (update as needed)\ntrain_path = '/kaggle/input/dakshina-tamil/ta.translit.sampled.train.tsv'\nval_path = '/kaggle/input/dakshina-tamil/ta.translit.sampled.dev.tsv'\ntest_path = '/kaggle/input/dakshina-tamil/ta.translit.sampled.test.tsv'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T05:45:21.881047Z","iopub.execute_input":"2025-05-15T05:45:21.881336Z","iopub.status.idle":"2025-05-15T05:45:21.885656Z","shell.execute_reply.started":"2025-05-15T05:45:21.881315Z","shell.execute_reply":"2025-05-15T05:45:21.884779Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# Create data loaders\ntrain_loader, val_loader, test_loader, src_vocab, tgt_vocab = prepare_data_loaders(train_path, val_path, test_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T05:45:40.262673Z","iopub.execute_input":"2025-05-15T05:45:40.262995Z","iopub.status.idle":"2025-05-15T05:45:43.547772Z","shell.execute_reply.started":"2025-05-15T05:45:40.262972Z","shell.execute_reply":"2025-05-15T05:45:43.546722Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# Print vocabulary sizes\nprint(f\"Source (English) vocabulary size: {src_vocab.size}\")\nprint(f\"Target (Tamil) vocabulary size: {tgt_vocab.size}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T05:45:52.729416Z","iopub.execute_input":"2025-05-15T05:45:52.729755Z","iopub.status.idle":"2025-05-15T05:45:52.734982Z","shell.execute_reply.started":"2025-05-15T05:45:52.729734Z","shell.execute_reply":"2025-05-15T05:45:52.734209Z"}},"outputs":[{"name":"stdout","text":"Source (English) vocabulary size: 30\nTarget (Tamil) vocabulary size: 50\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}