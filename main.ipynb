{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11817904,"sourceType":"datasetVersion","datasetId":7422957}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Added dataset manually, if you want to download it, you can access it from here https://github.com/google-research-datasets/dakshina. Here I have used Tamil language.","metadata":{}},{"cell_type":"markdown","source":"# Question 1","metadata":{}},{"cell_type":"code","source":"# Importing libraries\n\nimport torch\nimport torch.nn as nn","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T05:36:01.193106Z","iopub.execute_input":"2025-05-15T05:36:01.193514Z","iopub.status.idle":"2025-05-15T05:36:08.505851Z","shell.execute_reply.started":"2025-05-15T05:36:01.193479Z","shell.execute_reply":"2025-05-15T05:36:08.504876Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# Encoder RNN\n\nclass EncoderRNN(nn.Module):\n    def __init__(self, input_size, embed_size, hidden_size, cell_type='RNN', num_layers=1, dropout=0.0):\n        super(EncoderRNN, self).__init__()\n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n        self.embedding = nn.Embedding(input_size, embed_size)\n        self.cell_type = cell_type.upper()\n        \n        # Select RNN cell type\n        rnn_class = {'RNN': nn.RNN, 'LSTM': nn.LSTM, 'GRU': nn.GRU}[self.cell_type]\n        self.rnn = rnn_class(\n            input_size=embed_size,\n            hidden_size=hidden_size,\n            num_layers=num_layers,\n            batch_first=True,\n            dropout=dropout if num_layers > 1 else 0.0\n        )\n\n    def forward(self, input_seq):\n        embedded = self.embedding(input_seq)  # [batch_size, seq_len, embed_size]\n        if self.cell_type == 'LSTM':\n            outputs, (hidden, cell) = self.rnn(embedded)\n            return outputs, (hidden, cell)\n        else:\n            outputs, hidden = self.rnn(embedded)\n            return outputs, hidden","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T05:36:34.939477Z","iopub.execute_input":"2025-05-15T05:36:34.939834Z","iopub.status.idle":"2025-05-15T05:36:34.947186Z","shell.execute_reply.started":"2025-05-15T05:36:34.939811Z","shell.execute_reply":"2025-05-15T05:36:34.946219Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Decoder RNN\n\nclass DecoderRNN(nn.Module):\n    def __init__(self, output_size, embed_size, hidden_size, cell_type='RNN', num_layers=1, dropout=0.0):\n        super(DecoderRNN, self).__init__()\n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n        self.embedding = nn.Embedding(output_size, embed_size)\n        self.cell_type = cell_type.upper()\n        \n        # Select RNN cell type\n        rnn_class = {'RNN': nn.RNN, 'LSTM': nn.LSTM, 'GRU': nn.GRU}[self.cell_type]\n        self.rnn = rnn_class(\n            input_size=embed_size,\n            hidden_size=hidden_size,\n            num_layers=num_layers,\n            batch_first=True,\n            dropout=dropout if num_layers > 1 else 0.0\n        )\n        self.out = nn.Linear(hidden_size, output_size)\n\n    def forward(self, input_char, hidden):\n        embedded = self.embedding(input_char).unsqueeze(1)  # [batch_size, 1, embed_size]\n        if self.cell_type == 'LSTM':\n            output, (hidden, cell) = self.rnn(embedded, hidden)\n            output = self.out(output.squeeze(1))\n            return output, (hidden, cell)\n        else:\n            output, hidden = self.rnn(embedded, hidden)\n            output = self.out(output.squeeze(1))\n            return output, hidden\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T05:36:53.232666Z","iopub.execute_input":"2025-05-15T05:36:53.232974Z","iopub.status.idle":"2025-05-15T05:36:53.240718Z","shell.execute_reply.started":"2025-05-15T05:36:53.232951Z","shell.execute_reply":"2025-05-15T05:36:53.239745Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Seq2Seq model\n\nclass Seq2Seq(nn.Module):\n    def __init__(self, encoder, decoder):\n        super(Seq2Seq, self).__init__()\n        self.encoder = encoder\n        self.decoder = decoder\n\n    def forward(self, source, target, teacher_forcing_ratio=0.5):\n        batch_size = source.size(0)\n        target_len = target.size(1)\n        outputs = torch.zeros(batch_size, target_len, self.decoder.out.out_features).to(source.device)\n\n        encoder_outputs, hidden = self.encoder(source)\n        \n        # Initialize decoder input with <SOS> token (assuming 0 is <SOS>)\n        decoder_input = target[:, 0]\n        \n        # Handle hidden state for LSTM\n        if self.encoder.cell_type == 'LSTM':\n            hidden = (hidden[0], hidden[1])\n        \n        for t in range(1, target_len):\n            output, hidden = self.decoder(decoder_input, hidden)\n            outputs[:, t, :] = output\n            teacher_force = torch.rand(1).item() < teacher_forcing_ratio\n            top1 = output.argmax(1)\n            decoder_input = target[:, t] if teacher_force else top1\n\n        return outputs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T05:37:13.423967Z","iopub.execute_input":"2025-05-15T05:37:13.424930Z","iopub.status.idle":"2025-05-15T05:37:13.431772Z","shell.execute_reply.started":"2025-05-15T05:37:13.424899Z","shell.execute_reply":"2025-05-15T05:37:13.430858Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Wrapper function to create model\n\ndef create_model(input_vocab_size, output_vocab_size, embed_size=256, hidden_size=512, \n                 cell_type='RNN', num_layers=1, dropout=0.0):\n    encoder = EncoderRNN(input_vocab_size, embed_size, hidden_size, cell_type, num_layers, dropout)\n    decoder = DecoderRNN(output_vocab_size, embed_size, hidden_size, cell_type, num_layers, dropout)\n    model = Seq2Seq(encoder, decoder)\n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T05:37:56.983403Z","iopub.execute_input":"2025-05-15T05:37:56.983755Z","iopub.status.idle":"2025-05-15T05:37:56.989299Z","shell.execute_reply.started":"2025-05-15T05:37:56.983731Z","shell.execute_reply":"2025-05-15T05:37:56.988572Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"# Question 2","metadata":{}},{"cell_type":"markdown","source":"## Preparing dataset for training","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}