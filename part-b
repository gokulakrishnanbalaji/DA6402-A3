{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b659d60",
   "metadata": {
    "papermill": {
     "duration": 0.006128,
     "end_time": "2025-05-18T04:03:24.829525",
     "exception": false,
     "start_time": "2025-05-18T04:03:24.823397",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Question 5 - Attention Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9884fd3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T04:03:24.840913Z",
     "iopub.status.busy": "2025-05-18T04:03:24.840617Z",
     "iopub.status.idle": "2025-05-18T04:03:29.110007Z",
     "shell.execute_reply": "2025-05-18T04:03:29.109166Z"
    },
    "papermill": {
     "duration": 4.276504,
     "end_time": "2025-05-18T04:03:29.111441",
     "exception": false,
     "start_time": "2025-05-18T04:03:24.834937",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02bd5e0d",
   "metadata": {
    "papermill": {
     "duration": 0.004689,
     "end_time": "2025-05-18T04:03:29.121587",
     "exception": false,
     "start_time": "2025-05-18T04:03:29.116898",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## preparing dataset for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "711b38cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T04:03:29.132329Z",
     "iopub.status.busy": "2025-05-18T04:03:29.131995Z",
     "iopub.status.idle": "2025-05-18T04:03:30.547383Z",
     "shell.execute_reply": "2025-05-18T04:03:30.546802Z"
    },
    "papermill": {
     "duration": 1.4223,
     "end_time": "2025-05-18T04:03:30.548824",
     "exception": false,
     "start_time": "2025-05-18T04:03:29.126524",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import optim\n",
    "from collections import Counter\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7c3b31e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T04:03:30.560280Z",
     "iopub.status.busy": "2025-05-18T04:03:30.559907Z",
     "iopub.status.idle": "2025-05-18T04:03:30.564778Z",
     "shell.execute_reply": "2025-05-18T04:03:30.564203Z"
    },
    "papermill": {
     "duration": 0.011679,
     "end_time": "2025-05-18T04:03:30.565827",
     "exception": false,
     "start_time": "2025-05-18T04:03:30.554148",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Vocabulary class to handle character-to-index mapping\n",
    "class Vocabulary:\n",
    "    def __init__(self):\n",
    "        self.char2idx = {'<PAD>': 0, '<SOS>': 1, '<EOS>': 2, '<UNK>': 3}\n",
    "        self.idx2char = {0: '<PAD>', 1: '<SOS>', 2: '<EOS>', 3: '<UNK>'}\n",
    "        self.size = 4\n",
    "\n",
    "    def add_sequence(self, sequence):\n",
    "        for char in sequence:\n",
    "            if char not in self.char2idx:\n",
    "                self.char2idx[char] = self.size\n",
    "                self.idx2char[self.size] = char\n",
    "                self.size += 1\n",
    "\n",
    "    def get_indices(self, sequence):\n",
    "        indices = [self.char2idx.get(char, self.char2idx['<UNK>']) for char in sequence]\n",
    "        return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bf5acc5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T04:03:30.576386Z",
     "iopub.status.busy": "2025-05-18T04:03:30.576175Z",
     "iopub.status.idle": "2025-05-18T04:03:30.580986Z",
     "shell.execute_reply": "2025-05-18T04:03:30.580468Z"
    },
    "papermill": {
     "duration": 0.011189,
     "end_time": "2025-05-18T04:03:30.582034",
     "exception": false,
     "start_time": "2025-05-18T04:03:30.570845",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Custom Dataset class\n",
    "\n",
    "class DakshinaDataset(Dataset):\n",
    "    def __init__(self, data, src_vocab, tgt_vocab):\n",
    "        self.data = data\n",
    "        self.src_vocab = src_vocab\n",
    "        self.tgt_vocab = tgt_vocab\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        src = self.data.iloc[idx, 1]  # English (Latin)\n",
    "        tgt = self.data.iloc[idx, 0]  # Tamil\n",
    "        src_indices = [self.src_vocab.char2idx['<SOS>']] + self.src_vocab.get_indices(src) + [self.src_vocab.char2idx['<EOS>']]\n",
    "        tgt_indices = [self.tgt_vocab.char2idx['<SOS>']] + self.tgt_vocab.get_indices(tgt) + [self.tgt_vocab.char2idx['<EOS>']]\n",
    "        return torch.tensor(src_indices, dtype=torch.long), torch.tensor(tgt_indices, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d93acbda",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T04:03:30.592622Z",
     "iopub.status.busy": "2025-05-18T04:03:30.592436Z",
     "iopub.status.idle": "2025-05-18T04:03:30.598187Z",
     "shell.execute_reply": "2025-05-18T04:03:30.597509Z"
    },
    "papermill": {
     "duration": 0.012346,
     "end_time": "2025-05-18T04:03:30.599309",
     "exception": false,
     "start_time": "2025-05-18T04:03:30.586963",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to load and preprocess data\n",
    "def load_dakshina_data(train_path, val_path, test_path):\n",
    "    # Read TSV files without headers\n",
    "    train_df = pd.read_csv(train_path, sep='\\t', header=None, usecols=[0, 1])\n",
    "    val_df = pd.read_csv(val_path, sep='\\t', header=None, usecols=[0, 1])\n",
    "    test_df = pd.read_csv(test_path, sep='\\t', header=None, usecols=[0, 1])\n",
    "\n",
    "    # Ensure strings\n",
    "    train_df[0] = train_df[0].astype(str)\n",
    "    train_df[1] = train_df[1].astype(str)\n",
    "    val_df[0] = val_df[0].astype(str)\n",
    "    val_df[1] = val_df[1].astype(str)\n",
    "    test_df[0] = test_df[0].astype(str)\n",
    "    test_df[1] = test_df[1].astype(str)\n",
    "\n",
    "    # Build vocabularies\n",
    "    src_vocab = Vocabulary()  # English (Latin)\n",
    "    tgt_vocab = Vocabulary()  # Tamil\n",
    "\n",
    "    # Add characters to vocab from training data\n",
    "    for _, row in train_df.iterrows():\n",
    "        src_vocab.add_sequence(row[1])\n",
    "        tgt_vocab.add_sequence(row[0])\n",
    "\n",
    "    # Create datasets\n",
    "    train_dataset = DakshinaDataset(train_df, src_vocab, tgt_vocab)\n",
    "    val_dataset = DakshinaDataset(val_df, src_vocab, tgt_vocab)\n",
    "    test_dataset = DakshinaDataset(test_df, src_vocab, tgt_vocab)\n",
    "\n",
    "    return train_dataset, val_dataset, test_dataset, src_vocab, tgt_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffb9246e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T04:03:30.609905Z",
     "iopub.status.busy": "2025-05-18T04:03:30.609445Z",
     "iopub.status.idle": "2025-05-18T04:03:30.612990Z",
     "shell.execute_reply": "2025-05-18T04:03:30.612475Z"
    },
    "papermill": {
     "duration": 0.009896,
     "end_time": "2025-05-18T04:03:30.614020",
     "exception": false,
     "start_time": "2025-05-18T04:03:30.604124",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Collate function for DataLoader\n",
    "def collate_fn(batch):\n",
    "    src_batch, tgt_batch = zip(*batch)\n",
    "    # Pad sequences\n",
    "    src_padded = torch.nn.utils.rnn.pad_sequence(src_batch, batch_first=True, padding_value=0)\n",
    "    tgt_padded = torch.nn.utils.rnn.pad_sequence(tgt_batch, batch_first=True, padding_value=0)\n",
    "    return src_padded, tgt_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "201682d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T04:03:30.624310Z",
     "iopub.status.busy": "2025-05-18T04:03:30.624135Z",
     "iopub.status.idle": "2025-05-18T04:03:30.628216Z",
     "shell.execute_reply": "2025-05-18T04:03:30.627685Z"
    },
    "papermill": {
     "duration": 0.010314,
     "end_time": "2025-05-18T04:03:30.629210",
     "exception": false,
     "start_time": "2025-05-18T04:03:30.618896",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Wrapper function for easier access\n",
    "\n",
    "def prepare_data_loaders(train_path, val_path, test_path, batch_size=32):\n",
    "    train_dataset, val_dataset, test_dataset, src_vocab, tgt_vocab = load_dakshina_data(train_path, val_path, test_path)\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn, pin_memory=True\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn, pin_memory=True\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn, pin_memory=True\n",
    "    )\n",
    "    \n",
    "    return train_loader, val_loader, test_loader, src_vocab, tgt_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "126b8379",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T04:03:30.640047Z",
     "iopub.status.busy": "2025-05-18T04:03:30.639605Z",
     "iopub.status.idle": "2025-05-18T04:03:30.642596Z",
     "shell.execute_reply": "2025-05-18T04:03:30.642100Z"
    },
    "papermill": {
     "duration": 0.009585,
     "end_time": "2025-05-18T04:03:30.643584",
     "exception": false,
     "start_time": "2025-05-18T04:03:30.633999",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Paths to your local TSV files (update as needed)\n",
    "train_path = '/kaggle/input/dakshina-tamil-b/ta.translit.sampled.train.tsv'\n",
    "val_path = '/kaggle/input/dakshina-tamil-b/ta.translit.sampled.dev.tsv'\n",
    "test_path = '/kaggle/input/dakshina-tamil-b/ta.translit.sampled.test.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3feb50ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T04:03:30.653863Z",
     "iopub.status.busy": "2025-05-18T04:03:30.653659Z",
     "iopub.status.idle": "2025-05-18T04:03:33.261043Z",
     "shell.execute_reply": "2025-05-18T04:03:33.260429Z"
    },
    "papermill": {
     "duration": 2.613864,
     "end_time": "2025-05-18T04:03:33.262379",
     "exception": false,
     "start_time": "2025-05-18T04:03:30.648515",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create data loaders\n",
    "train_loader, val_loader, test_loader, src_vocab, tgt_vocab = prepare_data_loaders(train_path, val_path, test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "baf9a48f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T04:03:33.275266Z",
     "iopub.status.busy": "2025-05-18T04:03:33.275024Z",
     "iopub.status.idle": "2025-05-18T04:03:33.279556Z",
     "shell.execute_reply": "2025-05-18T04:03:33.278886Z"
    },
    "papermill": {
     "duration": 0.011508,
     "end_time": "2025-05-18T04:03:33.280631",
     "exception": false,
     "start_time": "2025-05-18T04:03:33.269123",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source (English) vocabulary size: 30\n",
      "Target (Tamil) vocabulary size: 50\n"
     ]
    }
   ],
   "source": [
    "# Print vocabulary sizes\n",
    "print(f\"Source (English) vocabulary size: {src_vocab.size}\")\n",
    "print(f\"Target (Tamil) vocabulary size: {tgt_vocab.size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4a631a",
   "metadata": {
    "papermill": {
     "duration": 0.004667,
     "end_time": "2025-05-18T04:03:33.290247",
     "exception": false,
     "start_time": "2025-05-18T04:03:33.285580",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## defining models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ae5c134",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T04:03:33.301171Z",
     "iopub.status.busy": "2025-05-18T04:03:33.300948Z",
     "iopub.status.idle": "2025-05-18T04:03:33.309138Z",
     "shell.execute_reply": "2025-05-18T04:03:33.308425Z"
    },
    "papermill": {
     "duration": 0.01505,
     "end_time": "2025-05-18T04:03:33.310210",
     "exception": false,
     "start_time": "2025-05-18T04:03:33.295160",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, hidden_size, attention_type='bahdanau'):\n",
    "        super(Attention, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.attention_type = attention_type.lower()\n",
    "        \n",
    "        if self.attention_type == 'bahdanau':\n",
    "            self.Wa = nn.Linear(hidden_size * 2, hidden_size)\n",
    "            self.Ua = nn.Linear(hidden_size, 1, bias=False)\n",
    "        elif self.attention_type == 'dot':\n",
    "            pass  # Dot-product attention uses no additional parameters\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported attention type. Use 'bahdanau' or 'dot'.\")\n",
    "\n",
    "    def forward(self, decoder_hidden, encoder_outputs):\n",
    "        # decoder_hidden: (num_layers, batch_size, hidden_size) or tuple for LSTM\n",
    "        # encoder_outputs: (batch_size, seq_len, hidden_size)\n",
    "        batch_size = encoder_outputs.size(0)\n",
    "        seq_len = encoder_outputs.size(1)\n",
    "        \n",
    "        # Validate encoder_outputs shape\n",
    "        assert encoder_outputs.dim() == 3, f\"Expected encoder_outputs to be 3D, got {encoder_outputs.shape}\"\n",
    "        assert encoder_outputs.size(2) == self.hidden_size, f\"Expected encoder_outputs hidden_size {self.hidden_size}, got {encoder_outputs.size(2)}\"\n",
    "        \n",
    "        # Extract the last layer of decoder hidden state\n",
    "        if isinstance(decoder_hidden, tuple):  # LSTM case\n",
    "            decoder_hidden = decoder_hidden[0]  # Take hidden state, not cell state\n",
    "        decoder_hidden = decoder_hidden[-1]  # (batch_size, hidden_size)\n",
    "        \n",
    "        assert decoder_hidden.dim() == 2, f\"Expected decoder_hidden to be 2D, got {decoder_hidden.shape}\"\n",
    "        assert decoder_hidden.size(1) == self.hidden_size, f\"Expected decoder_hidden hidden_size {self.hidden_size}, got {decoder_hidden.size(1)}\"\n",
    "        \n",
    "        if self.attention_type == 'bahdanau':\n",
    "            # Repeat decoder hidden to match seq_len\n",
    "            decoder_hidden = decoder_hidden.unsqueeze(1).repeat(1, seq_len, 1)  # (batch_size, seq_len, hidden_size)\n",
    "            # Combine with encoder outputs\n",
    "            combined = torch.cat((decoder_hidden, encoder_outputs), dim=2)  # (batch_size, seq_len, hidden_size*2)\n",
    "            # Compute energy\n",
    "            energy = torch.tanh(self.Wa(combined))  # (batch_size, seq_len, hidden_size)\n",
    "            attention_scores = self.Ua(energy).squeeze(2)  # (batch_size, seq_len)\n",
    "        else:  # dot\n",
    "            # Compute dot-product attention\n",
    "            decoder_hidden = decoder_hidden.unsqueeze(1)  # (batch_size, 1, hidden_size)\n",
    "            encoder_outputs_t = encoder_outputs.transpose(1, 2)  # (batch_size, hidden_size, seq_len)\n",
    "            # Verify shapes before bmm\n",
    "            assert decoder_hidden.shape == (batch_size, 1, self.hidden_size), f\"Expected decoder_hidden (batch_size, 1, hidden_size), got {decoder_hidden.shape}\"\n",
    "            assert encoder_outputs_t.shape == (batch_size, self.hidden_size, seq_len), f\"Expected encoder_outputs_t (batch_size, hidden_size, seq_len), got {encoder_outputs_t.shape}\"\n",
    "            attention_scores = torch.bmm(decoder_hidden, encoder_outputs_t).squeeze(1)  # (batch_size, seq_len)\n",
    "        \n",
    "        # Softmax to get attention weights\n",
    "        attention_weights = F.softmax(attention_scores, dim=1)  # (batch_size, seq_len)\n",
    "        # Compute context vector\n",
    "        context = torch.bmm(attention_weights.unsqueeze(1), encoder_outputs).squeeze(1)  # (batch_size, hidden_size)\n",
    "        \n",
    "        return context, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5dd9c5b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T04:03:33.321254Z",
     "iopub.status.busy": "2025-05-18T04:03:33.320577Z",
     "iopub.status.idle": "2025-05-18T04:03:33.326519Z",
     "shell.execute_reply": "2025-05-18T04:03:33.325793Z"
    },
    "papermill": {
     "duration": 0.012415,
     "end_time": "2025-05-18T04:03:33.327548",
     "exception": false,
     "start_time": "2025-05-18T04:03:33.315133",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, embed_size, hidden_size, cell_type='RNN', num_layers=1, dropout=0.0):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding = nn.Embedding(input_size, embed_size)\n",
    "        self.cell_type = cell_type.upper()\n",
    "        \n",
    "        rnn_class = {'RNN': nn.RNN, 'LSTM': nn.LSTM, 'GRU': nn.GRU}[self.cell_type]\n",
    "        self.rnn = rnn_class(\n",
    "            input_size=embed_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_layers > 1 else 0.0\n",
    "        )\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        embedded = self.embedding(input_seq)\n",
    "        if self.cell_type == 'LSTM':\n",
    "            outputs, (hidden, cell) = self.rnn(embedded)\n",
    "            return outputs, (hidden, cell)\n",
    "        else:\n",
    "            outputs, hidden = self.rnn(embedded)\n",
    "            return outputs, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec9127df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T04:03:33.338467Z",
     "iopub.status.busy": "2025-05-18T04:03:33.338277Z",
     "iopub.status.idle": "2025-05-18T04:03:33.345149Z",
     "shell.execute_reply": "2025-05-18T04:03:33.344435Z"
    },
    "papermill": {
     "duration": 0.013756,
     "end_time": "2025-05-18T04:03:33.346345",
     "exception": false,
     "start_time": "2025-05-18T04:03:33.332589",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, output_size, embed_size, hidden_size, cell_type='RNN', num_layers=1, dropout=0.0, attention_type='bahdanau'):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding = nn.Embedding(output_size, embed_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.cell_type = cell_type.upper()\n",
    "        \n",
    "        rnn_class = {'RNN': nn.RNN, 'LSTM': nn.LSTM, 'GRU': nn.GRU}[self.cell_type]\n",
    "        self.rnn = rnn_class(\n",
    "            input_size=embed_size + hidden_size,  # Input includes context vector\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_layers > 1 else 0.0\n",
    "        )\n",
    "        self.attention = Attention(hidden_size, attention_type)\n",
    "        self.out = nn.Linear(hidden_size * 2, output_size)  # Combine RNN output and context\n",
    "\n",
    "    def forward(self, input_char, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input_char).unsqueeze(1)  # (batch_size, 1, embed_size)\n",
    "        embedded = self.dropout(embedded)\n",
    "        \n",
    "        # Compute attention\n",
    "        context, attention_weights = self.attention(hidden, encoder_outputs)  # context: (batch_size, hidden_size)\n",
    "        \n",
    "        # Concatenate context with embedded input\n",
    "        rnn_input = torch.cat((embedded, context.unsqueeze(1)), dim=2)  # (batch_size, 1, embed_size + hidden_size)\n",
    "        \n",
    "        if self.cell_type == 'LSTM':\n",
    "            output, (hidden, cell) = self.rnn(rnn_input, hidden)\n",
    "            output = output.squeeze(1)  # (batch_size, hidden_size)\n",
    "            output = torch.cat((output, context), dim=1)  # (batch_size, hidden_size * 2)\n",
    "            output = self.out(output)  # (batch_size, output_size)\n",
    "            return output, (hidden, cell), attention_weights\n",
    "        else:\n",
    "            output, hidden = self.rnn(rnn_input, hidden)\n",
    "            output = output.squeeze(1)\n",
    "            output = torch.cat((output, context), dim=1)\n",
    "            output = self.out(output)\n",
    "            return output, hidden, attention_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9745b8f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T04:03:33.357058Z",
     "iopub.status.busy": "2025-05-18T04:03:33.356664Z",
     "iopub.status.idle": "2025-05-18T04:03:33.363339Z",
     "shell.execute_reply": "2025-05-18T04:03:33.362783Z"
    },
    "papermill": {
     "duration": 0.012941,
     "end_time": "2025-05-18T04:03:33.364325",
     "exception": false,
     "start_time": "2025-05-18T04:03:33.351384",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, source, target, teacher_forcing_ratio=0.5):\n",
    "        batch_size = source.size(0)\n",
    "        target_len = target.size(1)\n",
    "        outputs = torch.zeros(batch_size, target_len, self.decoder.out.out_features).to(source.device)\n",
    "        \n",
    "        encoder_outputs, hidden = self.encoder(source)\n",
    "        \n",
    "        decoder_input = target[:, 0]\n",
    "        \n",
    "        # Handle differing encoder/decoder layers\n",
    "        if self.encoder.cell_type == 'LSTM':\n",
    "            hidden, cell = hidden\n",
    "            if self.encoder.num_layers != self.decoder.num_layers:\n",
    "                factor = self.decoder.num_layers // self.encoder.num_layers + 1\n",
    "                hidden = hidden.repeat(factor, 1, 1)[:self.decoder.num_layers]\n",
    "                cell = cell.repeat(factor, 1, 1)[:self.decoder.num_layers]\n",
    "            hidden = (hidden, cell)\n",
    "        else:\n",
    "            if self.encoder.num_layers != self.decoder.num_layers:\n",
    "                factor = self.decoder.num_layers // self.encoder.num_layers + 1\n",
    "                hidden = hidden.repeat(factor, 1, 1)[:self.decoder.num_layers]\n",
    "        \n",
    "        for t in range(1, target_len):\n",
    "            output, hidden, _ = self.decoder(decoder_input, hidden, encoder_outputs)\n",
    "            outputs[:, t, :] = output\n",
    "            teacher_force = torch.rand(1).item() < teacher_forcing_ratio\n",
    "            top1 = output.argmax(1)\n",
    "            decoder_input = target[:, t] if teacher_force else top1\n",
    "\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f7b22ac9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T04:03:33.374922Z",
     "iopub.status.busy": "2025-05-18T04:03:33.374694Z",
     "iopub.status.idle": "2025-05-18T04:03:33.378729Z",
     "shell.execute_reply": "2025-05-18T04:03:33.378052Z"
    },
    "papermill": {
     "duration": 0.010574,
     "end_time": "2025-05-18T04:03:33.379924",
     "exception": false,
     "start_time": "2025-05-18T04:03:33.369350",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_model(input_vocab_size, output_vocab_size, embed_size=256, hidden_size=512, \n",
    "                 cell_type='RNN', encoder_layers=1, decoder_layers=1, dropout=0.0, attention_type='bahdanau'):\n",
    "    encoder = EncoderRNN(input_vocab_size, embed_size, hidden_size, cell_type, encoder_layers, dropout)\n",
    "    decoder = DecoderRNN(output_vocab_size, embed_size, hidden_size, cell_type, decoder_layers, dropout, attention_type)\n",
    "    model = Seq2Seq(encoder, decoder)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa6c70b",
   "metadata": {
    "papermill": {
     "duration": 0.004551,
     "end_time": "2025-05-18T04:03:33.389638",
     "exception": false,
     "start_time": "2025-05-18T04:03:33.385087",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## setting up wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b64021d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T04:03:33.399973Z",
     "iopub.status.busy": "2025-05-18T04:03:33.399724Z",
     "iopub.status.idle": "2025-05-18T04:03:37.238787Z",
     "shell.execute_reply": "2025-05-18T04:03:37.237646Z"
    },
    "papermill": {
     "duration": 3.846505,
     "end_time": "2025-05-18T04:03:37.240950",
     "exception": false,
     "start_time": "2025-05-18T04:03:33.394445",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install wandb -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ca1f7f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T04:03:37.252209Z",
     "iopub.status.busy": "2025-05-18T04:03:37.251948Z",
     "iopub.status.idle": "2025-05-18T04:03:39.990643Z",
     "shell.execute_reply": "2025-05-18T04:03:39.990060Z"
    },
    "papermill": {
     "duration": 2.745763,
     "end_time": "2025-05-18T04:03:39.992014",
     "exception": false,
     "start_time": "2025-05-18T04:03:37.246251",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "92754df3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T04:03:40.003507Z",
     "iopub.status.busy": "2025-05-18T04:03:40.002694Z",
     "iopub.status.idle": "2025-05-18T04:03:40.169500Z",
     "shell.execute_reply": "2025-05-18T04:03:40.168958Z"
    },
    "papermill": {
     "duration": 0.17352,
     "end_time": "2025-05-18T04:03:40.170786",
     "exception": false,
     "start_time": "2025-05-18T04:03:39.997266",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from kaggle_secrets import UserSecretsClient\n",
    "user_secrets = UserSecretsClient()\n",
    "secret_value_0 = user_secrets.get_secret(\"wandb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e672ac4e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T04:03:40.182146Z",
     "iopub.status.busy": "2025-05-18T04:03:40.181652Z",
     "iopub.status.idle": "2025-05-18T04:03:40.754422Z",
     "shell.execute_reply": "2025-05-18T04:03:40.753706Z"
    },
    "papermill": {
     "duration": 0.579524,
     "end_time": "2025-05-18T04:03:40.755582",
     "exception": false,
     "start_time": "2025-05-18T04:03:40.176058",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mda24m007\u001b[0m (\u001b[33mda24m007-iit-madras\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login(key=secret_value_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7116cf3d",
   "metadata": {
    "papermill": {
     "duration": 0.005137,
     "end_time": "2025-05-18T04:03:40.766471",
     "exception": false,
     "start_time": "2025-05-18T04:03:40.761334",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Running wandb sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2d017283",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T04:03:40.777491Z",
     "iopub.status.busy": "2025-05-18T04:03:40.777244Z",
     "iopub.status.idle": "2025-05-18T04:03:40.840960Z",
     "shell.execute_reply": "2025-05-18T04:03:40.840357Z"
    },
    "papermill": {
     "duration": 0.070599,
     "end_time": "2025-05-18T04:03:40.842158",
     "exception": false,
     "start_time": "2025-05-18T04:03:40.771559",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a9937079",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T04:03:40.854158Z",
     "iopub.status.busy": "2025-05-18T04:03:40.853910Z",
     "iopub.status.idle": "2025-05-18T04:03:40.863974Z",
     "shell.execute_reply": "2025-05-18T04:03:40.863247Z"
    },
    "papermill": {
     "duration": 0.017497,
     "end_time": "2025-05-18T04:03:40.865187",
     "exception": false,
     "start_time": "2025-05-18T04:03:40.847690",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Beam search decoding (adapted for attention)\n",
    "def beam_search_decode(model, src, max_len, beam_width, sos_idx, eos_idx):\n",
    "    model.eval()\n",
    "    src = src.to(device)\n",
    "    batch_size = src.size(0)\n",
    "    encoder_outputs, hidden = model.encoder(src)\n",
    "    \n",
    "    if model.encoder.cell_type == 'LSTM':\n",
    "        hidden, cell = hidden\n",
    "        if model.encoder.num_layers != model.decoder.num_layers:\n",
    "            factor = model.decoder.num_layers // model.encoder.num_layers\n",
    "            if factor > 1:\n",
    "                hidden = hidden.repeat(factor, 1, 1)\n",
    "                cell = cell.repeat(factor, 1, 1)\n",
    "            else:\n",
    "                hidden = hidden[-model.decoder.num_layers:]\n",
    "                cell = cell[-model.decoder.num_layers:]\n",
    "        hidden = (hidden, cell)\n",
    "    else:\n",
    "        if model.encoder.num_layers != model.decoder.num_layers:\n",
    "            factor = model.decoder.num_layers // model.encoder.num_layers\n",
    "            if factor > 1:\n",
    "                hidden = hidden.repeat(factor, 1, 1)\n",
    "            else:\n",
    "                hidden = hidden[-model.decoder.num_layers:]\n",
    "    \n",
    "    beams = [(torch.tensor([sos_idx], device=device), hidden, 0.0)]\n",
    "    completed = []\n",
    "    \n",
    "    for _ in range(max_len):\n",
    "        new_beams = []\n",
    "        for seq, hid, score in beams:\n",
    "            if seq[-1].item() == eos_idx:\n",
    "                completed.append((seq, score))\n",
    "                continue\n",
    "            output, new_hidden, _ = model.decoder(seq[-1].unsqueeze(0), hid, encoder_outputs)\n",
    "            probs = torch.softmax(output, dim=-1)\n",
    "            top_probs, top_idx = probs.topk(beam_width)\n",
    "            \n",
    "            for i in range(beam_width):\n",
    "                new_seq = torch.cat([seq, top_idx[:, i]])\n",
    "                new_score = score - math.log(top_probs[:, i].item())\n",
    "                new_beams.append((new_seq, new_hidden, new_score))\n",
    "        \n",
    "        new_beams = sorted(new_beams, key=lambda x: x[2])[:beam_width]\n",
    "        beams = new_beams\n",
    "        \n",
    "        if len(completed) >= beam_width:\n",
    "            break\n",
    "    \n",
    "    completed = sorted(completed, key=lambda x: x[1])\n",
    "    if completed:\n",
    "        return completed[0][0]\n",
    "    return beams[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6210c5fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T04:03:40.877124Z",
     "iopub.status.busy": "2025-05-18T04:03:40.876468Z",
     "iopub.status.idle": "2025-05-18T04:03:40.888522Z",
     "shell.execute_reply": "2025-05-18T04:03:40.887975Z"
    },
    "papermill": {
     "duration": 0.018877,
     "end_time": "2025-05-18T04:03:40.889534",
     "exception": false,
     "start_time": "2025-05-18T04:03:40.870657",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Training and evaluation function\n",
    "def train_and_evaluate():\n",
    "    wandb.init()\n",
    "    config = wandb.config\n",
    "    \n",
    "    # Create model with sweep parameters\n",
    "    model = create_model(\n",
    "        input_vocab_size=src_vocab.size,\n",
    "        output_vocab_size=tgt_vocab.size,\n",
    "        embed_size=config.embed_size,\n",
    "        hidden_size=config.hidden_size,\n",
    "        cell_type=config.cell_type,\n",
    "        encoder_layers=1,  # Single layer\n",
    "        decoder_layers=1,  # Single layer\n",
    "        dropout=config.dropout,\n",
    "        attention_type=config.attention_type\n",
    "    ).to(device)\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "    \n",
    "    for epoch in range(10):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for src, tgt in train_loader:\n",
    "            src, tgt = src.to(device), tgt.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(src, tgt, teacher_forcing_ratio=0.5)\n",
    "            output = output[:, 1:].reshape(-1, output.size(-1))\n",
    "            tgt_flat = tgt[:, 1:].reshape(-1)\n",
    "            loss = criterion(output, tgt_flat)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        # Compute training accuracy on one batch\n",
    "        model.eval()\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        with torch.no_grad():\n",
    "            for src, tgt in train_loader:\n",
    "                src, tgt = src.to(device), tgt.to(device)\n",
    "                for i in range(src.size(0)):\n",
    "                    pred = beam_search_decode(\n",
    "                        model, src[i:i+1], max_len=50,\n",
    "                        beam_width=config.beam_width,\n",
    "                        sos_idx=tgt_vocab.char2idx['<SOS>'],\n",
    "                        eos_idx=tgt_vocab.char2idx['<EOS>']\n",
    "                    )\n",
    "                    pred_str = ''.join([tgt_vocab.idx2char[idx.item()] for idx in pred if idx.item() not in [0, 1, 2]])\n",
    "                    tgt_seq = tgt[i]\n",
    "                    tgt_str = ''.join([tgt_vocab.idx2char[idx.item()] for idx in tgt_seq[1:] if idx.item() not in [0, 1, 2]])\n",
    "                    if pred_str == tgt_str:\n",
    "                        train_correct += 1\n",
    "                    train_total += 1\n",
    "                break\n",
    "        \n",
    "        # Compute validation loss and accuracy\n",
    "        val_loss = 0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        with torch.no_grad():\n",
    "            for src, tgt in val_loader:\n",
    "                src, tgt = src.to(device), tgt.to(device)\n",
    "                output = model(src, tgt, teacher_forcing_ratio=0.0)\n",
    "                output = output[:, 1:].reshape(-1, output.size(-1))\n",
    "                tgt_flat = tgt[:, 1:].reshape(-1)\n",
    "                loss = criterion(output, tgt_flat)\n",
    "                val_loss += loss.item()\n",
    "            \n",
    "            # Validation accuracy on one batch\n",
    "            for src, tgt in val_loader:\n",
    "                src, tgt = src.to(device), tgt.to(device)\n",
    "                for i in range(src.size(0)):\n",
    "                    pred = beam_search_decode(\n",
    "                        model, src[i:i+1], max_len=50,\n",
    "                        beam_width=config.beam_width,\n",
    "                        sos_idx=tgt_vocab.char2idx['<SOS>'],\n",
    "                        eos_idx=tgt_vocab.char2idx['<EOS>']\n",
    "                    )\n",
    "                    pred_str = ''.join([tgt_vocab.idx2char[idx.item()] for idx in pred if idx.item() not in [0, 1, 2]])\n",
    "                    tgt_seq = tgt[i]\n",
    "                    tgt_str = ''.join([tgt_vocab.idx2char[idx.item()] for idx in tgt_seq[1:] if idx.item() not in [0, 1, 2]])\n",
    "                    if pred_str == tgt_str:\n",
    "                        val_correct += 1\n",
    "                    val_total += 1\n",
    "                break\n",
    "        \n",
    "        # Log metrics to WandB\n",
    "        wandb.log({\n",
    "            \"epoch\": epoch,\n",
    "            \"train_loss\": train_loss / len(train_loader),\n",
    "            \"val_loss\": val_loss / len(val_loader),\n",
    "            \"train_accuracy\": train_correct / train_total,\n",
    "            \"val_accuracy\": val_correct / val_total\n",
    "        })\n",
    "        print(f\"Epoch {epoch+1}, Train Loss: {train_loss / len(train_loader):.4f}, Val Accuracy: {val_correct / val_total:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "70fa268e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T04:03:40.900789Z",
     "iopub.status.busy": "2025-05-18T04:03:40.900540Z",
     "iopub.status.idle": "2025-05-18T04:03:40.904842Z",
     "shell.execute_reply": "2025-05-18T04:03:40.904252Z"
    },
    "papermill": {
     "duration": 0.011056,
     "end_time": "2025-05-18T04:03:40.905886",
     "exception": false,
     "start_time": "2025-05-18T04:03:40.894830",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# WandB sweep configuration\n",
    "sweep_config = {\n",
    "    'method': 'bayes',\n",
    "    'metric': {\n",
    "        'name': 'val_accuracy',\n",
    "        'goal': 'maximize'\n",
    "    },\n",
    "    'parameters': {\n",
    "        'embed_size': {\n",
    "            'values': [32, 64, 128, 256, 512]\n",
    "        },\n",
    "        'hidden_size': {\n",
    "            'values': [32,64,128, 256, 512]\n",
    "        },\n",
    "        'cell_type': {\n",
    "            'values': ['RNN', 'GRU', 'LSTM']\n",
    "        },\n",
    "        'dropout': {\n",
    "            'values': [0.2, 0.3]\n",
    "        },\n",
    "        'beam_width': {\n",
    "            'values': [1, 3, 5]\n",
    "        },\n",
    "        'attention_type': {\n",
    "            'values': ['bahdanau', 'dot']\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "30c52743",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T04:03:40.916962Z",
     "iopub.status.busy": "2025-05-18T04:03:40.916712Z",
     "iopub.status.idle": "2025-05-18T08:33:20.479560Z",
     "shell.execute_reply": "2025-05-18T08:33:20.478806Z"
    },
    "papermill": {
     "duration": 16179.570057,
     "end_time": "2025-05-18T08:33:20.481167",
     "exception": false,
     "start_time": "2025-05-18T04:03:40.911110",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: s529s02o\n",
      "Sweep URL: https://wandb.ai/da24m007-iit-madras/DL-A3/sweeps/s529s02o\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ndehhfij with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_type: dot\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_width: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250518_040342-ndehhfij\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mupbeat-sweep-1\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/sweeps/s529s02o\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/runs/ndehhfij\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 1.9417, Val Accuracy: 0.0000\n",
      "Epoch 2, Train Loss: 1.0029, Val Accuracy: 0.0000\n",
      "Epoch 3, Train Loss: 0.7759, Val Accuracy: 0.0625\n",
      "Epoch 4, Train Loss: 0.6830, Val Accuracy: 0.0938\n",
      "Epoch 5, Train Loss: 0.6258, Val Accuracy: 0.3438\n",
      "Epoch 6, Train Loss: 0.5883, Val Accuracy: 0.3125\n",
      "Epoch 7, Train Loss: 0.5598, Val Accuracy: 0.3125\n",
      "Epoch 8, Train Loss: 0.5348, Val Accuracy: 0.4375\n",
      "Epoch 9, Train Loss: 0.5186, Val Accuracy: 0.5000\n",
      "Epoch 10, Train Loss: 0.5019, Val Accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch ▁▂▃▃▄▅▆▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy ▁▄▄▃▄▅▄▆▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss █▃▂▂▂▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_accuracy ▁▁▂▂▆▅▅▇█▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_loss █▄▃▂▂▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy 0.71875\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss 0.50192\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_accuracy 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_loss 0.84664\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mupbeat-sweep-1\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/runs/ndehhfij\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250518_040342-ndehhfij/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: prtpdtof with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_type: dot\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_width: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: GRU\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250518_041636-prtpdtof\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mhardy-sweep-2\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/sweeps/s529s02o\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/runs/prtpdtof\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 1.3774, Val Accuracy: 0.0625\n",
      "Epoch 2, Train Loss: 0.7113, Val Accuracy: 0.0000\n",
      "Epoch 3, Train Loss: 0.6014, Val Accuracy: 0.4062\n",
      "Epoch 4, Train Loss: 0.5426, Val Accuracy: 0.3750\n",
      "Epoch 5, Train Loss: 0.4985, Val Accuracy: 0.4688\n",
      "Epoch 6, Train Loss: 0.4723, Val Accuracy: 0.2812\n",
      "Epoch 7, Train Loss: 0.4511, Val Accuracy: 0.3125\n",
      "Epoch 8, Train Loss: 0.4286, Val Accuracy: 0.5000\n",
      "Epoch 9, Train Loss: 0.4211, Val Accuracy: 0.2812\n",
      "Epoch 10, Train Loss: 0.4102, Val Accuracy: 0.3125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch ▁▂▃▃▄▅▆▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy ▁▂▃▅▅▅▄█▆▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss █▃▂▂▂▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_accuracy ▂▁▇▆█▅▅█▅▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_loss █▄▃▃▂▁▁▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy 0.53125\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss 0.41022\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_accuracy 0.3125\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_loss 0.78927\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mhardy-sweep-2\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/runs/prtpdtof\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250518_041636-prtpdtof/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 79xhu46u with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_type: dot\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_width: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_size: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250518_042905-79xhu46u\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mexpert-sweep-3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/sweeps/s529s02o\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/runs/79xhu46u\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 1.0524, Val Accuracy: 0.1562\n",
      "Epoch 2, Train Loss: 0.5580, Val Accuracy: 0.2188\n",
      "Epoch 3, Train Loss: 0.4908, Val Accuracy: 0.4375\n",
      "Epoch 4, Train Loss: 0.4558, Val Accuracy: 0.1562\n",
      "Epoch 5, Train Loss: 0.4280, Val Accuracy: 0.4688\n",
      "Epoch 6, Train Loss: 0.4062, Val Accuracy: 0.4375\n",
      "Epoch 7, Train Loss: 0.3875, Val Accuracy: 0.5312\n",
      "Epoch 8, Train Loss: 0.3766, Val Accuracy: 0.2812\n",
      "Epoch 9, Train Loss: 0.3618, Val Accuracy: 0.5000\n",
      "Epoch 10, Train Loss: 0.3479, Val Accuracy: 0.4375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch ▁▂▃▃▄▅▆▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy ▂▂▂▇▁▆▃▇▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss █▃▂▂▂▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_accuracy ▁▂▆▁▇▆█▃▇▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_loss █▄▄▂▃▂▂▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy 0.6875\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss 0.34794\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_accuracy 0.4375\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_loss 0.78692\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mexpert-sweep-3\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/runs/79xhu46u\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250518_042905-79xhu46u/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 7zp2bb3z with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_type: dot\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_width: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_size: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250518_044205-7zp2bb3z\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mcrisp-sweep-4\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/sweeps/s529s02o\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/runs/7zp2bb3z\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 1.4063, Val Accuracy: 0.0000\n",
      "Epoch 2, Train Loss: 0.7766, Val Accuracy: 0.4062\n",
      "Epoch 3, Train Loss: 0.6623, Val Accuracy: 0.5000\n",
      "Epoch 4, Train Loss: 0.5931, Val Accuracy: 0.3438\n",
      "Epoch 5, Train Loss: 0.5499, Val Accuracy: 0.5625\n",
      "Epoch 6, Train Loss: 0.5229, Val Accuracy: 0.3438\n",
      "Epoch 7, Train Loss: 0.5009, Val Accuracy: 0.5625\n",
      "Epoch 8, Train Loss: 0.4865, Val Accuracy: 0.3438\n",
      "Epoch 9, Train Loss: 0.4720, Val Accuracy: 0.4688\n",
      "Epoch 10, Train Loss: 0.4624, Val Accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch ▁▂▃▃▄▅▆▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy ▁▃▃▃▇█▆▇▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss █▃▂▂▂▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_accuracy ▁▆▇▅█▅█▅▇▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_loss █▄▃▂▂▂▂▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy 0.65625\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss 0.46245\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_accuracy 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_loss 0.87912\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mcrisp-sweep-4\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/runs/7zp2bb3z\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250518_044205-7zp2bb3z/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: hn1bcyf4 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_type: dot\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_width: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_size: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250518_045510-hn1bcyf4\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mstellar-sweep-5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/sweeps/s529s02o\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/runs/hn1bcyf4\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 1.3939, Val Accuracy: 0.2500\n",
      "Epoch 2, Train Loss: 0.7360, Val Accuracy: 0.2188\n",
      "Epoch 3, Train Loss: 0.6250, Val Accuracy: 0.3125\n",
      "Epoch 4, Train Loss: 0.5666, Val Accuracy: 0.3750\n",
      "Epoch 5, Train Loss: 0.5319, Val Accuracy: 0.4375\n",
      "Epoch 6, Train Loss: 0.5015, Val Accuracy: 0.5625\n",
      "Epoch 7, Train Loss: 0.4836, Val Accuracy: 0.5625\n",
      "Epoch 8, Train Loss: 0.4688, Val Accuracy: 0.5000\n",
      "Epoch 9, Train Loss: 0.4535, Val Accuracy: 0.5625\n",
      "Epoch 10, Train Loss: 0.4425, Val Accuracy: 0.4688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch ▁▂▃▃▄▅▆▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy ▁▂▂▄█▅▄▅▇▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss █▃▂▂▂▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_accuracy ▂▁▃▄▅██▇█▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_loss █▅▃▂▂▂▂▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy 0.625\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss 0.44248\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_accuracy 0.46875\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_loss 0.83012\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mstellar-sweep-5\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/runs/hn1bcyf4\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250518_045510-hn1bcyf4/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 8ayjlta4 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_type: dot\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_width: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: GRU\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_size: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250518_050824-8ayjlta4\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mcosmic-sweep-6\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/sweeps/s529s02o\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/runs/8ayjlta4\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 1.4529, Val Accuracy: 0.0312\n",
      "Epoch 2, Train Loss: 0.8033, Val Accuracy: 0.2500\n",
      "Epoch 3, Train Loss: 0.7034, Val Accuracy: 0.1562\n",
      "Epoch 4, Train Loss: 0.6513, Val Accuracy: 0.4062\n",
      "Epoch 5, Train Loss: 0.6278, Val Accuracy: 0.3750\n",
      "Epoch 6, Train Loss: 0.6010, Val Accuracy: 0.3750\n",
      "Epoch 7, Train Loss: 0.5895, Val Accuracy: 0.2812\n",
      "Epoch 8, Train Loss: 0.5768, Val Accuracy: 0.3438\n",
      "Epoch 9, Train Loss: 0.5657, Val Accuracy: 0.5625\n",
      "Epoch 10, Train Loss: 0.5554, Val Accuracy: 0.3750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch ▁▂▃▃▄▅▆▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy ▁▅▂▃▃▅▇▂▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss █▃▂▂▂▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_accuracy ▁▄▃▆▆▆▄▅█▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_loss █▄▃▃▂▂▂▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy 0.625\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss 0.55543\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_accuracy 0.375\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_loss 0.90417\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mcosmic-sweep-6\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/runs/8ayjlta4\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250518_050824-8ayjlta4/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 8xbvtxf7 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_type: dot\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_width: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250518_052119-8xbvtxf7\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mdry-sweep-7\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/sweeps/s529s02o\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/runs/8xbvtxf7\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 1.3014, Val Accuracy: 0.1562\n",
      "Epoch 2, Train Loss: 0.6427, Val Accuracy: 0.3438\n",
      "Epoch 3, Train Loss: 0.5435, Val Accuracy: 0.5000\n",
      "Epoch 4, Train Loss: 0.5015, Val Accuracy: 0.5938\n",
      "Epoch 5, Train Loss: 0.4683, Val Accuracy: 0.4688\n",
      "Epoch 6, Train Loss: 0.4452, Val Accuracy: 0.3125\n",
      "Epoch 7, Train Loss: 0.4239, Val Accuracy: 0.4062\n",
      "Epoch 8, Train Loss: 0.4083, Val Accuracy: 0.4062\n",
      "Epoch 9, Train Loss: 0.3961, Val Accuracy: 0.5000\n",
      "Epoch 10, Train Loss: 0.3861, Val Accuracy: 0.5625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch ▁▂▃▃▄▅▆▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy ▁▄▇▅▇▅▄▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss █▃▂▂▂▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_accuracy ▁▄▇█▆▃▅▅▇▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_loss █▄▃▄▂▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy 0.5625\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss 0.38613\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_accuracy 0.5625\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_loss 0.78767\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mdry-sweep-7\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/runs/8xbvtxf7\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250518_052119-8xbvtxf7/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: imclnril with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_type: dot\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_width: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_size: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250518_053438-imclnril\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mgentle-sweep-8\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/sweeps/s529s02o\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/runs/imclnril\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 1.4484, Val Accuracy: 0.0000\n",
      "Epoch 2, Train Loss: 0.7988, Val Accuracy: 0.3125\n",
      "Epoch 3, Train Loss: 0.6423, Val Accuracy: 0.3125\n",
      "Epoch 4, Train Loss: 0.5751, Val Accuracy: 0.2500\n",
      "Epoch 5, Train Loss: 0.5425, Val Accuracy: 0.5000\n",
      "Epoch 6, Train Loss: 0.5168, Val Accuracy: 0.4062\n",
      "Epoch 7, Train Loss: 0.4980, Val Accuracy: 0.3750\n",
      "Epoch 8, Train Loss: 0.4809, Val Accuracy: 0.2188\n",
      "Epoch 9, Train Loss: 0.4676, Val Accuracy: 0.4062\n",
      "Epoch 10, Train Loss: 0.4593, Val Accuracy: 0.3438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch ▁▂▃▃▄▅▆▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy ▁▅▅▄█▇▅▇▆▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss █▃▂▂▂▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_accuracy ▁▅▅▅█▇▆▄▇▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_loss █▄▃▂▂▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy 0.46875\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss 0.4593\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_accuracy 0.34375\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_loss 0.83213\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mgentle-sweep-8\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/runs/imclnril\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250518_053438-imclnril/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 71ui80nh with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_type: dot\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_width: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250518_054758-71ui80nh\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mstoic-sweep-9\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/sweeps/s529s02o\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/runs/71ui80nh\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 0.9885, Val Accuracy: 0.3750\n",
      "Epoch 2, Train Loss: 0.4921, Val Accuracy: 0.2812\n",
      "Epoch 3, Train Loss: 0.4329, Val Accuracy: 0.5312\n",
      "Epoch 4, Train Loss: 0.3921, Val Accuracy: 0.4375\n",
      "Epoch 5, Train Loss: 0.3677, Val Accuracy: 0.5000\n",
      "Epoch 6, Train Loss: 0.3469, Val Accuracy: 0.5000\n",
      "Epoch 7, Train Loss: 0.3298, Val Accuracy: 0.4375\n",
      "Epoch 8, Train Loss: 0.3156, Val Accuracy: 0.5000\n",
      "Epoch 9, Train Loss: 0.3047, Val Accuracy: 0.5312\n",
      "Epoch 10, Train Loss: 0.2927, Val Accuracy: 0.5625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch ▁▂▃▃▄▅▆▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy ▁▂▃▆▇▄▆█▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss █▃▂▂▂▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_accuracy ▃▁▇▅▆▆▅▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_loss █▃▁▁▁▂▄▁▂▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy 0.6875\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss 0.29275\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_accuracy 0.5625\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_loss 0.77141\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mstoic-sweep-9\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/runs/71ui80nh\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250518_054758-71ui80nh/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ue0fzfas with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_type: dot\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_width: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250518_060118-ue0fzfas\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33msweet-sweep-10\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/sweeps/s529s02o\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/runs/ue0fzfas\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 0.9972, Val Accuracy: 0.3438\n",
      "Epoch 2, Train Loss: 0.5064, Val Accuracy: 0.2812\n",
      "Epoch 3, Train Loss: 0.4389, Val Accuracy: 0.5000\n",
      "Epoch 4, Train Loss: 0.3996, Val Accuracy: 0.3750\n",
      "Epoch 5, Train Loss: 0.3735, Val Accuracy: 0.4375\n",
      "Epoch 6, Train Loss: 0.3517, Val Accuracy: 0.5625\n",
      "Epoch 7, Train Loss: 0.3365, Val Accuracy: 0.5312\n",
      "Epoch 8, Train Loss: 0.3168, Val Accuracy: 0.5625\n",
      "Epoch 9, Train Loss: 0.3061, Val Accuracy: 0.5625\n",
      "Epoch 10, Train Loss: 0.2975, Val Accuracy: 0.6250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch ▁▂▃▃▄▅▆▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy ▁▇▁▇▆▅▆▃▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss █▃▂▂▂▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_accuracy ▂▁▅▃▄▇▆▇▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_loss █▅▃▂▂▂▃▁▃▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy 0.75\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss 0.29747\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_accuracy 0.625\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_loss 0.79204\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33msweet-sweep-10\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/runs/ue0fzfas\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250518_060118-ue0fzfas/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: fierdzb8 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_type: dot\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_width: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250518_061447-fierdzb8\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mtrue-sweep-11\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/sweeps/s529s02o\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/runs/fierdzb8\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 0.8407, Val Accuracy: 0.2188\n",
      "Epoch 2, Train Loss: 0.4628, Val Accuracy: 0.5625\n",
      "Epoch 3, Train Loss: 0.3982, Val Accuracy: 0.5625\n",
      "Epoch 4, Train Loss: 0.3607, Val Accuracy: 0.5312\n",
      "Epoch 5, Train Loss: 0.3329, Val Accuracy: 0.5625\n",
      "Epoch 6, Train Loss: 0.3097, Val Accuracy: 0.5938\n",
      "Epoch 7, Train Loss: 0.2844, Val Accuracy: 0.5625\n",
      "Epoch 8, Train Loss: 0.2721, Val Accuracy: 0.5000\n",
      "Epoch 9, Train Loss: 0.2571, Val Accuracy: 0.6250\n",
      "Epoch 10, Train Loss: 0.2448, Val Accuracy: 0.4062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch ▁▂▃▃▄▅▆▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy ▁▆█▇▇▅▇▇▆▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss █▄▃▂▂▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_accuracy ▁▇▇▆▇▇▇▆█▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_loss █▅▃▂▁▂▂▁▅▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy 0.65625\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss 0.24484\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_accuracy 0.40625\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_loss 0.78828\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mtrue-sweep-11\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/runs/fierdzb8\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250518_061447-fierdzb8/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: aj7mid6r with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_type: dot\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_width: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_size: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250518_062842-aj7mid6r\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mhardy-sweep-12\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/sweeps/s529s02o\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/runs/aj7mid6r\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 1.0872, Val Accuracy: 0.3125\n",
      "Epoch 2, Train Loss: 0.5579, Val Accuracy: 0.4688\n",
      "Epoch 3, Train Loss: 0.4928, Val Accuracy: 0.3750\n",
      "Epoch 4, Train Loss: 0.4538, Val Accuracy: 0.4688\n",
      "Epoch 5, Train Loss: 0.4305, Val Accuracy: 0.5938\n",
      "Epoch 6, Train Loss: 0.4087, Val Accuracy: 0.5000\n",
      "Epoch 7, Train Loss: 0.3938, Val Accuracy: 0.5312\n",
      "Epoch 8, Train Loss: 0.3797, Val Accuracy: 0.5938\n",
      "Epoch 9, Train Loss: 0.3627, Val Accuracy: 0.5625\n",
      "Epoch 10, Train Loss: 0.3519, Val Accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch ▁▂▃▃▄▅▆▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy ▁▂▅▆▆▅█▇▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss █▃▂▂▂▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_accuracy ▁▅▃▅█▆▆█▇▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_loss █▅▅▄▃▂▁▁▂▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy 0.75\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss 0.35192\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_accuracy 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_loss 0.80089\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mhardy-sweep-12\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/runs/aj7mid6r\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250518_062842-aj7mid6r/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: g7mhv3af with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_type: dot\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_width: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250518_064236-g7mhv3af\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mjolly-sweep-13\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/sweeps/s529s02o\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/runs/g7mhv3af\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 0.9908, Val Accuracy: 0.4375\n",
      "Epoch 2, Train Loss: 0.5146, Val Accuracy: 0.5312\n",
      "Epoch 3, Train Loss: 0.4436, Val Accuracy: 0.5000\n",
      "Epoch 4, Train Loss: 0.4025, Val Accuracy: 0.5625\n",
      "Epoch 5, Train Loss: 0.3765, Val Accuracy: 0.3438\n",
      "Epoch 6, Train Loss: 0.3552, Val Accuracy: 0.5625\n",
      "Epoch 7, Train Loss: 0.3413, Val Accuracy: 0.5938\n",
      "Epoch 8, Train Loss: 0.3257, Val Accuracy: 0.5625\n",
      "Epoch 9, Train Loss: 0.3130, Val Accuracy: 0.5000\n",
      "Epoch 10, Train Loss: 0.3026, Val Accuracy: 0.5938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch ▁▂▃▃▄▅▆▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy ▂▃▂▆▅▅▅▁▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss █▃▂▂▂▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_accuracy ▄▆▅▇▁▇█▇▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_loss █▃▂▂▂▁▂▃▃▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy 0.78125\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss 0.30263\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_accuracy 0.59375\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_loss 0.78277\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mjolly-sweep-13\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/runs/g7mhv3af\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250518_064236-g7mhv3af/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: xoxzv56w with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_type: dot\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_width: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250518_065622-xoxzv56w\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mswift-sweep-14\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/sweeps/s529s02o\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/runs/xoxzv56w\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 1.2631, Val Accuracy: 0.1562\n",
      "Epoch 2, Train Loss: 0.6452, Val Accuracy: 0.3125\n",
      "Epoch 3, Train Loss: 0.5408, Val Accuracy: 0.3750\n",
      "Epoch 4, Train Loss: 0.5087, Val Accuracy: 0.5312\n",
      "Epoch 5, Train Loss: 0.4685, Val Accuracy: 0.5625\n",
      "Epoch 6, Train Loss: 0.4440, Val Accuracy: 0.4688\n",
      "Epoch 7, Train Loss: 0.4244, Val Accuracy: 0.4062\n",
      "Epoch 8, Train Loss: 0.4104, Val Accuracy: 0.5625\n",
      "Epoch 9, Train Loss: 0.3983, Val Accuracy: 0.5625\n",
      "Epoch 10, Train Loss: 0.3840, Val Accuracy: 0.5625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch ▁▂▃▃▄▅▆▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy ▁▂▆▅▆▇▇▅▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss █▃▂▂▂▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_accuracy ▁▄▅▇█▆▅███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_loss █▄▃▃▂▂▂▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy 0.625\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss 0.38402\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_accuracy 0.5625\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_loss 0.79107\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mswift-sweep-14\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/runs/xoxzv56w\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250518_065622-xoxzv56w/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: edcbxgex with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_type: dot\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_width: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250518_071007-edcbxgex\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mdecent-sweep-15\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/sweeps/s529s02o\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/runs/edcbxgex\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 0.9964, Val Accuracy: 0.3750\n",
      "Epoch 2, Train Loss: 0.5017, Val Accuracy: 0.5312\n",
      "Epoch 3, Train Loss: 0.4402, Val Accuracy: 0.5000\n",
      "Epoch 4, Train Loss: 0.4036, Val Accuracy: 0.5312\n",
      "Epoch 5, Train Loss: 0.3756, Val Accuracy: 0.5938\n",
      "Epoch 6, Train Loss: 0.3543, Val Accuracy: 0.5000\n",
      "Epoch 7, Train Loss: 0.3385, Val Accuracy: 0.6250\n",
      "Epoch 8, Train Loss: 0.3246, Val Accuracy: 0.5938\n",
      "Epoch 9, Train Loss: 0.3118, Val Accuracy: 0.5000\n",
      "Epoch 10, Train Loss: 0.3004, Val Accuracy: 0.5312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch ▁▂▃▃▄▅▆▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy ▄▅▁▅▃▆█▅▇▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss █▃▂▂▂▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_accuracy ▁▅▅▅▇▅█▇▅▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_loss █▄▁▁▃▃▂▃▃▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy 0.53125\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss 0.30036\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_accuracy 0.53125\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_loss 0.7586\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mdecent-sweep-15\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/runs/edcbxgex\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250518_071007-edcbxgex/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: g6lq4ahh with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_type: dot\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_width: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250518_072336-g6lq4ahh\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mcelestial-sweep-16\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/sweeps/s529s02o\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/runs/g6lq4ahh\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 1.0009, Val Accuracy: 0.4062\n",
      "Epoch 2, Train Loss: 0.4908, Val Accuracy: 0.3438\n",
      "Epoch 3, Train Loss: 0.4163, Val Accuracy: 0.5312\n",
      "Epoch 4, Train Loss: 0.3795, Val Accuracy: 0.5625\n",
      "Epoch 5, Train Loss: 0.3519, Val Accuracy: 0.5000\n",
      "Epoch 6, Train Loss: 0.3262, Val Accuracy: 0.5000\n",
      "Epoch 7, Train Loss: 0.3095, Val Accuracy: 0.4375\n",
      "Epoch 8, Train Loss: 0.2944, Val Accuracy: 0.3438\n",
      "Epoch 9, Train Loss: 0.2844, Val Accuracy: 0.4375\n",
      "Epoch 10, Train Loss: 0.2702, Val Accuracy: 0.4375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch ▁▂▃▃▄▅▆▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy ▅▁▂▅▆▅█▇▆▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss █▃▂▂▂▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_accuracy ▃▁▇█▆▆▄▁▄▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_loss █▄▂▂▂▃▂▃▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy 0.625\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss 0.27017\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_accuracy 0.4375\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_loss 0.7638\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mcelestial-sweep-16\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/runs/g6lq4ahh\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250518_072336-g6lq4ahh/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: rhpfs5jm with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_type: dot\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_width: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250518_073706-rhpfs5jm\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mkind-sweep-17\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/sweeps/s529s02o\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/runs/rhpfs5jm\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 0.8171, Val Accuracy: 0.4688\n",
      "Epoch 2, Train Loss: 0.4474, Val Accuracy: 0.5000\n",
      "Epoch 3, Train Loss: 0.3834, Val Accuracy: 0.5625\n",
      "Epoch 4, Train Loss: 0.3513, Val Accuracy: 0.5625\n",
      "Epoch 5, Train Loss: 0.3185, Val Accuracy: 0.3125\n",
      "Epoch 6, Train Loss: 0.2970, Val Accuracy: 0.5938\n",
      "Epoch 7, Train Loss: 0.2807, Val Accuracy: 0.5625\n",
      "Epoch 8, Train Loss: 0.2603, Val Accuracy: 0.5312\n",
      "Epoch 9, Train Loss: 0.2464, Val Accuracy: 0.5938\n",
      "Epoch 10, Train Loss: 0.2319, Val Accuracy: 0.6250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch ▁▂▃▃▄▅▆▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy ▃▁▅▄▅▇▆▃█▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss █▄▃▂▂▂▂▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_accuracy ▅▅▇▇▁▇▇▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_loss ▅▄▁▁▃▂▆▄▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy 0.78125\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss 0.23193\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_accuracy 0.625\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_loss 0.83749\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mkind-sweep-17\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/runs/rhpfs5jm\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250518_073706-rhpfs5jm/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 0dne2rf3 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_type: dot\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_width: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_size: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250518_075107-0dne2rf3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mdifferent-sweep-18\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/sweeps/s529s02o\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/runs/0dne2rf3\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 1.4289, Val Accuracy: 0.1875\n",
      "Epoch 2, Train Loss: 0.7211, Val Accuracy: 0.3438\n",
      "Epoch 3, Train Loss: 0.6044, Val Accuracy: 0.4062\n",
      "Epoch 4, Train Loss: 0.5510, Val Accuracy: 0.4062\n",
      "Epoch 5, Train Loss: 0.5172, Val Accuracy: 0.5938\n",
      "Epoch 6, Train Loss: 0.4899, Val Accuracy: 0.5625\n",
      "Epoch 7, Train Loss: 0.4723, Val Accuracy: 0.5625\n",
      "Epoch 8, Train Loss: 0.4558, Val Accuracy: 0.4375\n",
      "Epoch 9, Train Loss: 0.4410, Val Accuracy: 0.4375\n",
      "Epoch 10, Train Loss: 0.4296, Val Accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch ▁▂▃▃▄▅▆▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy ▁▇▃▄▇▇▇▆▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss █▃▂▂▂▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_accuracy ▁▄▅▅█▇▇▅▅▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_loss █▃▃▂▁▂▂▁▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy 0.65625\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss 0.42962\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_accuracy 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_loss 0.81835\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mdifferent-sweep-18\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/runs/0dne2rf3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250518_075107-0dne2rf3/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: mb3i7gl9 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_type: dot\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_width: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250518_080446-mb3i7gl9\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfloral-sweep-19\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/sweeps/s529s02o\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/runs/mb3i7gl9\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 0.7661, Val Accuracy: 0.3750\n",
      "Epoch 2, Train Loss: 0.4244, Val Accuracy: 0.3125\n",
      "Epoch 3, Train Loss: 0.3625, Val Accuracy: 0.5625\n",
      "Epoch 4, Train Loss: 0.3157, Val Accuracy: 0.4375\n",
      "Epoch 5, Train Loss: 0.2905, Val Accuracy: 0.5000\n",
      "Epoch 6, Train Loss: 0.2595, Val Accuracy: 0.4688\n",
      "Epoch 7, Train Loss: 0.2402, Val Accuracy: 0.6250\n",
      "Epoch 8, Train Loss: 0.2265, Val Accuracy: 0.6250\n",
      "Epoch 9, Train Loss: 0.2073, Val Accuracy: 0.5938\n",
      "Epoch 10, Train Loss: 0.1969, Val Accuracy: 0.6250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch ▁▂▃▃▄▅▆▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy ▂▁▃▄▅▆█▅▆▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss █▄▃▂▂▂▂▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_accuracy ▂▁▇▄▅▅██▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_loss █▂▅▆▁▁▁█▆▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy 0.71875\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss 0.19693\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_accuracy 0.625\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_loss 0.81036\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mfloral-sweep-19\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/runs/mb3i7gl9\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250518_080446-mb3i7gl9/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: jp9b1uj4 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_type: dot\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_width: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250518_081907-jp9b1uj4\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mworldly-sweep-20\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/sweeps/s529s02o\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/runs/jp9b1uj4\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 0.7828, Val Accuracy: 0.2812\n",
      "Epoch 2, Train Loss: 0.4205, Val Accuracy: 0.5625\n",
      "Epoch 3, Train Loss: 0.3484, Val Accuracy: 0.4062\n",
      "Epoch 4, Train Loss: 0.3108, Val Accuracy: 0.5000\n",
      "Epoch 5, Train Loss: 0.2833, Val Accuracy: 0.5625\n",
      "Epoch 6, Train Loss: 0.2565, Val Accuracy: 0.5625\n",
      "Epoch 7, Train Loss: 0.2361, Val Accuracy: 0.5625\n",
      "Epoch 8, Train Loss: 0.2174, Val Accuracy: 0.6250\n",
      "Epoch 9, Train Loss: 0.2008, Val Accuracy: 0.5000\n",
      "Epoch 10, Train Loss: 0.1857, Val Accuracy: 0.5625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch ▁▂▃▃▄▅▆▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy ▁▃▅▄▆▃█▆▄█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss █▄▃▂▂▂▂▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_accuracy ▁▇▄▅▇▇▇█▅▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_loss ▇▂▂▂▂▁▆▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy 0.8125\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss 0.18575\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_accuracy 0.5625\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_loss 0.85792\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mworldly-sweep-20\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/runs/jp9b1uj4\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250518_081907-jp9b1uj4/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Initialize and run sweep\n",
    "sweep_id = wandb.sweep(sweep_config, project=\"DL-A3\")\n",
    "wandb.agent(sweep_id, function=train_and_evaluate, count=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49f3847",
   "metadata": {
    "papermill": {
     "duration": 0.026942,
     "end_time": "2025-05-18T08:33:20.546355",
     "exception": false,
     "start_time": "2025-05-18T08:33:20.519413",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training with best set of hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0a8768fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T08:33:20.603463Z",
     "iopub.status.busy": "2025-05-18T08:33:20.602665Z",
     "iopub.status.idle": "2025-05-18T08:33:21.544388Z",
     "shell.execute_reply": "2025-05-18T08:33:21.543657Z"
    },
    "papermill": {
     "duration": 0.972371,
     "end_time": "2025-05-18T08:33:21.545653",
     "exception": false,
     "start_time": "2025-05-18T08:33:20.573282",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to \u001b[34m\u001b[4mhttps://wandb.me/wandb-init\u001b[0m.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignoring project 'DL-A3' when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250518_083320-jp9b1uj4\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfinal_model_training_with_attention_v2\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/sweeps/s529s02o\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/runs/jp9b1uj4\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/da24m007-iit-madras/DL-A3/runs/jp9b1uj4?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7eb6452ee090>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=\"DL-A3\", name=\"final_model_training_with_attention_v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a80d2faf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T08:33:21.603942Z",
     "iopub.status.busy": "2025-05-18T08:33:21.603281Z",
     "iopub.status.idle": "2025-05-18T08:33:21.608304Z",
     "shell.execute_reply": "2025-05-18T08:33:21.607784Z"
    },
    "papermill": {
     "duration": 0.035735,
     "end_time": "2025-05-18T08:33:21.609321",
     "exception": false,
     "start_time": "2025-05-18T08:33:21.573586",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to retrieve best hyperparameters from WandB sweep\n",
    "def get_best_hyperparameters(project_name=\"DL-A3\"):\n",
    "    api = wandb.Api()\n",
    "    runs = api.runs(project_name)\n",
    "    best_run = None\n",
    "    best_val_accuracy = -float('inf')\n",
    "    \n",
    "    for run in runs:\n",
    "        if 'val_accuracy' in run.summary and run.summary['val_accuracy'] > best_val_accuracy:\n",
    "            best_val_accuracy = run.summary['val_accuracy']\n",
    "            best_run = run\n",
    "    \n",
    "    if best_run is None:\n",
    "        raise ValueError(\"No runs found with val_accuracy in WandB project\")\n",
    "    \n",
    "    # Extract hyperparameters\n",
    "    config = best_run.config\n",
    "    return {\n",
    "            'attention_type': config['attention_type'],\n",
    "                'cell_type': config['cell_type'],\n",
    "                'embed_size': config['embed_size'],\n",
    "                'hidden_size': config['hidden_size'],\n",
    "                'dropout': config['dropout'],\n",
    "                'beam_width': config['beam_width']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "16726e78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T08:33:21.665807Z",
     "iopub.status.busy": "2025-05-18T08:33:21.665399Z",
     "iopub.status.idle": "2025-05-18T08:33:21.677924Z",
     "shell.execute_reply": "2025-05-18T08:33:21.677326Z"
    },
    "papermill": {
     "duration": 0.042624,
     "end_time": "2025-05-18T08:33:21.678995",
     "exception": false,
     "start_time": "2025-05-18T08:33:21.636371",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Training and evaluation function\n",
    "def train_model(model, train_loader, val_loader, test_loader, num_epochs=30, beam_width=3):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for src, tgt in train_loader:\n",
    "            src, tgt = src.to(device), tgt.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(src, tgt, teacher_forcing_ratio=0.5)\n",
    "            output = output[:, 1:].reshape(-1, output.size(-1))\n",
    "            tgt_flat = tgt[:, 1:].reshape(-1)\n",
    "            loss = criterion(output, tgt_flat)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        # Compute validation loss and accuracy (one batch for speed)\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        with torch.no_grad():\n",
    "            for src, tgt in val_loader:\n",
    "                src, tgt = src.to(device), tgt.to(device)\n",
    "                output = model(src, tgt, teacher_forcing_ratio=0.0)\n",
    "                output = output[:, 1:].reshape(-1, output.size(-1))\n",
    "                tgt_flat = tgt[:, 1:].reshape(-1)\n",
    "                loss = criterion(output, tgt_flat)\n",
    "                val_loss += loss.item()\n",
    "                \n",
    "                # Compute accuracy on one batch\n",
    "                print(f\"Epoch {epoch+1}, Validation batch - src shape: {src.shape}, tgt shape: {tgt.shape}\")\n",
    "                for i in range(src.size(0)):\n",
    "                    pred = beam_search_decode(\n",
    "                        model, src[i:i+1], max_len=50,\n",
    "                        beam_width=beam_width,\n",
    "                        sos_idx=tgt_vocab.char2idx['<SOS>'],\n",
    "                        eos_idx=tgt_vocab.char2idx['<EOS>']\n",
    "                    )\n",
    "                    pred_str = ''.join([tgt_vocab.idx2char[idx.item()] for idx in pred if idx.item() not in [0, 1, 2]])\n",
    "                    tgt_seq = tgt[i]\n",
    "                    tgt_str = ''.join([tgt_vocab.idx2char[idx.item()] for idx in tgt_seq[1:] if idx.item() not in [0, 1, 2]])\n",
    "                    if pred_str == tgt_str:\n",
    "                        val_correct += 1\n",
    "                    val_total += 1\n",
    "                break  # Process only one batch for validation accuracy\n",
    "        \n",
    "        # Log metrics to WandB\n",
    "        wandb.log({\n",
    "            \"epoch\": epoch,\n",
    "            \"train_loss\": train_loss / len(train_loader),\n",
    "            \"val_loss\": val_loss / len(val_loader),\n",
    "            \"val_accuracy\": val_correct / val_total\n",
    "        })\n",
    "        print(f\"Epoch {epoch+1}, Train Loss: {train_loss / len(train_loader):.4f}, Val Loss: {val_loss / len(val_loader):.4f}, Val Accuracy: {val_correct / val_total:.4f}\")\n",
    "    \n",
    "    # Compute test accuracy and save predictions\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for src, tgt in test_loader:\n",
    "            src, tgt = src.to(device), tgt.to(device)\n",
    "            print(f\"Test batch - src shape: {src.shape}, tgt shape: {tgt.shape}\")\n",
    "            for i in range(src.size(0)):\n",
    "                pred = beam_search_decode(\n",
    "                    model, src[i:i+1], max_len=50,\n",
    "                    beam_width=beam_width,\n",
    "                    sos_idx=tgt_vocab.char2idx['<SOS>'],\n",
    "                    eos_idx=tgt_vocab.char2idx['<EOS>']\n",
    "                )\n",
    "                pred_str = ''.join([tgt_vocab.idx2char[idx.item()] for idx in pred if idx.item() not in [0, 1, 2]])\n",
    "                tgt_seq = tgt[i]\n",
    "                tgt_str = ''.join([tgt_vocab.idx2char[idx.item()] for idx in tgt_seq[1:] if idx.item() not in [0, 1, 2]])\n",
    "                src_str = ''.join([src_vocab.idx2char[idx.item()] for idx in src[i, 1:] if idx.item() not in [0, 1, 2]])\n",
    "                if pred_str == tgt_str:\n",
    "                    test_correct += 1\n",
    "                test_total += 1\n",
    "                predictions.append({\n",
    "                    'input_english': src_str,\n",
    "                    'actual_tamil': tgt_str,\n",
    "                    'predicted_tamil': pred_str\n",
    "                })\n",
    "    \n",
    "    test_accuracy = test_correct / test_total\n",
    "    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "    \n",
    "    # Save predictions to CSV\n",
    "    predictions_df = pd.DataFrame(predictions)\n",
    "    predictions_df.to_csv('test_predictions_attention.csv', index=False)\n",
    "    print(\"Test predictions saved to 'test_predictions.csv'\")\n",
    "    \n",
    "    return test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "24eea20c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T08:33:21.734404Z",
     "iopub.status.busy": "2025-05-18T08:33:21.733928Z",
     "iopub.status.idle": "2025-05-18T08:33:24.933691Z",
     "shell.execute_reply": "2025-05-18T08:33:24.932956Z"
    },
    "papermill": {
     "duration": 3.228558,
     "end_time": "2025-05-18T08:33:24.934908",
     "exception": false,
     "start_time": "2025-05-18T08:33:21.706350",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters from WandB sweep: {'attention_type': 'bahdanau', 'cell_type': 'GRU', 'embed_size': 128, 'hidden_size': 128, 'dropout': 0.2, 'beam_width': 5}\n"
     ]
    }
   ],
   "source": [
    "# Get best hyperparameters\n",
    "try:\n",
    "    best_params = get_best_hyperparameters()\n",
    "    print(\"Best hyperparameters from WandB sweep:\", best_params)\n",
    "except Exception as e:\n",
    "    print(f\"Error retrieving hyperparameters: {e}\")\n",
    "    print(\"Using default hyperparameters as fallback\")\n",
    "    best_params = {\n",
    "        'embed_size': 256,\n",
    "        'hidden_size': 512,\n",
    "        'cell_type': 'LSTM',\n",
    "        'encoder_layers': 2,\n",
    "        'decoder_layers': 1,\n",
    "        'dropout': 0.2,\n",
    "        'beam_width': 5\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ce6a6a57",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T08:33:24.990713Z",
     "iopub.status.busy": "2025-05-18T08:33:24.990510Z",
     "iopub.status.idle": "2025-05-18T08:33:24.999662Z",
     "shell.execute_reply": "2025-05-18T08:33:24.999171Z"
    },
    "papermill": {
     "duration": 0.037862,
     "end_time": "2025-05-18T08:33:25.000686",
     "exception": false,
     "start_time": "2025-05-18T08:33:24.962824",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create model with best parameters\n",
    "model = create_model(\n",
    "    input_vocab_size=src_vocab.size,\n",
    "    output_vocab_size=tgt_vocab.size,\n",
    "    embed_size=best_params['embed_size'],\n",
    "    hidden_size=best_params['hidden_size'],\n",
    "    cell_type=best_params['cell_type'],\n",
    "    encoder_layers=1,\n",
    "    decoder_layers=1,\n",
    "    dropout=best_params['dropout']\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "995ff81f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T08:33:25.054530Z",
     "iopub.status.busy": "2025-05-18T08:33:25.053971Z",
     "iopub.status.idle": "2025-05-18T08:33:25.058229Z",
     "shell.execute_reply": "2025-05-18T08:33:25.057704Z"
    },
    "papermill": {
     "duration": 0.032019,
     "end_time": "2025-05-18T08:33:25.059236",
     "exception": false,
     "start_time": "2025-05-18T08:33:25.027217",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): EncoderRNN(\n",
       "    (embedding): Embedding(30, 128)\n",
       "    (rnn): GRU(128, 128, batch_first=True)\n",
       "  )\n",
       "  (decoder): DecoderRNN(\n",
       "    (embedding): Embedding(50, 128)\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "    (rnn): GRU(256, 128, batch_first=True)\n",
       "    (attention): Attention(\n",
       "      (Wa): Linear(in_features=256, out_features=128, bias=True)\n",
       "      (Ua): Linear(in_features=128, out_features=1, bias=False)\n",
       "    )\n",
       "    (out): Linear(in_features=256, out_features=50, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f90f5840",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T08:33:25.113258Z",
     "iopub.status.busy": "2025-05-18T08:33:25.113081Z",
     "iopub.status.idle": "2025-05-18T09:22:44.805093Z",
     "shell.execute_reply": "2025-05-18T09:22:44.804283Z"
    },
    "papermill": {
     "duration": 2959.720407,
     "end_time": "2025-05-18T09:22:44.806301",
     "exception": false,
     "start_time": "2025-05-18T08:33:25.085894",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Validation batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 15])\n",
      "Epoch 1, Train Loss: 0.7498, Val Loss: 0.0053, Val Accuracy: 0.5625\n",
      "Epoch 2, Validation batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 15])\n",
      "Epoch 2, Train Loss: 0.4024, Val Loss: 0.0053, Val Accuracy: 0.5625\n",
      "Epoch 3, Validation batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 15])\n",
      "Epoch 3, Train Loss: 0.3530, Val Loss: 0.0052, Val Accuracy: 0.3438\n",
      "Epoch 4, Validation batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 15])\n",
      "Epoch 4, Train Loss: 0.3192, Val Loss: 0.0056, Val Accuracy: 0.5938\n",
      "Epoch 5, Validation batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 15])\n",
      "Epoch 5, Train Loss: 0.2953, Val Loss: 0.0055, Val Accuracy: 0.6562\n",
      "Epoch 6, Validation batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 15])\n",
      "Epoch 6, Train Loss: 0.2780, Val Loss: 0.0055, Val Accuracy: 0.5938\n",
      "Epoch 7, Validation batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 15])\n",
      "Epoch 7, Train Loss: 0.2615, Val Loss: 0.0057, Val Accuracy: 0.6562\n",
      "Epoch 8, Validation batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 15])\n",
      "Epoch 8, Train Loss: 0.2544, Val Loss: 0.0058, Val Accuracy: 0.6562\n",
      "Epoch 9, Validation batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 15])\n",
      "Epoch 9, Train Loss: 0.2405, Val Loss: 0.0057, Val Accuracy: 0.5312\n",
      "Epoch 10, Validation batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 15])\n",
      "Epoch 10, Train Loss: 0.2368, Val Loss: 0.0068, Val Accuracy: 0.5938\n",
      "Epoch 11, Validation batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 15])\n",
      "Epoch 11, Train Loss: 0.2267, Val Loss: 0.0064, Val Accuracy: 0.6250\n",
      "Epoch 12, Validation batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 15])\n",
      "Epoch 12, Train Loss: 0.2209, Val Loss: 0.0062, Val Accuracy: 0.5938\n",
      "Epoch 13, Validation batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 15])\n",
      "Epoch 13, Train Loss: 0.2135, Val Loss: 0.0063, Val Accuracy: 0.6875\n",
      "Epoch 14, Validation batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 15])\n",
      "Epoch 14, Train Loss: 0.2078, Val Loss: 0.0071, Val Accuracy: 0.6250\n",
      "Epoch 15, Validation batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 15])\n",
      "Epoch 15, Train Loss: 0.2025, Val Loss: 0.0056, Val Accuracy: 0.5938\n",
      "Epoch 16, Validation batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 15])\n",
      "Epoch 16, Train Loss: 0.2001, Val Loss: 0.0062, Val Accuracy: 0.6562\n",
      "Epoch 17, Validation batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 15])\n",
      "Epoch 17, Train Loss: 0.1932, Val Loss: 0.0067, Val Accuracy: 0.6250\n",
      "Epoch 18, Validation batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 15])\n",
      "Epoch 18, Train Loss: 0.1914, Val Loss: 0.0060, Val Accuracy: 0.6562\n",
      "Epoch 19, Validation batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 15])\n",
      "Epoch 19, Train Loss: 0.1861, Val Loss: 0.0056, Val Accuracy: 0.6250\n",
      "Epoch 20, Validation batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 15])\n",
      "Epoch 20, Train Loss: 0.1859, Val Loss: 0.0064, Val Accuracy: 0.5938\n",
      "Epoch 21, Validation batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 15])\n",
      "Epoch 21, Train Loss: 0.1820, Val Loss: 0.0064, Val Accuracy: 0.6250\n",
      "Epoch 22, Validation batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 15])\n",
      "Epoch 22, Train Loss: 0.1789, Val Loss: 0.0075, Val Accuracy: 0.5938\n",
      "Epoch 23, Validation batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 15])\n",
      "Epoch 23, Train Loss: 0.1786, Val Loss: 0.0064, Val Accuracy: 0.6250\n",
      "Epoch 24, Validation batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 15])\n",
      "Epoch 24, Train Loss: 0.1752, Val Loss: 0.0068, Val Accuracy: 0.5625\n",
      "Epoch 25, Validation batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 15])\n",
      "Epoch 25, Train Loss: 0.1734, Val Loss: 0.0065, Val Accuracy: 0.6562\n",
      "Epoch 26, Validation batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 15])\n",
      "Epoch 26, Train Loss: 0.1724, Val Loss: 0.0074, Val Accuracy: 0.5625\n",
      "Epoch 27, Validation batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 15])\n",
      "Epoch 27, Train Loss: 0.1716, Val Loss: 0.0063, Val Accuracy: 0.6250\n",
      "Epoch 28, Validation batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 15])\n",
      "Epoch 28, Train Loss: 0.1689, Val Loss: 0.0065, Val Accuracy: 0.6562\n",
      "Epoch 29, Validation batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 15])\n",
      "Epoch 29, Train Loss: 0.1640, Val Loss: 0.0068, Val Accuracy: 0.6250\n",
      "Epoch 30, Validation batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 15])\n",
      "Epoch 30, Train Loss: 0.1638, Val Loss: 0.0070, Val Accuracy: 0.6250\n",
      "Test batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 15])\n",
      "Test batch - src shape: torch.Size([32, 23]), tgt shape: torch.Size([32, 19])\n",
      "Test batch - src shape: torch.Size([32, 15]), tgt shape: torch.Size([32, 15])\n",
      "Test batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 17])\n",
      "Test batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 17])\n",
      "Test batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 17])\n",
      "Test batch - src shape: torch.Size([32, 21]), tgt shape: torch.Size([32, 17])\n",
      "Test batch - src shape: torch.Size([32, 18]), tgt shape: torch.Size([32, 19])\n",
      "Test batch - src shape: torch.Size([32, 16]), tgt shape: torch.Size([32, 17])\n",
      "Test batch - src shape: torch.Size([32, 16]), tgt shape: torch.Size([32, 17])\n",
      "Test batch - src shape: torch.Size([32, 17]), tgt shape: torch.Size([32, 14])\n",
      "Test batch - src shape: torch.Size([32, 17]), tgt shape: torch.Size([32, 12])\n",
      "Test batch - src shape: torch.Size([32, 18]), tgt shape: torch.Size([32, 14])\n",
      "Test batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 15])\n",
      "Test batch - src shape: torch.Size([32, 18]), tgt shape: torch.Size([32, 15])\n",
      "Test batch - src shape: torch.Size([32, 18]), tgt shape: torch.Size([32, 15])\n",
      "Test batch - src shape: torch.Size([32, 18]), tgt shape: torch.Size([32, 19])\n",
      "Test batch - src shape: torch.Size([32, 17]), tgt shape: torch.Size([32, 16])\n",
      "Test batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 19])\n",
      "Test batch - src shape: torch.Size([32, 16]), tgt shape: torch.Size([32, 13])\n",
      "Test batch - src shape: torch.Size([32, 21]), tgt shape: torch.Size([32, 16])\n",
      "Test batch - src shape: torch.Size([32, 22]), tgt shape: torch.Size([32, 19])\n",
      "Test batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 17])\n",
      "Test batch - src shape: torch.Size([32, 14]), tgt shape: torch.Size([32, 13])\n",
      "Test batch - src shape: torch.Size([32, 16]), tgt shape: torch.Size([32, 14])\n",
      "Test batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 17])\n",
      "Test batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 14])\n",
      "Test batch - src shape: torch.Size([32, 14]), tgt shape: torch.Size([32, 13])\n",
      "Test batch - src shape: torch.Size([32, 15]), tgt shape: torch.Size([32, 14])\n",
      "Test batch - src shape: torch.Size([32, 14]), tgt shape: torch.Size([32, 13])\n",
      "Test batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 18])\n",
      "Test batch - src shape: torch.Size([32, 17]), tgt shape: torch.Size([32, 18])\n",
      "Test batch - src shape: torch.Size([32, 14]), tgt shape: torch.Size([32, 14])\n",
      "Test batch - src shape: torch.Size([32, 18]), tgt shape: torch.Size([32, 17])\n",
      "Test batch - src shape: torch.Size([32, 17]), tgt shape: torch.Size([32, 18])\n",
      "Test batch - src shape: torch.Size([32, 14]), tgt shape: torch.Size([32, 15])\n",
      "Test batch - src shape: torch.Size([32, 17]), tgt shape: torch.Size([32, 16])\n",
      "Test batch - src shape: torch.Size([32, 18]), tgt shape: torch.Size([32, 16])\n",
      "Test batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 14])\n",
      "Test batch - src shape: torch.Size([32, 18]), tgt shape: torch.Size([32, 17])\n",
      "Test batch - src shape: torch.Size([32, 18]), tgt shape: torch.Size([32, 17])\n",
      "Test batch - src shape: torch.Size([32, 16]), tgt shape: torch.Size([32, 15])\n",
      "Test batch - src shape: torch.Size([32, 22]), tgt shape: torch.Size([32, 19])\n",
      "Test batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 18])\n",
      "Test batch - src shape: torch.Size([32, 21]), tgt shape: torch.Size([32, 20])\n",
      "Test batch - src shape: torch.Size([32, 21]), tgt shape: torch.Size([32, 18])\n",
      "Test batch - src shape: torch.Size([32, 15]), tgt shape: torch.Size([32, 13])\n",
      "Test batch - src shape: torch.Size([32, 17]), tgt shape: torch.Size([32, 17])\n",
      "Test batch - src shape: torch.Size([32, 22]), tgt shape: torch.Size([32, 21])\n",
      "Test batch - src shape: torch.Size([32, 15]), tgt shape: torch.Size([32, 15])\n",
      "Test batch - src shape: torch.Size([32, 17]), tgt shape: torch.Size([32, 14])\n",
      "Test batch - src shape: torch.Size([32, 21]), tgt shape: torch.Size([32, 16])\n",
      "Test batch - src shape: torch.Size([32, 15]), tgt shape: torch.Size([32, 15])\n",
      "Test batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 17])\n",
      "Test batch - src shape: torch.Size([32, 18]), tgt shape: torch.Size([32, 15])\n",
      "Test batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 16])\n",
      "Test batch - src shape: torch.Size([32, 13]), tgt shape: torch.Size([32, 12])\n",
      "Test batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 17])\n",
      "Test batch - src shape: torch.Size([32, 16]), tgt shape: torch.Size([32, 15])\n",
      "Test batch - src shape: torch.Size([32, 13]), tgt shape: torch.Size([32, 12])\n",
      "Test batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 15])\n",
      "Test batch - src shape: torch.Size([32, 14]), tgt shape: torch.Size([32, 13])\n",
      "Test batch - src shape: torch.Size([32, 13]), tgt shape: torch.Size([32, 11])\n",
      "Test batch - src shape: torch.Size([32, 17]), tgt shape: torch.Size([32, 16])\n",
      "Test batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 20])\n",
      "Test batch - src shape: torch.Size([32, 13]), tgt shape: torch.Size([32, 12])\n",
      "Test batch - src shape: torch.Size([32, 14]), tgt shape: torch.Size([32, 14])\n",
      "Test batch - src shape: torch.Size([32, 10]), tgt shape: torch.Size([32, 11])\n",
      "Test batch - src shape: torch.Size([32, 15]), tgt shape: torch.Size([32, 15])\n",
      "Test batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 20])\n",
      "Test batch - src shape: torch.Size([32, 14]), tgt shape: torch.Size([32, 15])\n",
      "Test batch - src shape: torch.Size([32, 16]), tgt shape: torch.Size([32, 15])\n",
      "Test batch - src shape: torch.Size([32, 9]), tgt shape: torch.Size([32, 8])\n",
      "Test batch - src shape: torch.Size([32, 15]), tgt shape: torch.Size([32, 13])\n",
      "Test batch - src shape: torch.Size([32, 11]), tgt shape: torch.Size([32, 10])\n",
      "Test batch - src shape: torch.Size([32, 12]), tgt shape: torch.Size([32, 10])\n",
      "Test batch - src shape: torch.Size([32, 15]), tgt shape: torch.Size([32, 13])\n",
      "Test batch - src shape: torch.Size([32, 17]), tgt shape: torch.Size([32, 15])\n",
      "Test batch - src shape: torch.Size([32, 16]), tgt shape: torch.Size([32, 14])\n",
      "Test batch - src shape: torch.Size([32, 14]), tgt shape: torch.Size([32, 14])\n",
      "Test batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 13])\n",
      "Test batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 18])\n",
      "Test batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 20])\n",
      "Test batch - src shape: torch.Size([32, 17]), tgt shape: torch.Size([32, 13])\n",
      "Test batch - src shape: torch.Size([32, 12]), tgt shape: torch.Size([32, 12])\n",
      "Test batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 18])\n",
      "Test batch - src shape: torch.Size([32, 16]), tgt shape: torch.Size([32, 16])\n",
      "Test batch - src shape: torch.Size([32, 15]), tgt shape: torch.Size([32, 13])\n",
      "Test batch - src shape: torch.Size([32, 14]), tgt shape: torch.Size([32, 13])\n",
      "Test batch - src shape: torch.Size([32, 14]), tgt shape: torch.Size([32, 10])\n",
      "Test batch - src shape: torch.Size([32, 16]), tgt shape: torch.Size([32, 13])\n",
      "Test batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 18])\n",
      "Test batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 18])\n",
      "Test batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 17])\n",
      "Test batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 18])\n",
      "Test batch - src shape: torch.Size([32, 22]), tgt shape: torch.Size([32, 19])\n",
      "Test batch - src shape: torch.Size([32, 18]), tgt shape: torch.Size([32, 16])\n",
      "Test batch - src shape: torch.Size([32, 16]), tgt shape: torch.Size([32, 17])\n",
      "Test batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 19])\n",
      "Test batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 20])\n",
      "Test batch - src shape: torch.Size([32, 22]), tgt shape: torch.Size([32, 14])\n",
      "Test batch - src shape: torch.Size([32, 14]), tgt shape: torch.Size([32, 14])\n",
      "Test batch - src shape: torch.Size([32, 14]), tgt shape: torch.Size([32, 13])\n",
      "Test batch - src shape: torch.Size([32, 16]), tgt shape: torch.Size([32, 15])\n",
      "Test batch - src shape: torch.Size([32, 17]), tgt shape: torch.Size([32, 14])\n",
      "Test batch - src shape: torch.Size([32, 13]), tgt shape: torch.Size([32, 10])\n",
      "Test batch - src shape: torch.Size([32, 9]), tgt shape: torch.Size([32, 10])\n",
      "Test batch - src shape: torch.Size([32, 11]), tgt shape: torch.Size([32, 10])\n",
      "Test batch - src shape: torch.Size([32, 9]), tgt shape: torch.Size([32, 10])\n",
      "Test batch - src shape: torch.Size([32, 10]), tgt shape: torch.Size([32, 11])\n",
      "Test batch - src shape: torch.Size([32, 13]), tgt shape: torch.Size([32, 13])\n",
      "Test batch - src shape: torch.Size([32, 16]), tgt shape: torch.Size([32, 14])\n",
      "Test batch - src shape: torch.Size([32, 21]), tgt shape: torch.Size([32, 18])\n",
      "Test batch - src shape: torch.Size([32, 21]), tgt shape: torch.Size([32, 17])\n",
      "Test batch - src shape: torch.Size([32, 25]), tgt shape: torch.Size([32, 19])\n",
      "Test batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 15])\n",
      "Test batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 13])\n",
      "Test batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 17])\n",
      "Test batch - src shape: torch.Size([32, 17]), tgt shape: torch.Size([32, 13])\n",
      "Test batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 15])\n",
      "Test batch - src shape: torch.Size([32, 17]), tgt shape: torch.Size([32, 14])\n",
      "Test batch - src shape: torch.Size([32, 21]), tgt shape: torch.Size([32, 19])\n",
      "Test batch - src shape: torch.Size([32, 24]), tgt shape: torch.Size([32, 23])\n",
      "Test batch - src shape: torch.Size([32, 21]), tgt shape: torch.Size([32, 19])\n",
      "Test batch - src shape: torch.Size([32, 16]), tgt shape: torch.Size([32, 15])\n",
      "Test batch - src shape: torch.Size([32, 17]), tgt shape: torch.Size([32, 16])\n",
      "Test batch - src shape: torch.Size([32, 17]), tgt shape: torch.Size([32, 18])\n",
      "Test batch - src shape: torch.Size([32, 16]), tgt shape: torch.Size([32, 14])\n",
      "Test batch - src shape: torch.Size([32, 18]), tgt shape: torch.Size([32, 16])\n",
      "Test batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 16])\n",
      "Test batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 16])\n",
      "Test batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 15])\n",
      "Test batch - src shape: torch.Size([32, 14]), tgt shape: torch.Size([32, 13])\n",
      "Test batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 15])\n",
      "Test batch - src shape: torch.Size([32, 22]), tgt shape: torch.Size([32, 17])\n",
      "Test batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 17])\n",
      "Test batch - src shape: torch.Size([32, 15]), tgt shape: torch.Size([32, 15])\n",
      "Test batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 19])\n",
      "Test batch - src shape: torch.Size([32, 17]), tgt shape: torch.Size([32, 15])\n",
      "Test batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 14])\n",
      "Test batch - src shape: torch.Size([32, 21]), tgt shape: torch.Size([32, 17])\n",
      "Test batch - src shape: torch.Size([32, 14]), tgt shape: torch.Size([32, 14])\n",
      "Test batch - src shape: torch.Size([32, 21]), tgt shape: torch.Size([32, 17])\n",
      "Test batch - src shape: torch.Size([32, 17]), tgt shape: torch.Size([32, 17])\n",
      "Test batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 16])\n",
      "Test batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 12])\n",
      "Test batch - src shape: torch.Size([32, 16]), tgt shape: torch.Size([32, 15])\n",
      "Test batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 19])\n",
      "Test batch - src shape: torch.Size([32, 22]), tgt shape: torch.Size([32, 18])\n",
      "Test batch - src shape: torch.Size([32, 18]), tgt shape: torch.Size([32, 14])\n",
      "Test batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 16])\n",
      "Test batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 16])\n",
      "Test batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 19])\n",
      "Test batch - src shape: torch.Size([32, 14]), tgt shape: torch.Size([32, 11])\n",
      "Test batch - src shape: torch.Size([32, 18]), tgt shape: torch.Size([32, 15])\n",
      "Test batch - src shape: torch.Size([32, 16]), tgt shape: torch.Size([32, 16])\n",
      "Test batch - src shape: torch.Size([32, 21]), tgt shape: torch.Size([32, 13])\n",
      "Test batch - src shape: torch.Size([32, 15]), tgt shape: torch.Size([32, 12])\n",
      "Test batch - src shape: torch.Size([32, 17]), tgt shape: torch.Size([32, 15])\n",
      "Test batch - src shape: torch.Size([32, 18]), tgt shape: torch.Size([32, 16])\n",
      "Test batch - src shape: torch.Size([32, 17]), tgt shape: torch.Size([32, 16])\n",
      "Test batch - src shape: torch.Size([32, 17]), tgt shape: torch.Size([32, 15])\n",
      "Test batch - src shape: torch.Size([32, 18]), tgt shape: torch.Size([32, 16])\n",
      "Test batch - src shape: torch.Size([32, 16]), tgt shape: torch.Size([32, 16])\n",
      "Test batch - src shape: torch.Size([32, 14]), tgt shape: torch.Size([32, 14])\n",
      "Test batch - src shape: torch.Size([32, 17]), tgt shape: torch.Size([32, 14])\n",
      "Test batch - src shape: torch.Size([32, 23]), tgt shape: torch.Size([32, 17])\n",
      "Test batch - src shape: torch.Size([32, 17]), tgt shape: torch.Size([32, 15])\n",
      "Test batch - src shape: torch.Size([32, 23]), tgt shape: torch.Size([32, 24])\n",
      "Test batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 15])\n",
      "Test batch - src shape: torch.Size([32, 18]), tgt shape: torch.Size([32, 16])\n",
      "Test batch - src shape: torch.Size([32, 18]), tgt shape: torch.Size([32, 17])\n",
      "Test batch - src shape: torch.Size([32, 13]), tgt shape: torch.Size([32, 9])\n",
      "Test batch - src shape: torch.Size([32, 15]), tgt shape: torch.Size([32, 12])\n",
      "Test batch - src shape: torch.Size([32, 18]), tgt shape: torch.Size([32, 16])\n",
      "Test batch - src shape: torch.Size([32, 18]), tgt shape: torch.Size([32, 13])\n",
      "Test batch - src shape: torch.Size([32, 23]), tgt shape: torch.Size([32, 18])\n",
      "Test batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 16])\n",
      "Test batch - src shape: torch.Size([32, 22]), tgt shape: torch.Size([32, 17])\n",
      "Test batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 18])\n",
      "Test batch - src shape: torch.Size([32, 16]), tgt shape: torch.Size([32, 14])\n",
      "Test batch - src shape: torch.Size([32, 22]), tgt shape: torch.Size([32, 18])\n",
      "Test batch - src shape: torch.Size([32, 18]), tgt shape: torch.Size([32, 14])\n",
      "Test batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 17])\n",
      "Test batch - src shape: torch.Size([32, 16]), tgt shape: torch.Size([32, 13])\n",
      "Test batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 16])\n",
      "Test batch - src shape: torch.Size([32, 21]), tgt shape: torch.Size([32, 18])\n",
      "Test batch - src shape: torch.Size([32, 16]), tgt shape: torch.Size([32, 15])\n",
      "Test batch - src shape: torch.Size([32, 13]), tgt shape: torch.Size([32, 14])\n",
      "Test batch - src shape: torch.Size([32, 15]), tgt shape: torch.Size([32, 12])\n",
      "Test batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 15])\n",
      "Test batch - src shape: torch.Size([32, 14]), tgt shape: torch.Size([32, 12])\n",
      "Test batch - src shape: torch.Size([32, 11]), tgt shape: torch.Size([32, 9])\n",
      "Test batch - src shape: torch.Size([32, 13]), tgt shape: torch.Size([32, 13])\n",
      "Test batch - src shape: torch.Size([32, 13]), tgt shape: torch.Size([32, 11])\n",
      "Test batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 15])\n",
      "Test batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 15])\n",
      "Test batch - src shape: torch.Size([32, 15]), tgt shape: torch.Size([32, 13])\n",
      "Test batch - src shape: torch.Size([32, 21]), tgt shape: torch.Size([32, 15])\n",
      "Test batch - src shape: torch.Size([32, 21]), tgt shape: torch.Size([32, 17])\n",
      "Test batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 15])\n",
      "Test batch - src shape: torch.Size([32, 14]), tgt shape: torch.Size([32, 13])\n",
      "Test batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 16])\n",
      "Test batch - src shape: torch.Size([32, 21]), tgt shape: torch.Size([32, 17])\n",
      "Test batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 19])\n",
      "Test batch - src shape: torch.Size([32, 13]), tgt shape: torch.Size([32, 13])\n",
      "Test batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 17])\n",
      "Test batch - src shape: torch.Size([32, 24]), tgt shape: torch.Size([32, 20])\n",
      "Test batch - src shape: torch.Size([32, 18]), tgt shape: torch.Size([32, 15])\n",
      "Test batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 16])\n",
      "Test batch - src shape: torch.Size([32, 17]), tgt shape: torch.Size([32, 17])\n",
      "Test batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 16])\n",
      "Test batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 16])\n",
      "Test batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 16])\n",
      "Test batch - src shape: torch.Size([16, 9]), tgt shape: torch.Size([16, 8])\n",
      "Test Accuracy: 0.5233\n",
      "Test predictions saved to 'test_predictions.csv'\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate\n",
    "test_accuracy = train_model(\n",
    "    model, train_loader, val_loader, test_loader,\n",
    "    num_epochs=30, beam_width=best_params['beam_width']\n",
    ")\n",
    "\n",
    "# Log test accuracy to WandB\n",
    "wandb.log({\"test_accuracy\": test_accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397afeb1",
   "metadata": {
    "papermill": {
     "duration": 0.036602,
     "end_time": "2025-05-18T09:22:44.881575",
     "exception": false,
     "start_time": "2025-05-18T09:22:44.844973",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7429459,
     "sourceId": 11826703,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 19168.885753,
   "end_time": "2025-05-18T09:22:49.324061",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-18T04:03:20.438308",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
