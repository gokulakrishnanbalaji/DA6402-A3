{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3d264f3",
   "metadata": {
    "papermill": {
     "duration": 0.005071,
     "end_time": "2025-05-15T17:58:27.111333",
     "exception": false,
     "start_time": "2025-05-15T17:58:27.106262",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Question 5 - Attention Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f3c8f46",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T17:58:27.120386Z",
     "iopub.status.busy": "2025-05-15T17:58:27.120157Z",
     "iopub.status.idle": "2025-05-15T17:58:31.728887Z",
     "shell.execute_reply": "2025-05-15T17:58:31.728340Z"
    },
    "papermill": {
     "duration": 4.614675,
     "end_time": "2025-05-15T17:58:31.730312",
     "exception": false,
     "start_time": "2025-05-15T17:58:27.115637",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfab9ce",
   "metadata": {
    "papermill": {
     "duration": 0.004259,
     "end_time": "2025-05-15T17:58:31.738778",
     "exception": false,
     "start_time": "2025-05-15T17:58:31.734519",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## preparing dataset for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b12c5d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T17:58:31.747873Z",
     "iopub.status.busy": "2025-05-15T17:58:31.747588Z",
     "iopub.status.idle": "2025-05-15T17:58:33.105398Z",
     "shell.execute_reply": "2025-05-15T17:58:33.104833Z"
    },
    "papermill": {
     "duration": 1.363607,
     "end_time": "2025-05-15T17:58:33.106755",
     "exception": false,
     "start_time": "2025-05-15T17:58:31.743148",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import optim\n",
    "from collections import Counter\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29a5514e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T17:58:33.116007Z",
     "iopub.status.busy": "2025-05-15T17:58:33.115700Z",
     "iopub.status.idle": "2025-05-15T17:58:33.120559Z",
     "shell.execute_reply": "2025-05-15T17:58:33.120037Z"
    },
    "papermill": {
     "duration": 0.010561,
     "end_time": "2025-05-15T17:58:33.121575",
     "exception": false,
     "start_time": "2025-05-15T17:58:33.111014",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Vocabulary class to handle character-to-index mapping\n",
    "class Vocabulary:\n",
    "    def __init__(self):\n",
    "        self.char2idx = {'<PAD>': 0, '<SOS>': 1, '<EOS>': 2, '<UNK>': 3}\n",
    "        self.idx2char = {0: '<PAD>', 1: '<SOS>', 2: '<EOS>', 3: '<UNK>'}\n",
    "        self.size = 4\n",
    "\n",
    "    def add_sequence(self, sequence):\n",
    "        for char in sequence:\n",
    "            if char not in self.char2idx:\n",
    "                self.char2idx[char] = self.size\n",
    "                self.idx2char[self.size] = char\n",
    "                self.size += 1\n",
    "\n",
    "    def get_indices(self, sequence):\n",
    "        indices = [self.char2idx.get(char, self.char2idx['<UNK>']) for char in sequence]\n",
    "        return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3e483e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T17:58:33.130018Z",
     "iopub.status.busy": "2025-05-15T17:58:33.129816Z",
     "iopub.status.idle": "2025-05-15T17:58:33.134581Z",
     "shell.execute_reply": "2025-05-15T17:58:33.134087Z"
    },
    "papermill": {
     "duration": 0.010175,
     "end_time": "2025-05-15T17:58:33.135588",
     "exception": false,
     "start_time": "2025-05-15T17:58:33.125413",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Custom Dataset class\n",
    "\n",
    "class DakshinaDataset(Dataset):\n",
    "    def __init__(self, data, src_vocab, tgt_vocab):\n",
    "        self.data = data\n",
    "        self.src_vocab = src_vocab\n",
    "        self.tgt_vocab = tgt_vocab\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        src = self.data.iloc[idx, 1]  # English (Latin)\n",
    "        tgt = self.data.iloc[idx, 0]  # Tamil\n",
    "        src_indices = [self.src_vocab.char2idx['<SOS>']] + self.src_vocab.get_indices(src) + [self.src_vocab.char2idx['<EOS>']]\n",
    "        tgt_indices = [self.tgt_vocab.char2idx['<SOS>']] + self.tgt_vocab.get_indices(tgt) + [self.tgt_vocab.char2idx['<EOS>']]\n",
    "        return torch.tensor(src_indices, dtype=torch.long), torch.tensor(tgt_indices, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a72e0a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T17:58:33.144164Z",
     "iopub.status.busy": "2025-05-15T17:58:33.143943Z",
     "iopub.status.idle": "2025-05-15T17:58:33.149227Z",
     "shell.execute_reply": "2025-05-15T17:58:33.148722Z"
    },
    "papermill": {
     "duration": 0.010798,
     "end_time": "2025-05-15T17:58:33.150246",
     "exception": false,
     "start_time": "2025-05-15T17:58:33.139448",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to load and preprocess data\n",
    "def load_dakshina_data(train_path, val_path, test_path):\n",
    "    # Read TSV files without headers\n",
    "    train_df = pd.read_csv(train_path, sep='\\t', header=None, usecols=[0, 1])\n",
    "    val_df = pd.read_csv(val_path, sep='\\t', header=None, usecols=[0, 1])\n",
    "    test_df = pd.read_csv(test_path, sep='\\t', header=None, usecols=[0, 1])\n",
    "\n",
    "    # Ensure strings\n",
    "    train_df[0] = train_df[0].astype(str)\n",
    "    train_df[1] = train_df[1].astype(str)\n",
    "    val_df[0] = val_df[0].astype(str)\n",
    "    val_df[1] = val_df[1].astype(str)\n",
    "    test_df[0] = test_df[0].astype(str)\n",
    "    test_df[1] = test_df[1].astype(str)\n",
    "\n",
    "    # Build vocabularies\n",
    "    src_vocab = Vocabulary()  # English (Latin)\n",
    "    tgt_vocab = Vocabulary()  # Tamil\n",
    "\n",
    "    # Add characters to vocab from training data\n",
    "    for _, row in train_df.iterrows():\n",
    "        src_vocab.add_sequence(row[1])\n",
    "        tgt_vocab.add_sequence(row[0])\n",
    "\n",
    "    # Create datasets\n",
    "    train_dataset = DakshinaDataset(train_df, src_vocab, tgt_vocab)\n",
    "    val_dataset = DakshinaDataset(val_df, src_vocab, tgt_vocab)\n",
    "    test_dataset = DakshinaDataset(test_df, src_vocab, tgt_vocab)\n",
    "\n",
    "    return train_dataset, val_dataset, test_dataset, src_vocab, tgt_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33697b94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T17:58:33.158805Z",
     "iopub.status.busy": "2025-05-15T17:58:33.158393Z",
     "iopub.status.idle": "2025-05-15T17:58:33.161792Z",
     "shell.execute_reply": "2025-05-15T17:58:33.161307Z"
    },
    "papermill": {
     "duration": 0.008723,
     "end_time": "2025-05-15T17:58:33.162840",
     "exception": false,
     "start_time": "2025-05-15T17:58:33.154117",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Collate function for DataLoader\n",
    "def collate_fn(batch):\n",
    "    src_batch, tgt_batch = zip(*batch)\n",
    "    # Pad sequences\n",
    "    src_padded = torch.nn.utils.rnn.pad_sequence(src_batch, batch_first=True, padding_value=0)\n",
    "    tgt_padded = torch.nn.utils.rnn.pad_sequence(tgt_batch, batch_first=True, padding_value=0)\n",
    "    return src_padded, tgt_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbe99948",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T17:58:33.171411Z",
     "iopub.status.busy": "2025-05-15T17:58:33.170985Z",
     "iopub.status.idle": "2025-05-15T17:58:33.175048Z",
     "shell.execute_reply": "2025-05-15T17:58:33.174537Z"
    },
    "papermill": {
     "duration": 0.009322,
     "end_time": "2025-05-15T17:58:33.176036",
     "exception": false,
     "start_time": "2025-05-15T17:58:33.166714",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Wrapper function for easier access\n",
    "\n",
    "def prepare_data_loaders(train_path, val_path, test_path, batch_size=32):\n",
    "    train_dataset, val_dataset, test_dataset, src_vocab, tgt_vocab = load_dakshina_data(train_path, val_path, test_path)\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn, pin_memory=True\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn, pin_memory=True\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn, pin_memory=True\n",
    "    )\n",
    "    \n",
    "    return train_loader, val_loader, test_loader, src_vocab, tgt_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38b22e21",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T17:58:33.184672Z",
     "iopub.status.busy": "2025-05-15T17:58:33.184496Z",
     "iopub.status.idle": "2025-05-15T17:58:33.187574Z",
     "shell.execute_reply": "2025-05-15T17:58:33.187080Z"
    },
    "papermill": {
     "duration": 0.008251,
     "end_time": "2025-05-15T17:58:33.188557",
     "exception": false,
     "start_time": "2025-05-15T17:58:33.180306",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Paths to your local TSV files (update as needed)\n",
    "train_path = '/kaggle/input/dakshina-tamil-b/ta.translit.sampled.train.tsv'\n",
    "val_path = '/kaggle/input/dakshina-tamil-b/ta.translit.sampled.dev.tsv'\n",
    "test_path = '/kaggle/input/dakshina-tamil-b/ta.translit.sampled.test.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5109d8ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T17:58:33.196757Z",
     "iopub.status.busy": "2025-05-15T17:58:33.196569Z",
     "iopub.status.idle": "2025-05-15T17:58:35.790033Z",
     "shell.execute_reply": "2025-05-15T17:58:35.789495Z"
    },
    "papermill": {
     "duration": 2.599096,
     "end_time": "2025-05-15T17:58:35.791498",
     "exception": false,
     "start_time": "2025-05-15T17:58:33.192402",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create data loaders\n",
    "train_loader, val_loader, test_loader, src_vocab, tgt_vocab = prepare_data_loaders(train_path, val_path, test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0472302",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T17:58:35.800986Z",
     "iopub.status.busy": "2025-05-15T17:58:35.800319Z",
     "iopub.status.idle": "2025-05-15T17:58:35.804512Z",
     "shell.execute_reply": "2025-05-15T17:58:35.803814Z"
    },
    "papermill": {
     "duration": 0.009725,
     "end_time": "2025-05-15T17:58:35.805559",
     "exception": false,
     "start_time": "2025-05-15T17:58:35.795834",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source (English) vocabulary size: 30\n",
      "Target (Tamil) vocabulary size: 50\n"
     ]
    }
   ],
   "source": [
    "# Print vocabulary sizes\n",
    "print(f\"Source (English) vocabulary size: {src_vocab.size}\")\n",
    "print(f\"Target (Tamil) vocabulary size: {tgt_vocab.size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710f2536",
   "metadata": {
    "papermill": {
     "duration": 0.003778,
     "end_time": "2025-05-15T17:58:35.813218",
     "exception": false,
     "start_time": "2025-05-15T17:58:35.809440",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## defining models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6be6b31",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T17:58:35.821820Z",
     "iopub.status.busy": "2025-05-15T17:58:35.821633Z",
     "iopub.status.idle": "2025-05-15T17:58:35.829359Z",
     "shell.execute_reply": "2025-05-15T17:58:35.828708Z"
    },
    "papermill": {
     "duration": 0.013235,
     "end_time": "2025-05-15T17:58:35.830365",
     "exception": false,
     "start_time": "2025-05-15T17:58:35.817130",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, hidden_size, attention_type='bahdanau'):\n",
    "        super(Attention, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.attention_type = attention_type.lower()\n",
    "        \n",
    "        if self.attention_type == 'bahdanau':\n",
    "            self.Wa = nn.Linear(hidden_size * 2, hidden_size)\n",
    "            self.Ua = nn.Linear(hidden_size, 1, bias=False)\n",
    "        elif self.attention_type == 'dot':\n",
    "            pass  # Dot-product attention uses no additional parameters\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported attention type. Use 'bahdanau' or 'dot'.\")\n",
    "\n",
    "    def forward(self, decoder_hidden, encoder_outputs):\n",
    "        # decoder_hidden: (num_layers, batch_size, hidden_size) or tuple for LSTM\n",
    "        # encoder_outputs: (batch_size, seq_len, hidden_size)\n",
    "        batch_size = encoder_outputs.size(0)\n",
    "        seq_len = encoder_outputs.size(1)\n",
    "        \n",
    "        # Validate encoder_outputs shape\n",
    "        assert encoder_outputs.dim() == 3, f\"Expected encoder_outputs to be 3D, got {encoder_outputs.shape}\"\n",
    "        assert encoder_outputs.size(2) == self.hidden_size, f\"Expected encoder_outputs hidden_size {self.hidden_size}, got {encoder_outputs.size(2)}\"\n",
    "        \n",
    "        # Extract the last layer of decoder hidden state\n",
    "        if isinstance(decoder_hidden, tuple):  # LSTM case\n",
    "            decoder_hidden = decoder_hidden[0]  # Take hidden state, not cell state\n",
    "        decoder_hidden = decoder_hidden[-1]  # (batch_size, hidden_size)\n",
    "        \n",
    "        assert decoder_hidden.dim() == 2, f\"Expected decoder_hidden to be 2D, got {decoder_hidden.shape}\"\n",
    "        assert decoder_hidden.size(1) == self.hidden_size, f\"Expected decoder_hidden hidden_size {self.hidden_size}, got {decoder_hidden.size(1)}\"\n",
    "        \n",
    "        if self.attention_type == 'bahdanau':\n",
    "            # Repeat decoder hidden to match seq_len\n",
    "            decoder_hidden = decoder_hidden.unsqueeze(1).repeat(1, seq_len, 1)  # (batch_size, seq_len, hidden_size)\n",
    "            # Combine with encoder outputs\n",
    "            combined = torch.cat((decoder_hidden, encoder_outputs), dim=2)  # (batch_size, seq_len, hidden_size*2)\n",
    "            # Compute energy\n",
    "            energy = torch.tanh(self.Wa(combined))  # (batch_size, seq_len, hidden_size)\n",
    "            attention_scores = self.Ua(energy).squeeze(2)  # (batch_size, seq_len)\n",
    "        else:  # dot\n",
    "            # Compute dot-product attention\n",
    "            decoder_hidden = decoder_hidden.unsqueeze(1)  # (batch_size, 1, hidden_size)\n",
    "            encoder_outputs_t = encoder_outputs.transpose(1, 2)  # (batch_size, hidden_size, seq_len)\n",
    "            # Verify shapes before bmm\n",
    "            assert decoder_hidden.shape == (batch_size, 1, self.hidden_size), f\"Expected decoder_hidden (batch_size, 1, hidden_size), got {decoder_hidden.shape}\"\n",
    "            assert encoder_outputs_t.shape == (batch_size, self.hidden_size, seq_len), f\"Expected encoder_outputs_t (batch_size, hidden_size, seq_len), got {encoder_outputs_t.shape}\"\n",
    "            attention_scores = torch.bmm(decoder_hidden, encoder_outputs_t).squeeze(1)  # (batch_size, seq_len)\n",
    "        \n",
    "        # Softmax to get attention weights\n",
    "        attention_weights = F.softmax(attention_scores, dim=1)  # (batch_size, seq_len)\n",
    "        # Compute context vector\n",
    "        context = torch.bmm(attention_weights.unsqueeze(1), encoder_outputs).squeeze(1)  # (batch_size, hidden_size)\n",
    "        \n",
    "        return context, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c53eb5b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T17:58:35.840025Z",
     "iopub.status.busy": "2025-05-15T17:58:35.839828Z",
     "iopub.status.idle": "2025-05-15T17:58:35.845188Z",
     "shell.execute_reply": "2025-05-15T17:58:35.844517Z"
    },
    "papermill": {
     "duration": 0.012069,
     "end_time": "2025-05-15T17:58:35.846321",
     "exception": false,
     "start_time": "2025-05-15T17:58:35.834252",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, embed_size, hidden_size, cell_type='RNN', num_layers=1, dropout=0.0):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding = nn.Embedding(input_size, embed_size)\n",
    "        self.cell_type = cell_type.upper()\n",
    "        \n",
    "        rnn_class = {'RNN': nn.RNN, 'LSTM': nn.LSTM, 'GRU': nn.GRU}[self.cell_type]\n",
    "        self.rnn = rnn_class(\n",
    "            input_size=embed_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_layers > 1 else 0.0\n",
    "        )\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        embedded = self.embedding(input_seq)\n",
    "        if self.cell_type == 'LSTM':\n",
    "            outputs, (hidden, cell) = self.rnn(embedded)\n",
    "            return outputs, (hidden, cell)\n",
    "        else:\n",
    "            outputs, hidden = self.rnn(embedded)\n",
    "            return outputs, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "583bb441",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T17:58:35.854920Z",
     "iopub.status.busy": "2025-05-15T17:58:35.854731Z",
     "iopub.status.idle": "2025-05-15T17:58:35.861492Z",
     "shell.execute_reply": "2025-05-15T17:58:35.860854Z"
    },
    "papermill": {
     "duration": 0.012211,
     "end_time": "2025-05-15T17:58:35.862456",
     "exception": false,
     "start_time": "2025-05-15T17:58:35.850245",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, output_size, embed_size, hidden_size, cell_type='RNN', num_layers=1, dropout=0.0, attention_type='bahdanau'):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding = nn.Embedding(output_size, embed_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.cell_type = cell_type.upper()\n",
    "        \n",
    "        rnn_class = {'RNN': nn.RNN, 'LSTM': nn.LSTM, 'GRU': nn.GRU}[self.cell_type]\n",
    "        self.rnn = rnn_class(\n",
    "            input_size=embed_size + hidden_size,  # Input includes context vector\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_layers > 1 else 0.0\n",
    "        )\n",
    "        self.attention = Attention(hidden_size, attention_type)\n",
    "        self.out = nn.Linear(hidden_size * 2, output_size)  # Combine RNN output and context\n",
    "\n",
    "    def forward(self, input_char, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input_char).unsqueeze(1)  # (batch_size, 1, embed_size)\n",
    "        embedded = self.dropout(embedded)\n",
    "        \n",
    "        # Compute attention\n",
    "        context, attention_weights = self.attention(hidden, encoder_outputs)  # context: (batch_size, hidden_size)\n",
    "        \n",
    "        # Concatenate context with embedded input\n",
    "        rnn_input = torch.cat((embedded, context.unsqueeze(1)), dim=2)  # (batch_size, 1, embed_size + hidden_size)\n",
    "        \n",
    "        if self.cell_type == 'LSTM':\n",
    "            output, (hidden, cell) = self.rnn(rnn_input, hidden)\n",
    "            output = output.squeeze(1)  # (batch_size, hidden_size)\n",
    "            output = torch.cat((output, context), dim=1)  # (batch_size, hidden_size * 2)\n",
    "            output = self.out(output)  # (batch_size, output_size)\n",
    "            return output, (hidden, cell), attention_weights\n",
    "        else:\n",
    "            output, hidden = self.rnn(rnn_input, hidden)\n",
    "            output = output.squeeze(1)\n",
    "            output = torch.cat((output, context), dim=1)\n",
    "            output = self.out(output)\n",
    "            return output, hidden, attention_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7aed0382",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T17:58:35.871036Z",
     "iopub.status.busy": "2025-05-15T17:58:35.870545Z",
     "iopub.status.idle": "2025-05-15T17:58:35.877208Z",
     "shell.execute_reply": "2025-05-15T17:58:35.876529Z"
    },
    "papermill": {
     "duration": 0.011913,
     "end_time": "2025-05-15T17:58:35.878208",
     "exception": false,
     "start_time": "2025-05-15T17:58:35.866295",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, source, target, teacher_forcing_ratio=0.5):\n",
    "        batch_size = source.size(0)\n",
    "        target_len = target.size(1)\n",
    "        outputs = torch.zeros(batch_size, target_len, self.decoder.out.out_features).to(source.device)\n",
    "        \n",
    "        encoder_outputs, hidden = self.encoder(source)\n",
    "        \n",
    "        decoder_input = target[:, 0]\n",
    "        \n",
    "        # Handle differing encoder/decoder layers\n",
    "        if self.encoder.cell_type == 'LSTM':\n",
    "            hidden, cell = hidden\n",
    "            if self.encoder.num_layers != self.decoder.num_layers:\n",
    "                factor = self.decoder.num_layers // self.encoder.num_layers + 1\n",
    "                hidden = hidden.repeat(factor, 1, 1)[:self.decoder.num_layers]\n",
    "                cell = cell.repeat(factor, 1, 1)[:self.decoder.num_layers]\n",
    "            hidden = (hidden, cell)\n",
    "        else:\n",
    "            if self.encoder.num_layers != self.decoder.num_layers:\n",
    "                factor = self.decoder.num_layers // self.encoder.num_layers + 1\n",
    "                hidden = hidden.repeat(factor, 1, 1)[:self.decoder.num_layers]\n",
    "        \n",
    "        for t in range(1, target_len):\n",
    "            output, hidden, _ = self.decoder(decoder_input, hidden, encoder_outputs)\n",
    "            outputs[:, t, :] = output\n",
    "            teacher_force = torch.rand(1).item() < teacher_forcing_ratio\n",
    "            top1 = output.argmax(1)\n",
    "            decoder_input = target[:, t] if teacher_force else top1\n",
    "\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e621ae8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T17:58:35.886825Z",
     "iopub.status.busy": "2025-05-15T17:58:35.886351Z",
     "iopub.status.idle": "2025-05-15T17:58:35.890347Z",
     "shell.execute_reply": "2025-05-15T17:58:35.889620Z"
    },
    "papermill": {
     "duration": 0.009334,
     "end_time": "2025-05-15T17:58:35.891346",
     "exception": false,
     "start_time": "2025-05-15T17:58:35.882012",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_model(input_vocab_size, output_vocab_size, embed_size=256, hidden_size=512, \n",
    "                 cell_type='RNN', encoder_layers=1, decoder_layers=1, dropout=0.0, attention_type='bahdanau'):\n",
    "    encoder = EncoderRNN(input_vocab_size, embed_size, hidden_size, cell_type, encoder_layers, dropout)\n",
    "    decoder = DecoderRNN(output_vocab_size, embed_size, hidden_size, cell_type, decoder_layers, dropout, attention_type)\n",
    "    model = Seq2Seq(encoder, decoder)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006e0494",
   "metadata": {
    "papermill": {
     "duration": 0.004025,
     "end_time": "2025-05-15T17:58:35.899373",
     "exception": false,
     "start_time": "2025-05-15T17:58:35.895348",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## setting up wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "de0f3958",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T17:58:35.907565Z",
     "iopub.status.busy": "2025-05-15T17:58:35.907377Z",
     "iopub.status.idle": "2025-05-15T17:58:39.634043Z",
     "shell.execute_reply": "2025-05-15T17:58:39.633226Z"
    },
    "papermill": {
     "duration": 3.732745,
     "end_time": "2025-05-15T17:58:39.635961",
     "exception": false,
     "start_time": "2025-05-15T17:58:35.903216",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install wandb -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6e9a6e15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T17:58:39.645501Z",
     "iopub.status.busy": "2025-05-15T17:58:39.644961Z",
     "iopub.status.idle": "2025-05-15T17:58:42.260409Z",
     "shell.execute_reply": "2025-05-15T17:58:42.259825Z"
    },
    "papermill": {
     "duration": 2.621489,
     "end_time": "2025-05-15T17:58:42.261714",
     "exception": false,
     "start_time": "2025-05-15T17:58:39.640225",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "07b30114",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T17:58:42.270939Z",
     "iopub.status.busy": "2025-05-15T17:58:42.270586Z",
     "iopub.status.idle": "2025-05-15T17:58:42.539140Z",
     "shell.execute_reply": "2025-05-15T17:58:42.538457Z"
    },
    "papermill": {
     "duration": 0.274325,
     "end_time": "2025-05-15T17:58:42.540364",
     "exception": false,
     "start_time": "2025-05-15T17:58:42.266039",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from kaggle_secrets import UserSecretsClient\n",
    "user_secrets = UserSecretsClient()\n",
    "secret_value_0 = user_secrets.get_secret(\"wandb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ea8ea2de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T17:58:42.548927Z",
     "iopub.status.busy": "2025-05-15T17:58:42.548714Z",
     "iopub.status.idle": "2025-05-15T17:58:43.348322Z",
     "shell.execute_reply": "2025-05-15T17:58:43.347750Z"
    },
    "papermill": {
     "duration": 0.805143,
     "end_time": "2025-05-15T17:58:43.349469",
     "exception": false,
     "start_time": "2025-05-15T17:58:42.544326",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mda24m007\u001b[0m (\u001b[33mda24m007-iit-madras\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login(key=secret_value_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4259e0e",
   "metadata": {
    "papermill": {
     "duration": 0.004171,
     "end_time": "2025-05-15T17:58:43.358211",
     "exception": false,
     "start_time": "2025-05-15T17:58:43.354040",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Running wandb sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9ad62aa3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T17:58:43.367304Z",
     "iopub.status.busy": "2025-05-15T17:58:43.367091Z",
     "iopub.status.idle": "2025-05-15T17:58:43.435489Z",
     "shell.execute_reply": "2025-05-15T17:58:43.434774Z"
    },
    "papermill": {
     "duration": 0.074205,
     "end_time": "2025-05-15T17:58:43.436620",
     "exception": false,
     "start_time": "2025-05-15T17:58:43.362415",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bf61816a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T17:58:43.445992Z",
     "iopub.status.busy": "2025-05-15T17:58:43.445810Z",
     "iopub.status.idle": "2025-05-15T17:58:43.453925Z",
     "shell.execute_reply": "2025-05-15T17:58:43.453246Z"
    },
    "papermill": {
     "duration": 0.014071,
     "end_time": "2025-05-15T17:58:43.454972",
     "exception": false,
     "start_time": "2025-05-15T17:58:43.440901",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Beam search decoding (adapted for attention)\n",
    "def beam_search_decode(model, src, max_len, beam_width, sos_idx, eos_idx):\n",
    "    model.eval()\n",
    "    src = src.to(device)\n",
    "    batch_size = src.size(0)\n",
    "    encoder_outputs, hidden = model.encoder(src)\n",
    "    \n",
    "    if model.encoder.cell_type == 'LSTM':\n",
    "        hidden, cell = hidden\n",
    "        if model.encoder.num_layers != model.decoder.num_layers:\n",
    "            factor = model.decoder.num_layers // model.encoder.num_layers\n",
    "            if factor > 1:\n",
    "                hidden = hidden.repeat(factor, 1, 1)\n",
    "                cell = cell.repeat(factor, 1, 1)\n",
    "            else:\n",
    "                hidden = hidden[-model.decoder.num_layers:]\n",
    "                cell = cell[-model.decoder.num_layers:]\n",
    "        hidden = (hidden, cell)\n",
    "    else:\n",
    "        if model.encoder.num_layers != model.decoder.num_layers:\n",
    "            factor = model.decoder.num_layers // model.encoder.num_layers\n",
    "            if factor > 1:\n",
    "                hidden = hidden.repeat(factor, 1, 1)\n",
    "            else:\n",
    "                hidden = hidden[-model.decoder.num_layers:]\n",
    "    \n",
    "    beams = [(torch.tensor([sos_idx], device=device), hidden, 0.0)]\n",
    "    completed = []\n",
    "    \n",
    "    for _ in range(max_len):\n",
    "        new_beams = []\n",
    "        for seq, hid, score in beams:\n",
    "            if seq[-1].item() == eos_idx:\n",
    "                completed.append((seq, score))\n",
    "                continue\n",
    "            output, new_hidden, _ = model.decoder(seq[-1].unsqueeze(0), hid, encoder_outputs)\n",
    "            probs = torch.softmax(output, dim=-1)\n",
    "            top_probs, top_idx = probs.topk(beam_width)\n",
    "            \n",
    "            for i in range(beam_width):\n",
    "                new_seq = torch.cat([seq, top_idx[:, i]])\n",
    "                new_score = score - math.log(top_probs[:, i].item())\n",
    "                new_beams.append((new_seq, new_hidden, new_score))\n",
    "        \n",
    "        new_beams = sorted(new_beams, key=lambda x: x[2])[:beam_width]\n",
    "        beams = new_beams\n",
    "        \n",
    "        if len(completed) >= beam_width:\n",
    "            break\n",
    "    \n",
    "    completed = sorted(completed, key=lambda x: x[1])\n",
    "    if completed:\n",
    "        return completed[0][0]\n",
    "    return beams[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a9719375",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T17:58:43.464272Z",
     "iopub.status.busy": "2025-05-15T17:58:43.464013Z",
     "iopub.status.idle": "2025-05-15T17:58:43.475127Z",
     "shell.execute_reply": "2025-05-15T17:58:43.474601Z"
    },
    "papermill": {
     "duration": 0.016995,
     "end_time": "2025-05-15T17:58:43.476144",
     "exception": false,
     "start_time": "2025-05-15T17:58:43.459149",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Training and evaluation function\n",
    "def train_and_evaluate():\n",
    "    wandb.init()\n",
    "    config = wandb.config\n",
    "    \n",
    "    # Create model with sweep parameters\n",
    "    model = create_model(\n",
    "        input_vocab_size=src_vocab.size,\n",
    "        output_vocab_size=tgt_vocab.size,\n",
    "        embed_size=config.embed_size,\n",
    "        hidden_size=config.hidden_size,\n",
    "        cell_type=config.cell_type,\n",
    "        encoder_layers=1,  # Single layer\n",
    "        decoder_layers=1,  # Single layer\n",
    "        dropout=config.dropout,\n",
    "        attention_type=config.attention_type\n",
    "    ).to(device)\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "    \n",
    "    for epoch in range(10):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for src, tgt in train_loader:\n",
    "            src, tgt = src.to(device), tgt.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(src, tgt, teacher_forcing_ratio=0.5)\n",
    "            output = output[:, 1:].reshape(-1, output.size(-1))\n",
    "            tgt_flat = tgt[:, 1:].reshape(-1)\n",
    "            loss = criterion(output, tgt_flat)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        # Compute training accuracy on one batch\n",
    "        model.eval()\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        with torch.no_grad():\n",
    "            for src, tgt in train_loader:\n",
    "                src, tgt = src.to(device), tgt.to(device)\n",
    "                for i in range(src.size(0)):\n",
    "                    pred = beam_search_decode(\n",
    "                        model, src[i:i+1], max_len=50,\n",
    "                        beam_width=config.beam_width,\n",
    "                        sos_idx=tgt_vocab.char2idx['<SOS>'],\n",
    "                        eos_idx=tgt_vocab.char2idx['<EOS>']\n",
    "                    )\n",
    "                    pred_str = ''.join([tgt_vocab.idx2char[idx.item()] for idx in pred if idx.item() not in [0, 1, 2]])\n",
    "                    tgt_seq = tgt[i]\n",
    "                    tgt_str = ''.join([tgt_vocab.idx2char[idx.item()] for idx in tgt_seq[1:] if idx.item() not in [0, 1, 2]])\n",
    "                    if pred_str == tgt_str:\n",
    "                        train_correct += 1\n",
    "                    train_total += 1\n",
    "                break\n",
    "        \n",
    "        # Compute validation loss and accuracy\n",
    "        val_loss = 0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        with torch.no_grad():\n",
    "            for src, tgt in val_loader:\n",
    "                src, tgt = src.to(device), tgt.to(device)\n",
    "                output = model(src, tgt, teacher_forcing_ratio=0.0)\n",
    "                output = output[:, 1:].reshape(-1, output.size(-1))\n",
    "                tgt_flat = tgt[:, 1:].reshape(-1)\n",
    "                loss = criterion(output, tgt_flat)\n",
    "                val_loss += loss.item()\n",
    "            \n",
    "            # Validation accuracy on one batch\n",
    "            for src, tgt in val_loader:\n",
    "                src, tgt = src.to(device), tgt.to(device)\n",
    "                for i in range(src.size(0)):\n",
    "                    pred = beam_search_decode(\n",
    "                        model, src[i:i+1], max_len=50,\n",
    "                        beam_width=config.beam_width,\n",
    "                        sos_idx=tgt_vocab.char2idx['<SOS>'],\n",
    "                        eos_idx=tgt_vocab.char2idx['<EOS>']\n",
    "                    )\n",
    "                    pred_str = ''.join([tgt_vocab.idx2char[idx.item()] for idx in pred if idx.item() not in [0, 1, 2]])\n",
    "                    tgt_seq = tgt[i]\n",
    "                    tgt_str = ''.join([tgt_vocab.idx2char[idx.item()] for idx in tgt_seq[1:] if idx.item() not in [0, 1, 2]])\n",
    "                    if pred_str == tgt_str:\n",
    "                        val_correct += 1\n",
    "                    val_total += 1\n",
    "                break\n",
    "        \n",
    "        # Log metrics to WandB\n",
    "        wandb.log({\n",
    "            \"epoch\": epoch,\n",
    "            \"train_loss\": train_loss / len(train_loader),\n",
    "            \"val_loss\": val_loss / len(val_loader),\n",
    "            \"train_accuracy\": train_correct / train_total,\n",
    "            \"val_accuracy\": val_correct / val_total\n",
    "        })\n",
    "        print(f\"Epoch {epoch+1}, Train Loss: {train_loss / len(train_loader):.4f}, Val Accuracy: {val_correct / val_total:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c26131ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T17:58:43.485427Z",
     "iopub.status.busy": "2025-05-15T17:58:43.484908Z",
     "iopub.status.idle": "2025-05-15T17:58:43.488779Z",
     "shell.execute_reply": "2025-05-15T17:58:43.488312Z"
    },
    "papermill": {
     "duration": 0.009501,
     "end_time": "2025-05-15T17:58:43.489821",
     "exception": false,
     "start_time": "2025-05-15T17:58:43.480320",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# WandB sweep configuration\n",
    "sweep_config = {\n",
    "    'method': 'bayes',\n",
    "    'metric': {\n",
    "        'name': 'val_accuracy',\n",
    "        'goal': 'maximize'\n",
    "    },\n",
    "    'parameters': {\n",
    "        'embed_size': {\n",
    "            'values': [64, 128, 256]\n",
    "        },\n",
    "        'hidden_size': {\n",
    "            'values': [128, 256, 512]\n",
    "        },\n",
    "        'cell_type': {\n",
    "            'values': ['RNN', 'GRU', 'LSTM']\n",
    "        },\n",
    "        'dropout': {\n",
    "            'values': [0.2, 0.3]\n",
    "        },\n",
    "        'beam_width': {\n",
    "            'values': [1, 3, 5]\n",
    "        },\n",
    "        'attention_type': {\n",
    "            'values': ['bahdanau', 'dot']\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2c2258dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T17:58:43.499196Z",
     "iopub.status.busy": "2025-05-15T17:58:43.498505Z",
     "iopub.status.idle": "2025-05-15T23:03:24.211400Z",
     "shell.execute_reply": "2025-05-15T23:03:24.210859Z"
    },
    "papermill": {
     "duration": 18280.718549,
     "end_time": "2025-05-15T23:03:24.212566",
     "exception": false,
     "start_time": "2025-05-15T17:58:43.494017",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: m2slz7x3\n",
      "Sweep URL: https://wandb.ai/da24m007-iit-madras/DL-A3/sweeps/m2slz7x3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: nvw6qttx with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_type: bahdanau\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_width: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: GRU\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250515_175845-nvw6qttx\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33msilvery-sweep-1\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/sweeps/m2slz7x3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/runs/nvw6qttx\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 0.6071, Val Accuracy: 0.5000\n",
      "Epoch 2, Train Loss: 0.3585, Val Accuracy: 0.5938\n",
      "Epoch 3, Train Loss: 0.3119, Val Accuracy: 0.5938\n",
      "Epoch 4, Train Loss: 0.2870, Val Accuracy: 0.5312\n",
      "Epoch 5, Train Loss: 0.2636, Val Accuracy: 0.5312\n",
      "Epoch 6, Train Loss: 0.2508, Val Accuracy: 0.6562\n",
      "Epoch 7, Train Loss: 0.2364, Val Accuracy: 0.5938\n",
      "Epoch 8, Train Loss: 0.2240, Val Accuracy: 0.5312\n",
      "Epoch 9, Train Loss: 0.2188, Val Accuracy: 0.5312\n",
      "Epoch 10, Train Loss: 0.2085, Val Accuracy: 0.3438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: uploading output.log; uploading wandb-summary.json; uploading config.yaml\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch ▁▂▃▃▄▅▆▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy ▁▇▃▃▄▅▅█▅▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss █▄▃▂▂▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_accuracy ▅▇▇▅▅█▇▅▅▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_loss ▁▂▃▂▄▂▅▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy 0.78125\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss 0.20852\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_accuracy 0.34375\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_loss 0.83753\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33msilvery-sweep-1\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/runs/nvw6qttx\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250515_175845-nvw6qttx/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: cfd2mp28 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_type: bahdanau\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_width: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: RNN\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250515_181414-cfd2mp28\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33msunny-sweep-2\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/sweeps/m2slz7x3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/runs/cfd2mp28\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 0.8589, Val Accuracy: 0.5625\n",
      "Epoch 2, Train Loss: 0.4821, Val Accuracy: 0.5000\n",
      "Epoch 3, Train Loss: 0.4296, Val Accuracy: 0.5625\n",
      "Epoch 4, Train Loss: 0.3932, Val Accuracy: 0.5625\n",
      "Epoch 5, Train Loss: 0.3716, Val Accuracy: 0.5625\n",
      "Epoch 6, Train Loss: 0.3548, Val Accuracy: 0.6250\n",
      "Epoch 7, Train Loss: 0.3469, Val Accuracy: 0.6250\n",
      "Epoch 8, Train Loss: 0.3269, Val Accuracy: 0.6250\n",
      "Epoch 9, Train Loss: 0.3220, Val Accuracy: 0.6250\n",
      "Epoch 10, Train Loss: 0.3121, Val Accuracy: 0.6562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: uploading output.log; uploading config.yaml\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch ▁▂▃▃▄▅▆▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy ▁▅▆▃▆▃▇█▆▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss █▃▃▂▂▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_accuracy ▄▁▄▄▄▇▇▇▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_loss █▂▂▁▂▂▁▃▂▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy 0.71875\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss 0.31213\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_accuracy 0.65625\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_loss 0.76018\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33msunny-sweep-2\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/runs/cfd2mp28\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250515_181414-cfd2mp28/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 0jbiifme with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_type: bahdanau\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_width: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: RNN\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250515_182836-0jbiifme\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33miconic-sweep-3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/sweeps/m2slz7x3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/runs/0jbiifme\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 0.6817, Val Accuracy: 0.4062\n",
      "Epoch 2, Train Loss: 0.4185, Val Accuracy: 0.5625\n",
      "Epoch 3, Train Loss: 0.3722, Val Accuracy: 0.5625\n",
      "Epoch 4, Train Loss: 0.3440, Val Accuracy: 0.6250\n",
      "Epoch 5, Train Loss: 0.3220, Val Accuracy: 0.6250\n",
      "Epoch 6, Train Loss: 0.3112, Val Accuracy: 0.6250\n",
      "Epoch 7, Train Loss: 0.2967, Val Accuracy: 0.6250\n",
      "Epoch 8, Train Loss: 0.2884, Val Accuracy: 0.5312\n",
      "Epoch 9, Train Loss: 0.2777, Val Accuracy: 0.5938\n",
      "Epoch 10, Train Loss: 0.2738, Val Accuracy: 0.5938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: uploading wandb-summary.json; uploading output.log; uploading config.yaml\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch ▁▂▃▃▄▅▆▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy ▅▅▂▁▅▅▇██▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss █▃▃▂▂▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_accuracy ▁▆▆████▅▇▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_loss ▃▃▁▆▄▂▅▆█▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy 0.65625\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss 0.27378\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_accuracy 0.59375\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_loss 0.77245\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33miconic-sweep-3\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/runs/0jbiifme\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250515_182836-0jbiifme/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: iok2v0de with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_type: bahdanau\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_width: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: GRU\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250515_184258-iok2v0de\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mcrisp-sweep-4\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/sweeps/m2slz7x3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/runs/iok2v0de\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 0.7807, Val Accuracy: 0.5000\n",
      "Epoch 2, Train Loss: 0.4154, Val Accuracy: 0.5312\n",
      "Epoch 3, Train Loss: 0.3574, Val Accuracy: 0.5938\n",
      "Epoch 4, Train Loss: 0.3254, Val Accuracy: 0.5938\n",
      "Epoch 5, Train Loss: 0.2963, Val Accuracy: 0.5938\n",
      "Epoch 6, Train Loss: 0.2762, Val Accuracy: 0.5312\n",
      "Epoch 7, Train Loss: 0.2643, Val Accuracy: 0.5625\n",
      "Epoch 8, Train Loss: 0.2477, Val Accuracy: 0.6250\n",
      "Epoch 9, Train Loss: 0.2344, Val Accuracy: 0.4688\n",
      "Epoch 10, Train Loss: 0.2289, Val Accuracy: 0.5312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: uploading output.log; uploading config.yaml\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch ▁▂▃▃▄▅▆▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy ▁▅▅▇▇▅▅██▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss █▃▃▂▂▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_accuracy ▂▄▇▇▇▄▅█▁▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_loss █▃▁▁▂▅▃▄▄█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy 0.78125\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss 0.22889\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_accuracy 0.53125\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_loss 0.81047\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mcrisp-sweep-4\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/runs/iok2v0de\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250515_184258-iok2v0de/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: hnsub03u with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_type: dot\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_width: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: RNN\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250515_185811-hnsub03u\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mdandy-sweep-5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/sweeps/m2slz7x3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/runs/hnsub03u\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 1.4301, Val Accuracy: 0.0000\n",
      "Epoch 2, Train Loss: 1.4205, Val Accuracy: 0.0000\n",
      "Epoch 3, Train Loss: 1.1130, Val Accuracy: 0.0000\n",
      "Epoch 4, Train Loss: 1.2584, Val Accuracy: 0.0000\n",
      "Epoch 5, Train Loss: 1.2212, Val Accuracy: 0.0000\n",
      "Epoch 6, Train Loss: 1.9604, Val Accuracy: 0.0000\n",
      "Epoch 7, Train Loss: 1.7088, Val Accuracy: 0.0000\n",
      "Epoch 8, Train Loss: 1.3317, Val Accuracy: 0.0938\n",
      "Epoch 9, Train Loss: 1.1602, Val Accuracy: 0.0000\n",
      "Epoch 10, Train Loss: 1.0996, Val Accuracy: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: uploading output.log; uploading wandb-summary.json; uploading config.yaml\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch ▁▂▃▃▄▅▆▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy ▁▅▃▁▃▁▃█▃▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss ▄▄▁▂▂█▆▃▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_accuracy ▁▁▁▁▁▁▁█▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_loss ▄▃▁▅▁█▆▄▂▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy 0.03125\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss 1.09955\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_accuracy 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_loss 1.50495\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mdandy-sweep-5\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/runs/hnsub03u\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250515_185811-hnsub03u/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: raej7aqs with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_type: bahdanau\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_width: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: GRU\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250515_191003-raej7aqs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mradiant-sweep-6\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/sweeps/m2slz7x3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/runs/raej7aqs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 0.6730, Val Accuracy: 0.5625\n",
      "Epoch 2, Train Loss: 0.3597, Val Accuracy: 0.6562\n",
      "Epoch 3, Train Loss: 0.3015, Val Accuracy: 0.6562\n",
      "Epoch 4, Train Loss: 0.2638, Val Accuracy: 0.6562\n",
      "Epoch 5, Train Loss: 0.2323, Val Accuracy: 0.6562\n",
      "Epoch 6, Train Loss: 0.2099, Val Accuracy: 0.6562\n",
      "Epoch 7, Train Loss: 0.1971, Val Accuracy: 0.6250\n",
      "Epoch 8, Train Loss: 0.1850, Val Accuracy: 0.5625\n",
      "Epoch 9, Train Loss: 0.1764, Val Accuracy: 0.5625\n",
      "Epoch 10, Train Loss: 0.1652, Val Accuracy: 0.5312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: uploading output.log; uploading wandb-summary.json; uploading config.yaml\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch ▁▂▃▃▄▅▆▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy ▃▄▅▆▁▅▇▆█▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss █▄▃▂▂▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_accuracy ▃█████▆▃▃▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_loss ▂▁▂▂▄▅▄▇▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy 0.65625\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss 0.16521\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_accuracy 0.53125\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_loss 0.83625\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mradiant-sweep-6\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/runs/raej7aqs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250515_191003-raej7aqs/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: qipwb3ru with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_type: bahdanau\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_width: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: GRU\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250515_192557-qipwb3ru\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mpeach-sweep-7\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/sweeps/m2slz7x3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/runs/qipwb3ru\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 0.6538, Val Accuracy: 0.5625\n",
      "Epoch 2, Train Loss: 0.3614, Val Accuracy: 0.4062\n",
      "Epoch 3, Train Loss: 0.2977, Val Accuracy: 0.5000\n",
      "Epoch 4, Train Loss: 0.2566, Val Accuracy: 0.5000\n",
      "Epoch 5, Train Loss: 0.2332, Val Accuracy: 0.6562\n",
      "Epoch 6, Train Loss: 0.2078, Val Accuracy: 0.5938\n",
      "Epoch 7, Train Loss: 0.1906, Val Accuracy: 0.6250\n",
      "Epoch 8, Train Loss: 0.1828, Val Accuracy: 0.5938\n",
      "Epoch 9, Train Loss: 0.1717, Val Accuracy: 0.6250\n",
      "Epoch 10, Train Loss: 0.1620, Val Accuracy: 0.5625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: uploading output.log; uploading wandb-summary.json; uploading config.yaml\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch ▁▂▃▃▄▅▆▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy ▁▃▃▄▄▄▇▇█▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss █▄▃▂▂▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_accuracy ▅▁▄▄█▆▇▆▇▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_loss ▃▂▁▃▄▅▄▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy 0.71875\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss 0.16199\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_accuracy 0.5625\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_loss 0.866\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mpeach-sweep-7\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/runs/qipwb3ru\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250515_192557-qipwb3ru/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: qxd1du69 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_type: bahdanau\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_width: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: GRU\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250515_194200-qxd1du69\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mcrimson-sweep-8\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/sweeps/m2slz7x3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/runs/qxd1du69\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 0.7360, Val Accuracy: 0.5625\n",
      "Epoch 2, Train Loss: 0.4067, Val Accuracy: 0.5625\n",
      "Epoch 3, Train Loss: 0.3559, Val Accuracy: 0.6250\n",
      "Epoch 4, Train Loss: 0.3220, Val Accuracy: 0.5938\n",
      "Epoch 5, Train Loss: 0.2991, Val Accuracy: 0.4062\n",
      "Epoch 6, Train Loss: 0.2830, Val Accuracy: 0.6250\n",
      "Epoch 7, Train Loss: 0.2683, Val Accuracy: 0.3750\n",
      "Epoch 8, Train Loss: 0.2550, Val Accuracy: 0.5625\n",
      "Epoch 9, Train Loss: 0.2462, Val Accuracy: 0.3750\n",
      "Epoch 10, Train Loss: 0.2395, Val Accuracy: 0.4688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: uploading wandb-summary.json; uploading output.log; uploading config.yaml\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch ▁▂▃▃▄▅▆▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy ▁▂▃▂▅▆▅▂▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss █▃▃▂▂▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_accuracy ▆▆█▇▂█▁▆▁▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_loss ▅▃▂▁▃▅▄▅█▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy 0.90625\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss 0.23953\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_accuracy 0.46875\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_loss 0.81547\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mcrimson-sweep-8\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/runs/qxd1du69\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250515_194200-qxd1du69/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: sy5gvhqh with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_type: bahdanau\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_width: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: RNN\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250515_195736-sy5gvhqh\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33msmooth-sweep-9\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/sweeps/m2slz7x3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/runs/sy5gvhqh\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 0.8314, Val Accuracy: 0.4688\n",
      "Epoch 2, Train Loss: 0.4778, Val Accuracy: 0.5625\n",
      "Epoch 3, Train Loss: 0.4269, Val Accuracy: 0.5625\n",
      "Epoch 4, Train Loss: 0.3924, Val Accuracy: 0.5312\n",
      "Epoch 5, Train Loss: 0.3657, Val Accuracy: 0.5625\n",
      "Epoch 6, Train Loss: 0.3515, Val Accuracy: 0.6250\n",
      "Epoch 7, Train Loss: 0.3424, Val Accuracy: 0.3125\n",
      "Epoch 8, Train Loss: 0.3290, Val Accuracy: 0.6250\n",
      "Epoch 9, Train Loss: 0.3252, Val Accuracy: 0.6250\n",
      "Epoch 10, Train Loss: 0.3097, Val Accuracy: 0.5625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: uploading wandb-summary.json; uploading config.yaml\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch ▁▂▃▃▄▅▆▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy ▆▁▃▄▆▇▆█▆▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss █▃▃▂▂▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_accuracy ▅▇▇▆▇█▁██▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_loss █▄▁▃▁▃▁▁▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy 0.625\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss 0.30974\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_accuracy 0.5625\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_loss 0.70099\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33msmooth-sweep-9\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/runs/sy5gvhqh\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250515_195736-sy5gvhqh/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: m4tv2amq with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_type: bahdanau\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_width: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: RNN\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250515_201223-m4tv2amq\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mdistinctive-sweep-10\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/sweeps/m2slz7x3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/runs/m4tv2amq\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 0.7177, Val Accuracy: 0.5625\n",
      "Epoch 2, Train Loss: 0.4247, Val Accuracy: 0.5625\n",
      "Epoch 3, Train Loss: 0.3767, Val Accuracy: 0.4375\n",
      "Epoch 4, Train Loss: 0.3468, Val Accuracy: 0.5625\n",
      "Epoch 5, Train Loss: 0.3177, Val Accuracy: 0.3750\n",
      "Epoch 6, Train Loss: 0.3046, Val Accuracy: 0.5938\n",
      "Epoch 7, Train Loss: 0.2922, Val Accuracy: 0.5938\n",
      "Epoch 8, Train Loss: 0.2804, Val Accuracy: 0.5625\n",
      "Epoch 9, Train Loss: 0.2719, Val Accuracy: 0.6250\n",
      "Epoch 10, Train Loss: 0.2739, Val Accuracy: 0.5938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: uploading output.log; uploading config.yaml\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch ▁▂▃▃▄▅▆▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy ▂▂▂▄▁█▃▆▅▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss █▃▃▂▂▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_accuracy ▆▆▃▆▁▇▇▆█▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_loss ▇▂█▅▁▆▄▄▄▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy 0.8125\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss 0.27386\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_accuracy 0.59375\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_loss 0.74627\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mdistinctive-sweep-10\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/runs/m4tv2amq\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250515_201223-m4tv2amq/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: mzahlg9e with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_type: bahdanau\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_width: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: GRU\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250515_202711-mzahlg9e\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfancy-sweep-11\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/sweeps/m2slz7x3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/runs/mzahlg9e\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 0.6636, Val Accuracy: 0.5625\n",
      "Epoch 2, Train Loss: 0.3566, Val Accuracy: 0.5000\n",
      "Epoch 3, Train Loss: 0.2939, Val Accuracy: 0.5000\n",
      "Epoch 4, Train Loss: 0.2573, Val Accuracy: 0.6250\n",
      "Epoch 5, Train Loss: 0.2276, Val Accuracy: 0.5000\n",
      "Epoch 6, Train Loss: 0.2073, Val Accuracy: 0.5625\n",
      "Epoch 7, Train Loss: 0.1963, Val Accuracy: 0.5312\n",
      "Epoch 8, Train Loss: 0.1783, Val Accuracy: 0.5312\n",
      "Epoch 9, Train Loss: 0.1717, Val Accuracy: 0.5938\n",
      "Epoch 10, Train Loss: 0.1593, Val Accuracy: 0.5625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: uploading config.yaml\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch ▁▂▃▃▄▅▆▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy ▁▄▅▆▃█▇▆▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss █▄▃▂▂▂▂▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_accuracy ▅▁▁█▁▅▃▃▆▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_loss ▃▂▁▂▂▃▃▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy 0.9375\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss 0.1593\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_accuracy 0.5625\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_loss 0.85341\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mfancy-sweep-11\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/runs/mzahlg9e\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250515_202711-mzahlg9e/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: uw2bmm4f with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_type: bahdanau\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_width: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: RNN\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250515_204331-uw2bmm4f\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfresh-sweep-12\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/sweeps/m2slz7x3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/runs/uw2bmm4f\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 0.8544, Val Accuracy: 0.3750\n",
      "Epoch 2, Train Loss: 0.4811, Val Accuracy: 0.5625\n",
      "Epoch 3, Train Loss: 0.4277, Val Accuracy: 0.5625\n",
      "Epoch 4, Train Loss: 0.3970, Val Accuracy: 0.5625\n",
      "Epoch 5, Train Loss: 0.3711, Val Accuracy: 0.5000\n",
      "Epoch 6, Train Loss: 0.3559, Val Accuracy: 0.5625\n",
      "Epoch 7, Train Loss: 0.3390, Val Accuracy: 0.5625\n",
      "Epoch 8, Train Loss: 0.3288, Val Accuracy: 0.6250\n",
      "Epoch 9, Train Loss: 0.3212, Val Accuracy: 0.4375\n",
      "Epoch 10, Train Loss: 0.3138, Val Accuracy: 0.6250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: uploading wandb-summary.json; uploading config.yaml\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch ▁▂▃▃▄▅▆▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy ▁▆▃▅▆▃▄█▅▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss █▃▂▂▂▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_accuracy ▁▆▆▆▅▆▆█▃█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_loss █▃▁▃▂▁▂▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy 0.625\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss 0.31384\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_accuracy 0.625\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_loss 0.71738\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mfresh-sweep-12\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/runs/uw2bmm4f\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250515_204331-uw2bmm4f/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: gp6wgsjj with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_type: bahdanau\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_width: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: GRU\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250515_205824-gp6wgsjj\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mblooming-sweep-13\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/sweeps/m2slz7x3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/runs/gp6wgsjj\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 0.6228, Val Accuracy: 0.5625\n",
      "Epoch 2, Train Loss: 0.3535, Val Accuracy: 0.6250\n",
      "Epoch 3, Train Loss: 0.3012, Val Accuracy: 0.6250\n",
      "Epoch 4, Train Loss: 0.2686, Val Accuracy: 0.5000\n",
      "Epoch 5, Train Loss: 0.2431, Val Accuracy: 0.5938\n",
      "Epoch 6, Train Loss: 0.2245, Val Accuracy: 0.3750\n",
      "Epoch 7, Train Loss: 0.2075, Val Accuracy: 0.5938\n",
      "Epoch 8, Train Loss: 0.1980, Val Accuracy: 0.5938\n",
      "Epoch 9, Train Loss: 0.1879, Val Accuracy: 0.5625\n",
      "Epoch 10, Train Loss: 0.1829, Val Accuracy: 0.5938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: uploading output.log; uploading wandb-summary.json; uploading config.yaml\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch ▁▂▃▃▄▅▆▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy ▅▃▁▃▇▆▆▆█▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss █▄▃▂▂▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_accuracy ▆██▅▇▁▇▇▆▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_loss ▂▃▁▁▃▄▆▇▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy 0.71875\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss 0.18293\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_accuracy 0.59375\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_loss 0.83807\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mblooming-sweep-13\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/runs/gp6wgsjj\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250515_205824-gp6wgsjj/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: w42gq2qj with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_type: bahdanau\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_width: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: RNN\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250515_211424-w42gq2qj\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mresilient-sweep-14\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/sweeps/m2slz7x3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/runs/w42gq2qj\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 0.8860, Val Accuracy: 0.3125\n",
      "Epoch 2, Train Loss: 0.4765, Val Accuracy: 0.3750\n",
      "Epoch 3, Train Loss: 0.4211, Val Accuracy: 0.5625\n",
      "Epoch 4, Train Loss: 0.3866, Val Accuracy: 0.5625\n",
      "Epoch 5, Train Loss: 0.3681, Val Accuracy: 0.5625\n",
      "Epoch 6, Train Loss: 0.3518, Val Accuracy: 0.5625\n",
      "Epoch 7, Train Loss: 0.3359, Val Accuracy: 0.5625\n",
      "Epoch 8, Train Loss: 0.3278, Val Accuracy: 0.5625\n",
      "Epoch 9, Train Loss: 0.3198, Val Accuracy: 0.4062\n",
      "Epoch 10, Train Loss: 0.3130, Val Accuracy: 0.5625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: uploading output.log; uploading config.yaml\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch ▁▂▃▃▄▅▆▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy ▂▄▅▂▄▁█▆▄▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss █▃▂▂▂▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_accuracy ▁▃██████▄█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_loss ▇▁▇▃▅▂▅▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy 0.6875\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss 0.31302\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_accuracy 0.5625\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_loss 0.85729\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mresilient-sweep-14\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/runs/w42gq2qj\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250515_211424-w42gq2qj/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 51t33lft with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_type: bahdanau\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_width: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: GRU\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250515_212912-51t33lft\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mneat-sweep-15\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/sweeps/m2slz7x3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/runs/51t33lft\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 0.7467, Val Accuracy: 0.5625\n",
      "Epoch 2, Train Loss: 0.4006, Val Accuracy: 0.5625\n",
      "Epoch 3, Train Loss: 0.3514, Val Accuracy: 0.5000\n",
      "Epoch 4, Train Loss: 0.3188, Val Accuracy: 0.5625\n",
      "Epoch 5, Train Loss: 0.2944, Val Accuracy: 0.5938\n",
      "Epoch 6, Train Loss: 0.2818, Val Accuracy: 0.5625\n",
      "Epoch 7, Train Loss: 0.2642, Val Accuracy: 0.5938\n",
      "Epoch 8, Train Loss: 0.2510, Val Accuracy: 0.6562\n",
      "Epoch 9, Train Loss: 0.2431, Val Accuracy: 0.6250\n",
      "Epoch 10, Train Loss: 0.2319, Val Accuracy: 0.7188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: uploading output.log; uploading wandb-summary.json; uploading config.yaml\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch ▁▂▃▃▄▅▆▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy ▁▅▅▆▄▄▅▆█▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss █▃▃▂▂▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_accuracy ▃▃▁▃▄▃▄▆▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_loss █▆▁▂▁▂▇█▇▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy 0.78125\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss 0.23186\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_accuracy 0.71875\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_loss 0.79977\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mneat-sweep-15\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/runs/51t33lft\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250515_212912-51t33lft/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: o51sc16y with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_type: dot\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_width: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: GRU\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250515_214451-o51sc16y\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mdeft-sweep-16\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/sweeps/m2slz7x3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/runs/o51sc16y\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 0.8705, Val Accuracy: 0.3125\n",
      "Epoch 2, Train Loss: 0.5350, Val Accuracy: 0.3750\n",
      "Epoch 3, Train Loss: 0.5123, Val Accuracy: 0.4062\n",
      "Epoch 4, Train Loss: 0.5055, Val Accuracy: 0.5000\n",
      "Epoch 5, Train Loss: 0.5304, Val Accuracy: 0.2500\n",
      "Epoch 6, Train Loss: 0.6258, Val Accuracy: 0.0312\n",
      "Epoch 7, Train Loss: 0.7558, Val Accuracy: 0.2188\n",
      "Epoch 8, Train Loss: 0.7846, Val Accuracy: 0.2812\n",
      "Epoch 9, Train Loss: 0.6760, Val Accuracy: 0.2500\n",
      "Epoch 10, Train Loss: 0.6342, Val Accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: uploading wandb-summary.json; uploading config.yaml\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch ▁▂▃▃▄▅▆▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy ▆█▆▅▄▂▁▄▂▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss █▂▁▁▁▃▆▆▄▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_accuracy ▅▆▇█▄▁▄▅▄▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_loss ▂▁▁▂▇█▇▄▃▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy 0.21875\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss 0.63425\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_accuracy 0.25\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_loss 1.21325\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mdeft-sweep-16\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/runs/o51sc16y\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250515_214451-o51sc16y/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: jtc4likw with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_type: bahdanau\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_width: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: GRU\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250515_215824-jtc4likw\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mmild-sweep-17\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/sweeps/m2slz7x3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/runs/jtc4likw\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 0.6311, Val Accuracy: 0.5625\n",
      "Epoch 2, Train Loss: 0.3477, Val Accuracy: 0.5625\n",
      "Epoch 3, Train Loss: 0.2968, Val Accuracy: 0.6250\n",
      "Epoch 4, Train Loss: 0.2649, Val Accuracy: 0.3750\n",
      "Epoch 5, Train Loss: 0.2391, Val Accuracy: 0.5625\n",
      "Epoch 6, Train Loss: 0.2234, Val Accuracy: 0.6562\n",
      "Epoch 7, Train Loss: 0.2084, Val Accuracy: 0.5938\n",
      "Epoch 8, Train Loss: 0.1928, Val Accuracy: 0.6250\n",
      "Epoch 9, Train Loss: 0.1864, Val Accuracy: 0.5625\n",
      "Epoch 10, Train Loss: 0.1812, Val Accuracy: 0.5625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: uploading output.log; uploading config.yaml\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch ▁▂▃▃▄▅▆▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy ▁▅▄▇▆▅█▇▅▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss █▄▃▂▂▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_accuracy ▆▆▇▁▆█▆▇▆▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_loss ▃▂▁▁▃▆▆▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy 0.75\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss 0.18121\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_accuracy 0.5625\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_loss 0.86254\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mmild-sweep-17\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/runs/jtc4likw\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250515_215824-jtc4likw/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: kvth8duj with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_type: bahdanau\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_width: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: GRU\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250515_221447-kvth8duj\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mbreezy-sweep-18\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/sweeps/m2slz7x3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/runs/kvth8duj\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 0.6214, Val Accuracy: 0.4062\n",
      "Epoch 2, Train Loss: 0.3490, Val Accuracy: 0.5625\n",
      "Epoch 3, Train Loss: 0.2967, Val Accuracy: 0.5312\n",
      "Epoch 4, Train Loss: 0.2637, Val Accuracy: 0.5938\n",
      "Epoch 5, Train Loss: 0.2403, Val Accuracy: 0.5625\n",
      "Epoch 6, Train Loss: 0.2214, Val Accuracy: 0.5000\n",
      "Epoch 7, Train Loss: 0.2065, Val Accuracy: 0.6250\n",
      "Epoch 8, Train Loss: 0.1953, Val Accuracy: 0.5625\n",
      "Epoch 9, Train Loss: 0.1871, Val Accuracy: 0.5938\n",
      "Epoch 10, Train Loss: 0.1812, Val Accuracy: 0.6250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: uploading config.yaml; uploading history steps 9-9, summary, console lines 9-9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch ▁▂▃▃▄▅▆▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy ▁█▃▆▅▅▅▆▃▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss █▄▃▂▂▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_accuracy ▁▆▅▇▆▄█▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_loss ▃▂▁▂▂▃▄▇▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy 0.71875\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss 0.18121\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_accuracy 0.625\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_loss 0.85357\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mbreezy-sweep-18\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/runs/kvth8duj\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250515_221447-kvth8duj/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: l1dy0vjv with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_type: bahdanau\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_width: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: GRU\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250515_223138-l1dy0vjv\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mpeach-sweep-19\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/sweeps/m2slz7x3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/runs/l1dy0vjv\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 0.6240, Val Accuracy: 0.5312\n",
      "Epoch 2, Train Loss: 0.3530, Val Accuracy: 0.5625\n",
      "Epoch 3, Train Loss: 0.2990, Val Accuracy: 0.6250\n",
      "Epoch 4, Train Loss: 0.2670, Val Accuracy: 0.6250\n",
      "Epoch 5, Train Loss: 0.2396, Val Accuracy: 0.6562\n",
      "Epoch 6, Train Loss: 0.2223, Val Accuracy: 0.6250\n",
      "Epoch 7, Train Loss: 0.2115, Val Accuracy: 0.6250\n",
      "Epoch 8, Train Loss: 0.1980, Val Accuracy: 0.6562\n",
      "Epoch 9, Train Loss: 0.1879, Val Accuracy: 0.5938\n",
      "Epoch 10, Train Loss: 0.1821, Val Accuracy: 0.5625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: uploading wandb-summary.json; uploading output.log; uploading config.yaml\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch ▁▂▃▃▄▅▆▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy ▁▃▃▆▇▃▇▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss █▄▃▂▂▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_accuracy ▁▃▆▆█▆▆█▅▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_loss ▃▃▁▃▄▄▅▃█▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy 0.875\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss 0.18209\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_accuracy 0.5625\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_loss 0.8556\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mpeach-sweep-19\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/runs/l1dy0vjv\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250515_223138-l1dy0vjv/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 6ef2dd5r with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_type: bahdanau\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_width: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: GRU\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250515_224753-6ef2dd5r\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mproud-sweep-20\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/sweeps/m2slz7x3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/runs/6ef2dd5r\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 0.7511, Val Accuracy: 0.5312\n",
      "Epoch 2, Train Loss: 0.4140, Val Accuracy: 0.5625\n",
      "Epoch 3, Train Loss: 0.3599, Val Accuracy: 0.6250\n",
      "Epoch 4, Train Loss: 0.3261, Val Accuracy: 0.5000\n",
      "Epoch 5, Train Loss: 0.3034, Val Accuracy: 0.6250\n",
      "Epoch 6, Train Loss: 0.2853, Val Accuracy: 0.5938\n",
      "Epoch 7, Train Loss: 0.2716, Val Accuracy: 0.5938\n",
      "Epoch 8, Train Loss: 0.2618, Val Accuracy: 0.5312\n",
      "Epoch 9, Train Loss: 0.2494, Val Accuracy: 0.5938\n",
      "Epoch 10, Train Loss: 0.2434, Val Accuracy: 0.5625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: uploading output.log; uploading wandb-summary.json; uploading config.yaml\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch ▁▂▃▃▄▅▆▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy ▂▁▂▃▅▅▄▄▅█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss █▃▃▂▂▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_accuracy ▃▅█▁█▆▆▃▆▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_loss ▅▃▁▂▁▁▆▄▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy 0.875\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss 0.24343\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_accuracy 0.5625\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_loss 0.8117\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mproud-sweep-20\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3/runs/6ef2dd5r\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/da24m007-iit-madras/DL-A3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250515_224753-6ef2dd5r/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Initialize and run sweep\n",
    "sweep_id = wandb.sweep(sweep_config, project=\"DL-A3\")\n",
    "wandb.agent(sweep_id, function=train_and_evaluate, count=20)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7429459,
     "sourceId": 11826703,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 18305.276854,
   "end_time": "2025-05-15T23:03:28.324595",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-15T17:58:23.047741",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
