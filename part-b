{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11826703,"sourceType":"datasetVersion","datasetId":7429459}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Question 5 - Attention Network","metadata":{}},{"cell_type":"code","source":"# Importing Libraries\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T14:33:33.937921Z","iopub.execute_input":"2025-05-17T14:33:33.938526Z","iopub.status.idle":"2025-05-17T14:33:38.935675Z","shell.execute_reply.started":"2025-05-17T14:33:33.938503Z","shell.execute_reply":"2025-05-17T14:33:38.934823Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"## preparing dataset for training","metadata":{}},{"cell_type":"code","source":"# Importing Libraries\n\nimport pandas as pd\nimport numpy as np\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch import optim\nfrom collections import Counter\nimport os\nimport math","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T14:33:38.936816Z","iopub.execute_input":"2025-05-17T14:33:38.937190Z","iopub.status.idle":"2025-05-17T14:33:39.207356Z","shell.execute_reply.started":"2025-05-17T14:33:38.937161Z","shell.execute_reply":"2025-05-17T14:33:39.206813Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Vocabulary class to handle character-to-index mapping\nclass Vocabulary:\n    def __init__(self):\n        self.char2idx = {'<PAD>': 0, '<SOS>': 1, '<EOS>': 2, '<UNK>': 3}\n        self.idx2char = {0: '<PAD>', 1: '<SOS>', 2: '<EOS>', 3: '<UNK>'}\n        self.size = 4\n\n    def add_sequence(self, sequence):\n        for char in sequence:\n            if char not in self.char2idx:\n                self.char2idx[char] = self.size\n                self.idx2char[self.size] = char\n                self.size += 1\n\n    def get_indices(self, sequence):\n        indices = [self.char2idx.get(char, self.char2idx['<UNK>']) for char in sequence]\n        return indices","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T14:33:39.208065Z","iopub.execute_input":"2025-05-17T14:33:39.208379Z","iopub.status.idle":"2025-05-17T14:33:39.213994Z","shell.execute_reply.started":"2025-05-17T14:33:39.208361Z","shell.execute_reply":"2025-05-17T14:33:39.213430Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Custom Dataset class\n\nclass DakshinaDataset(Dataset):\n    def __init__(self, data, src_vocab, tgt_vocab):\n        self.data = data\n        self.src_vocab = src_vocab\n        self.tgt_vocab = tgt_vocab\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        src = self.data.iloc[idx, 1]  # English (Latin)\n        tgt = self.data.iloc[idx, 0]  # Tamil\n        src_indices = [self.src_vocab.char2idx['<SOS>']] + self.src_vocab.get_indices(src) + [self.src_vocab.char2idx['<EOS>']]\n        tgt_indices = [self.tgt_vocab.char2idx['<SOS>']] + self.tgt_vocab.get_indices(tgt) + [self.tgt_vocab.char2idx['<EOS>']]\n        return torch.tensor(src_indices, dtype=torch.long), torch.tensor(tgt_indices, dtype=torch.long)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T14:33:39.215732Z","iopub.execute_input":"2025-05-17T14:33:39.215967Z","iopub.status.idle":"2025-05-17T14:33:39.229943Z","shell.execute_reply.started":"2025-05-17T14:33:39.215949Z","shell.execute_reply":"2025-05-17T14:33:39.229204Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Function to load and preprocess data\ndef load_dakshina_data(train_path, val_path, test_path):\n    # Read TSV files without headers\n    train_df = pd.read_csv(train_path, sep='\\t', header=None, usecols=[0, 1])\n    val_df = pd.read_csv(val_path, sep='\\t', header=None, usecols=[0, 1])\n    test_df = pd.read_csv(test_path, sep='\\t', header=None, usecols=[0, 1])\n\n    # Ensure strings\n    train_df[0] = train_df[0].astype(str)\n    train_df[1] = train_df[1].astype(str)\n    val_df[0] = val_df[0].astype(str)\n    val_df[1] = val_df[1].astype(str)\n    test_df[0] = test_df[0].astype(str)\n    test_df[1] = test_df[1].astype(str)\n\n    # Build vocabularies\n    src_vocab = Vocabulary()  # English (Latin)\n    tgt_vocab = Vocabulary()  # Tamil\n\n    # Add characters to vocab from training data\n    for _, row in train_df.iterrows():\n        src_vocab.add_sequence(row[1])\n        tgt_vocab.add_sequence(row[0])\n\n    # Create datasets\n    train_dataset = DakshinaDataset(train_df, src_vocab, tgt_vocab)\n    val_dataset = DakshinaDataset(val_df, src_vocab, tgt_vocab)\n    test_dataset = DakshinaDataset(test_df, src_vocab, tgt_vocab)\n\n    return train_dataset, val_dataset, test_dataset, src_vocab, tgt_vocab","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T14:33:39.230728Z","iopub.execute_input":"2025-05-17T14:33:39.231145Z","iopub.status.idle":"2025-05-17T14:33:39.244584Z","shell.execute_reply.started":"2025-05-17T14:33:39.231127Z","shell.execute_reply":"2025-05-17T14:33:39.244014Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Collate function for DataLoader\ndef collate_fn(batch):\n    src_batch, tgt_batch = zip(*batch)\n    # Pad sequences\n    src_padded = torch.nn.utils.rnn.pad_sequence(src_batch, batch_first=True, padding_value=0)\n    tgt_padded = torch.nn.utils.rnn.pad_sequence(tgt_batch, batch_first=True, padding_value=0)\n    return src_padded, tgt_padded","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T14:33:39.245476Z","iopub.execute_input":"2025-05-17T14:33:39.245731Z","iopub.status.idle":"2025-05-17T14:33:39.262575Z","shell.execute_reply.started":"2025-05-17T14:33:39.245704Z","shell.execute_reply":"2025-05-17T14:33:39.261914Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# Wrapper function for easier access\n\ndef prepare_data_loaders(train_path, val_path, test_path, batch_size=32):\n    train_dataset, val_dataset, test_dataset, src_vocab, tgt_vocab = load_dakshina_data(train_path, val_path, test_path)\n    \n    train_loader = DataLoader(\n        train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn, pin_memory=True\n    )\n    val_loader = DataLoader(\n        val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn, pin_memory=True\n    )\n    test_loader = DataLoader(\n        test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn, pin_memory=True\n    )\n    \n    return train_loader, val_loader, test_loader, src_vocab, tgt_vocab","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T14:33:39.263435Z","iopub.execute_input":"2025-05-17T14:33:39.263672Z","iopub.status.idle":"2025-05-17T14:33:39.276786Z","shell.execute_reply.started":"2025-05-17T14:33:39.263652Z","shell.execute_reply":"2025-05-17T14:33:39.276161Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# Paths to your local TSV files (update as needed)\ntrain_path = '/kaggle/input/dakshina-tamil-b/ta.translit.sampled.train.tsv'\nval_path = '/kaggle/input/dakshina-tamil-b/ta.translit.sampled.dev.tsv'\ntest_path = '/kaggle/input/dakshina-tamil-b/ta.translit.sampled.test.tsv'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T14:33:39.277492Z","iopub.execute_input":"2025-05-17T14:33:39.277693Z","iopub.status.idle":"2025-05-17T14:33:39.293057Z","shell.execute_reply.started":"2025-05-17T14:33:39.277676Z","shell.execute_reply":"2025-05-17T14:33:39.292504Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# Create data loaders\ntrain_loader, val_loader, test_loader, src_vocab, tgt_vocab = prepare_data_loaders(train_path, val_path, test_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T14:33:39.293964Z","iopub.execute_input":"2025-05-17T14:33:39.294225Z","iopub.status.idle":"2025-05-17T14:33:42.077418Z","shell.execute_reply.started":"2025-05-17T14:33:39.294203Z","shell.execute_reply":"2025-05-17T14:33:42.076850Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# Print vocabulary sizes\nprint(f\"Source (English) vocabulary size: {src_vocab.size}\")\nprint(f\"Target (Tamil) vocabulary size: {tgt_vocab.size}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T14:33:42.080003Z","iopub.execute_input":"2025-05-17T14:33:42.080198Z","iopub.status.idle":"2025-05-17T14:33:42.084462Z","shell.execute_reply.started":"2025-05-17T14:33:42.080184Z","shell.execute_reply":"2025-05-17T14:33:42.083602Z"}},"outputs":[{"name":"stdout","text":"Source (English) vocabulary size: 30\nTarget (Tamil) vocabulary size: 50\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"## defining models","metadata":{}},{"cell_type":"code","source":"class Attention(nn.Module):\n    def __init__(self, hidden_size, attention_type='bahdanau'):\n        super(Attention, self).__init__()\n        self.hidden_size = hidden_size\n        self.attention_type = attention_type.lower()\n        \n        if self.attention_type == 'bahdanau':\n            self.Wa = nn.Linear(hidden_size * 2, hidden_size)\n            self.Ua = nn.Linear(hidden_size, 1, bias=False)\n        elif self.attention_type == 'dot':\n            pass  # Dot-product attention uses no additional parameters\n        else:\n            raise ValueError(\"Unsupported attention type. Use 'bahdanau' or 'dot'.\")\n\n    def forward(self, decoder_hidden, encoder_outputs):\n        # decoder_hidden: (num_layers, batch_size, hidden_size) or tuple for LSTM\n        # encoder_outputs: (batch_size, seq_len, hidden_size)\n        batch_size = encoder_outputs.size(0)\n        seq_len = encoder_outputs.size(1)\n        \n        # Validate encoder_outputs shape\n        assert encoder_outputs.dim() == 3, f\"Expected encoder_outputs to be 3D, got {encoder_outputs.shape}\"\n        assert encoder_outputs.size(2) == self.hidden_size, f\"Expected encoder_outputs hidden_size {self.hidden_size}, got {encoder_outputs.size(2)}\"\n        \n        # Extract the last layer of decoder hidden state\n        if isinstance(decoder_hidden, tuple):  # LSTM case\n            decoder_hidden = decoder_hidden[0]  # Take hidden state, not cell state\n        decoder_hidden = decoder_hidden[-1]  # (batch_size, hidden_size)\n        \n        assert decoder_hidden.dim() == 2, f\"Expected decoder_hidden to be 2D, got {decoder_hidden.shape}\"\n        assert decoder_hidden.size(1) == self.hidden_size, f\"Expected decoder_hidden hidden_size {self.hidden_size}, got {decoder_hidden.size(1)}\"\n        \n        if self.attention_type == 'bahdanau':\n            # Repeat decoder hidden to match seq_len\n            decoder_hidden = decoder_hidden.unsqueeze(1).repeat(1, seq_len, 1)  # (batch_size, seq_len, hidden_size)\n            # Combine with encoder outputs\n            combined = torch.cat((decoder_hidden, encoder_outputs), dim=2)  # (batch_size, seq_len, hidden_size*2)\n            # Compute energy\n            energy = torch.tanh(self.Wa(combined))  # (batch_size, seq_len, hidden_size)\n            attention_scores = self.Ua(energy).squeeze(2)  # (batch_size, seq_len)\n        else:  # dot\n            # Compute dot-product attention\n            decoder_hidden = decoder_hidden.unsqueeze(1)  # (batch_size, 1, hidden_size)\n            encoder_outputs_t = encoder_outputs.transpose(1, 2)  # (batch_size, hidden_size, seq_len)\n            # Verify shapes before bmm\n            assert decoder_hidden.shape == (batch_size, 1, self.hidden_size), f\"Expected decoder_hidden (batch_size, 1, hidden_size), got {decoder_hidden.shape}\"\n            assert encoder_outputs_t.shape == (batch_size, self.hidden_size, seq_len), f\"Expected encoder_outputs_t (batch_size, hidden_size, seq_len), got {encoder_outputs_t.shape}\"\n            attention_scores = torch.bmm(decoder_hidden, encoder_outputs_t).squeeze(1)  # (batch_size, seq_len)\n        \n        # Softmax to get attention weights\n        attention_weights = F.softmax(attention_scores, dim=1)  # (batch_size, seq_len)\n        # Compute context vector\n        context = torch.bmm(attention_weights.unsqueeze(1), encoder_outputs).squeeze(1)  # (batch_size, hidden_size)\n        \n        return context, attention_weights","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T14:33:42.085425Z","iopub.execute_input":"2025-05-17T14:33:42.086219Z","iopub.status.idle":"2025-05-17T14:33:42.240718Z","shell.execute_reply.started":"2025-05-17T14:33:42.086193Z","shell.execute_reply":"2025-05-17T14:33:42.239917Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"class EncoderRNN(nn.Module):\n    def __init__(self, input_size, embed_size, hidden_size, cell_type='RNN', num_layers=1, dropout=0.0):\n        super(EncoderRNN, self).__init__()\n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n        self.embedding = nn.Embedding(input_size, embed_size)\n        self.cell_type = cell_type.upper()\n        \n        rnn_class = {'RNN': nn.RNN, 'LSTM': nn.LSTM, 'GRU': nn.GRU}[self.cell_type]\n        self.rnn = rnn_class(\n            input_size=embed_size,\n            hidden_size=hidden_size,\n            num_layers=num_layers,\n            batch_first=True,\n            dropout=dropout if num_layers > 1 else 0.0\n        )\n\n    def forward(self, input_seq):\n        embedded = self.embedding(input_seq)\n        if self.cell_type == 'LSTM':\n            outputs, (hidden, cell) = self.rnn(embedded)\n            return outputs, (hidden, cell)\n        else:\n            outputs, hidden = self.rnn(embedded)\n            return outputs, hidden","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T14:33:42.241638Z","iopub.execute_input":"2025-05-17T14:33:42.241908Z","iopub.status.idle":"2025-05-17T14:33:42.260784Z","shell.execute_reply.started":"2025-05-17T14:33:42.241851Z","shell.execute_reply":"2025-05-17T14:33:42.260103Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"class DecoderRNN(nn.Module):\n    def __init__(self, output_size, embed_size, hidden_size, cell_type='RNN', num_layers=1, dropout=0.0, attention_type='bahdanau'):\n        super(DecoderRNN, self).__init__()\n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n        self.embedding = nn.Embedding(output_size, embed_size)\n        self.dropout = nn.Dropout(dropout)\n        self.cell_type = cell_type.upper()\n        \n        rnn_class = {'RNN': nn.RNN, 'LSTM': nn.LSTM, 'GRU': nn.GRU}[self.cell_type]\n        self.rnn = rnn_class(\n            input_size=embed_size + hidden_size,  # Input includes context vector\n            hidden_size=hidden_size,\n            num_layers=num_layers,\n            batch_first=True,\n            dropout=dropout if num_layers > 1 else 0.0\n        )\n        self.attention = Attention(hidden_size, attention_type)\n        self.out = nn.Linear(hidden_size * 2, output_size)  # Combine RNN output and context\n\n    def forward(self, input_char, hidden, encoder_outputs):\n        embedded = self.embedding(input_char).unsqueeze(1)  # (batch_size, 1, embed_size)\n        embedded = self.dropout(embedded)\n        \n        # Compute attention\n        context, attention_weights = self.attention(hidden, encoder_outputs)  # context: (batch_size, hidden_size)\n        \n        # Concatenate context with embedded input\n        rnn_input = torch.cat((embedded, context.unsqueeze(1)), dim=2)  # (batch_size, 1, embed_size + hidden_size)\n        \n        if self.cell_type == 'LSTM':\n            output, (hidden, cell) = self.rnn(rnn_input, hidden)\n            output = output.squeeze(1)  # (batch_size, hidden_size)\n            output = torch.cat((output, context), dim=1)  # (batch_size, hidden_size * 2)\n            output = self.out(output)  # (batch_size, output_size)\n            return output, (hidden, cell), attention_weights\n        else:\n            output, hidden = self.rnn(rnn_input, hidden)\n            output = output.squeeze(1)\n            output = torch.cat((output, context), dim=1)\n            output = self.out(output)\n            return output, hidden, attention_weights\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T14:33:42.261586Z","iopub.execute_input":"2025-05-17T14:33:42.261789Z","iopub.status.idle":"2025-05-17T14:33:42.277591Z","shell.execute_reply.started":"2025-05-17T14:33:42.261773Z","shell.execute_reply":"2025-05-17T14:33:42.276827Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"class Seq2Seq(nn.Module):\n    def __init__(self, encoder, decoder):\n        super(Seq2Seq, self).__init__()\n        self.encoder = encoder\n        self.decoder = decoder\n\n    def forward(self, source, target, teacher_forcing_ratio=0.5):\n        batch_size = source.size(0)\n        target_len = target.size(1)\n        outputs = torch.zeros(batch_size, target_len, self.decoder.out.out_features).to(source.device)\n        \n        encoder_outputs, hidden = self.encoder(source)\n        \n        decoder_input = target[:, 0]\n        \n        # Handle differing encoder/decoder layers\n        if self.encoder.cell_type == 'LSTM':\n            hidden, cell = hidden\n            if self.encoder.num_layers != self.decoder.num_layers:\n                factor = self.decoder.num_layers // self.encoder.num_layers + 1\n                hidden = hidden.repeat(factor, 1, 1)[:self.decoder.num_layers]\n                cell = cell.repeat(factor, 1, 1)[:self.decoder.num_layers]\n            hidden = (hidden, cell)\n        else:\n            if self.encoder.num_layers != self.decoder.num_layers:\n                factor = self.decoder.num_layers // self.encoder.num_layers + 1\n                hidden = hidden.repeat(factor, 1, 1)[:self.decoder.num_layers]\n        \n        for t in range(1, target_len):\n            output, hidden, _ = self.decoder(decoder_input, hidden, encoder_outputs)\n            outputs[:, t, :] = output\n            teacher_force = torch.rand(1).item() < teacher_forcing_ratio\n            top1 = output.argmax(1)\n            decoder_input = target[:, t] if teacher_force else top1\n\n        return outputs\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T14:33:42.278368Z","iopub.execute_input":"2025-05-17T14:33:42.278595Z","iopub.status.idle":"2025-05-17T14:33:42.296769Z","shell.execute_reply.started":"2025-05-17T14:33:42.278578Z","shell.execute_reply":"2025-05-17T14:33:42.296093Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"def create_model(input_vocab_size, output_vocab_size, embed_size=256, hidden_size=512, \n                 cell_type='RNN', encoder_layers=1, decoder_layers=1, dropout=0.0, attention_type='bahdanau'):\n    encoder = EncoderRNN(input_vocab_size, embed_size, hidden_size, cell_type, encoder_layers, dropout)\n    decoder = DecoderRNN(output_vocab_size, embed_size, hidden_size, cell_type, decoder_layers, dropout, attention_type)\n    model = Seq2Seq(encoder, decoder)\n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T14:33:42.297490Z","iopub.execute_input":"2025-05-17T14:33:42.297708Z","iopub.status.idle":"2025-05-17T14:33:42.316296Z","shell.execute_reply.started":"2025-05-17T14:33:42.297680Z","shell.execute_reply":"2025-05-17T14:33:42.315715Z"}},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":"## setting up wandb","metadata":{}},{"cell_type":"code","source":"!pip install wandb -q","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T14:33:42.317055Z","iopub.execute_input":"2025-05-17T14:33:42.317297Z","iopub.status.idle":"2025-05-17T14:33:46.563182Z","shell.execute_reply.started":"2025-05-17T14:33:42.317275Z","shell.execute_reply":"2025-05-17T14:33:46.562374Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"import wandb","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T14:33:46.564159Z","iopub.execute_input":"2025-05-17T14:33:46.564439Z","iopub.status.idle":"2025-05-17T14:33:49.391757Z","shell.execute_reply.started":"2025-05-17T14:33:46.564407Z","shell.execute_reply":"2025-05-17T14:33:49.391181Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_value_0 = user_secrets.get_secret(\"wandb\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T14:33:49.392492Z","iopub.execute_input":"2025-05-17T14:33:49.392841Z","iopub.status.idle":"2025-05-17T14:33:49.581955Z","shell.execute_reply.started":"2025-05-17T14:33:49.392823Z","shell.execute_reply":"2025-05-17T14:33:49.581161Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"wandb.login(key=secret_value_0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T14:33:49.582777Z","iopub.execute_input":"2025-05-17T14:33:49.582978Z","iopub.status.idle":"2025-05-17T14:33:56.190685Z","shell.execute_reply.started":"2025-05-17T14:33:49.582963Z","shell.execute_reply":"2025-05-17T14:33:56.190064Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mda24m007\u001b[0m (\u001b[33mda24m007-iit-madras\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":19},{"cell_type":"markdown","source":"## Running wandb sweep","metadata":{}},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T14:33:56.191383Z","iopub.execute_input":"2025-05-17T14:33:56.191837Z","iopub.status.idle":"2025-05-17T14:33:56.248221Z","shell.execute_reply.started":"2025-05-17T14:33:56.191813Z","shell.execute_reply":"2025-05-17T14:33:56.247404Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"# Beam search decoding (adapted for attention)\ndef beam_search_decode(model, src, max_len, beam_width, sos_idx, eos_idx):\n    model.eval()\n    src = src.to(device)\n    batch_size = src.size(0)\n    encoder_outputs, hidden = model.encoder(src)\n    \n    if model.encoder.cell_type == 'LSTM':\n        hidden, cell = hidden\n        if model.encoder.num_layers != model.decoder.num_layers:\n            factor = model.decoder.num_layers // model.encoder.num_layers\n            if factor > 1:\n                hidden = hidden.repeat(factor, 1, 1)\n                cell = cell.repeat(factor, 1, 1)\n            else:\n                hidden = hidden[-model.decoder.num_layers:]\n                cell = cell[-model.decoder.num_layers:]\n        hidden = (hidden, cell)\n    else:\n        if model.encoder.num_layers != model.decoder.num_layers:\n            factor = model.decoder.num_layers // model.encoder.num_layers\n            if factor > 1:\n                hidden = hidden.repeat(factor, 1, 1)\n            else:\n                hidden = hidden[-model.decoder.num_layers:]\n    \n    beams = [(torch.tensor([sos_idx], device=device), hidden, 0.0)]\n    completed = []\n    \n    for _ in range(max_len):\n        new_beams = []\n        for seq, hid, score in beams:\n            if seq[-1].item() == eos_idx:\n                completed.append((seq, score))\n                continue\n            output, new_hidden, _ = model.decoder(seq[-1].unsqueeze(0), hid, encoder_outputs)\n            probs = torch.softmax(output, dim=-1)\n            top_probs, top_idx = probs.topk(beam_width)\n            \n            for i in range(beam_width):\n                new_seq = torch.cat([seq, top_idx[:, i]])\n                new_score = score - math.log(top_probs[:, i].item())\n                new_beams.append((new_seq, new_hidden, new_score))\n        \n        new_beams = sorted(new_beams, key=lambda x: x[2])[:beam_width]\n        beams = new_beams\n        \n        if len(completed) >= beam_width:\n            break\n    \n    completed = sorted(completed, key=lambda x: x[1])\n    if completed:\n        return completed[0][0]\n    return beams[0][0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T14:33:56.249095Z","iopub.execute_input":"2025-05-17T14:33:56.249332Z","iopub.status.idle":"2025-05-17T14:33:56.263038Z","shell.execute_reply.started":"2025-05-17T14:33:56.249314Z","shell.execute_reply":"2025-05-17T14:33:56.262488Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"# Training and evaluation function\ndef train_and_evaluate():\n    wandb.init()\n    config = wandb.config\n    \n    # Create model with sweep parameters\n    model = create_model(\n        input_vocab_size=src_vocab.size,\n        output_vocab_size=tgt_vocab.size,\n        embed_size=config.embed_size,\n        hidden_size=config.hidden_size,\n        cell_type=config.cell_type,\n        encoder_layers=1,  # Single layer\n        decoder_layers=1,  # Single layer\n        dropout=config.dropout,\n        attention_type=config.attention_type\n    ).to(device)\n    \n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n    criterion = nn.CrossEntropyLoss(ignore_index=0)\n    \n    for epoch in range(10):\n        model.train()\n        train_loss = 0\n        for src, tgt in train_loader:\n            src, tgt = src.to(device), tgt.to(device)\n            optimizer.zero_grad()\n            output = model(src, tgt, teacher_forcing_ratio=0.5)\n            output = output[:, 1:].reshape(-1, output.size(-1))\n            tgt_flat = tgt[:, 1:].reshape(-1)\n            loss = criterion(output, tgt_flat)\n            loss.backward()\n            optimizer.step()\n            train_loss += loss.item()\n        \n        # Compute training accuracy on one batch\n        model.eval()\n        train_correct = 0\n        train_total = 0\n        with torch.no_grad():\n            for src, tgt in train_loader:\n                src, tgt = src.to(device), tgt.to(device)\n                for i in range(src.size(0)):\n                    pred = beam_search_decode(\n                        model, src[i:i+1], max_len=50,\n                        beam_width=config.beam_width,\n                        sos_idx=tgt_vocab.char2idx['<SOS>'],\n                        eos_idx=tgt_vocab.char2idx['<EOS>']\n                    )\n                    pred_str = ''.join([tgt_vocab.idx2char[idx.item()] for idx in pred if idx.item() not in [0, 1, 2]])\n                    tgt_seq = tgt[i]\n                    tgt_str = ''.join([tgt_vocab.idx2char[idx.item()] for idx in tgt_seq[1:] if idx.item() not in [0, 1, 2]])\n                    if pred_str == tgt_str:\n                        train_correct += 1\n                    train_total += 1\n                break\n        \n        # Compute validation loss and accuracy\n        val_loss = 0\n        val_correct = 0\n        val_total = 0\n        with torch.no_grad():\n            for src, tgt in val_loader:\n                src, tgt = src.to(device), tgt.to(device)\n                output = model(src, tgt, teacher_forcing_ratio=0.0)\n                output = output[:, 1:].reshape(-1, output.size(-1))\n                tgt_flat = tgt[:, 1:].reshape(-1)\n                loss = criterion(output, tgt_flat)\n                val_loss += loss.item()\n            \n            # Validation accuracy on one batch\n            for src, tgt in val_loader:\n                src, tgt = src.to(device), tgt.to(device)\n                for i in range(src.size(0)):\n                    pred = beam_search_decode(\n                        model, src[i:i+1], max_len=50,\n                        beam_width=config.beam_width,\n                        sos_idx=tgt_vocab.char2idx['<SOS>'],\n                        eos_idx=tgt_vocab.char2idx['<EOS>']\n                    )\n                    pred_str = ''.join([tgt_vocab.idx2char[idx.item()] for idx in pred if idx.item() not in [0, 1, 2]])\n                    tgt_seq = tgt[i]\n                    tgt_str = ''.join([tgt_vocab.idx2char[idx.item()] for idx in tgt_seq[1:] if idx.item() not in [0, 1, 2]])\n                    if pred_str == tgt_str:\n                        val_correct += 1\n                    val_total += 1\n                break\n        \n        # Log metrics to WandB\n        wandb.log({\n            \"epoch\": epoch,\n            \"train_loss\": train_loss / len(train_loader),\n            \"val_loss\": val_loss / len(val_loader),\n            \"train_accuracy\": train_correct / train_total,\n            \"val_accuracy\": val_correct / val_total\n        })\n        print(f\"Epoch {epoch+1}, Train Loss: {train_loss / len(train_loader):.4f}, Val Accuracy: {val_correct / val_total:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T14:33:56.263648Z","iopub.execute_input":"2025-05-17T14:33:56.263841Z","iopub.status.idle":"2025-05-17T14:33:56.278076Z","shell.execute_reply.started":"2025-05-17T14:33:56.263826Z","shell.execute_reply":"2025-05-17T14:33:56.277361Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"# WandB sweep configuration\nsweep_config = {\n    'method': 'bayes',\n    'metric': {\n        'name': 'val_accuracy',\n        'goal': 'maximize'\n    },\n    'parameters': {\n        'embed_size': {\n            'values': [64, 128, 256]\n        },\n        'hidden_size': {\n            'values': [128, 256, 512]\n        },\n        'cell_type': {\n            'values': ['RNN', 'GRU', 'LSTM']\n        },\n        'dropout': {\n            'values': [0.2, 0.3]\n        },\n        'beam_width': {\n            'values': [1, 3, 5]\n        },\n        'attention_type': {\n            'values': ['bahdanau', 'dot']\n        }\n    }\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T14:33:56.278841Z","iopub.execute_input":"2025-05-17T14:33:56.279107Z","iopub.status.idle":"2025-05-17T14:33:56.294479Z","shell.execute_reply.started":"2025-05-17T14:33:56.279086Z","shell.execute_reply":"2025-05-17T14:33:56.293908Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"# Initialize and run sweep\nsweep_id = wandb.sweep(sweep_config, project=\"DL-A3\")\nwandb.agent(sweep_id, function=train_and_evaluate, count=20)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T17:53:57.185185Z","iopub.execute_input":"2025-05-15T17:53:57.185394Z","execution_failed":"2025-05-15T17:57:35.974Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Training with best set of hyperparameters","metadata":{}},{"cell_type":"code","source":"wandb.init(project=\"DL-A3\", name=\"final_model_training_with_attention\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T14:34:19.860118Z","iopub.execute_input":"2025-05-17T14:34:19.860405Z","iopub.status.idle":"2025-05-17T14:34:26.508623Z","shell.execute_reply.started":"2025-05-17T14:34:19.860386Z","shell.execute_reply":"2025-05-17T14:34:26.507897Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250517_143419-isr6v98q</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/da24m007-iit-madras/DL-A3/runs/isr6v98q' target=\"_blank\">final_model_training_with_attention</a></strong> to <a href='https://wandb.ai/da24m007-iit-madras/DL-A3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/da24m007-iit-madras/DL-A3' target=\"_blank\">https://wandb.ai/da24m007-iit-madras/DL-A3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/da24m007-iit-madras/DL-A3/runs/isr6v98q' target=\"_blank\">https://wandb.ai/da24m007-iit-madras/DL-A3/runs/isr6v98q</a>"},"metadata":{}},{"execution_count":24,"output_type":"execute_result","data":{"text/html":"<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/da24m007-iit-madras/DL-A3/runs/isr6v98q?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>","text/plain":"<wandb.sdk.wandb_run.Run at 0x7a42f05dbb90>"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"# Function to retrieve best hyperparameters from WandB sweep\ndef get_best_hyperparameters(project_name=\"DL-A3\"):\n    api = wandb.Api()\n    runs = api.runs(project_name)\n    best_run = None\n    best_val_accuracy = -float('inf')\n    \n    for run in runs:\n        if 'val_accuracy' in run.summary and run.summary['val_accuracy'] > best_val_accuracy:\n            best_val_accuracy = run.summary['val_accuracy']\n            best_run = run\n    \n    if best_run is None:\n        raise ValueError(\"No runs found with val_accuracy in WandB project\")\n    \n    # Extract hyperparameters\n    config = best_run.config\n    return {\n            'attention_type': config['attention_type'],\n                'cell_type': config['cell_type'],\n                'embed_size': config['embed_size'],\n                'hidden_size': config['hidden_size'],\n                'dropout': config['dropout'],\n                'beam_width': config['beam_width']\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T14:34:28.781271Z","iopub.execute_input":"2025-05-17T14:34:28.781990Z","iopub.status.idle":"2025-05-17T14:34:28.787823Z","shell.execute_reply.started":"2025-05-17T14:34:28.781965Z","shell.execute_reply":"2025-05-17T14:34:28.787225Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"# Training and evaluation function\ndef train_model(model, train_loader, val_loader, test_loader, num_epochs=30, beam_width=3):\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n    criterion = nn.CrossEntropyLoss(ignore_index=0)\n    \n    for epoch in range(num_epochs):\n        model.train()\n        train_loss = 0\n        for src, tgt in train_loader:\n            src, tgt = src.to(device), tgt.to(device)\n            optimizer.zero_grad()\n            output = model(src, tgt, teacher_forcing_ratio=0.5)\n            output = output[:, 1:].reshape(-1, output.size(-1))\n            tgt_flat = tgt[:, 1:].reshape(-1)\n            loss = criterion(output, tgt_flat)\n            loss.backward()\n            optimizer.step()\n            train_loss += loss.item()\n        \n        # Compute validation loss and accuracy (one batch for speed)\n        model.eval()\n        val_loss = 0\n        val_correct = 0\n        val_total = 0\n        with torch.no_grad():\n            for src, tgt in val_loader:\n                src, tgt = src.to(device), tgt.to(device)\n                output = model(src, tgt, teacher_forcing_ratio=0.0)\n                output = output[:, 1:].reshape(-1, output.size(-1))\n                tgt_flat = tgt[:, 1:].reshape(-1)\n                loss = criterion(output, tgt_flat)\n                val_loss += loss.item()\n                \n                # Compute accuracy on one batch\n                print(f\"Epoch {epoch+1}, Validation batch - src shape: {src.shape}, tgt shape: {tgt.shape}\")\n                for i in range(src.size(0)):\n                    pred = beam_search_decode(\n                        model, src[i:i+1], max_len=50,\n                        beam_width=beam_width,\n                        sos_idx=tgt_vocab.char2idx['<SOS>'],\n                        eos_idx=tgt_vocab.char2idx['<EOS>']\n                    )\n                    pred_str = ''.join([tgt_vocab.idx2char[idx.item()] for idx in pred if idx.item() not in [0, 1, 2]])\n                    tgt_seq = tgt[i]\n                    tgt_str = ''.join([tgt_vocab.idx2char[idx.item()] for idx in tgt_seq[1:] if idx.item() not in [0, 1, 2]])\n                    if pred_str == tgt_str:\n                        val_correct += 1\n                    val_total += 1\n                break  # Process only one batch for validation accuracy\n        \n        # Log metrics to WandB\n        wandb.log({\n            \"epoch\": epoch,\n            \"train_loss\": train_loss / len(train_loader),\n            \"val_loss\": val_loss / len(val_loader),\n            \"val_accuracy\": val_correct / val_total\n        })\n        print(f\"Epoch {epoch+1}, Train Loss: {train_loss / len(train_loader):.4f}, Val Loss: {val_loss / len(val_loader):.4f}, Val Accuracy: {val_correct / val_total:.4f}\")\n    \n    # Compute test accuracy and save predictions\n    test_correct = 0\n    test_total = 0\n    predictions = []\n    with torch.no_grad():\n        for src, tgt in test_loader:\n            src, tgt = src.to(device), tgt.to(device)\n            print(f\"Test batch - src shape: {src.shape}, tgt shape: {tgt.shape}\")\n            for i in range(src.size(0)):\n                pred = beam_search_decode(\n                    model, src[i:i+1], max_len=50,\n                    beam_width=beam_width,\n                    sos_idx=tgt_vocab.char2idx['<SOS>'],\n                    eos_idx=tgt_vocab.char2idx['<EOS>']\n                )\n                pred_str = ''.join([tgt_vocab.idx2char[idx.item()] for idx in pred if idx.item() not in [0, 1, 2]])\n                tgt_seq = tgt[i]\n                tgt_str = ''.join([tgt_vocab.idx2char[idx.item()] for idx in tgt_seq[1:] if idx.item() not in [0, 1, 2]])\n                src_str = ''.join([src_vocab.idx2char[idx.item()] for idx in src[i, 1:] if idx.item() not in [0, 1, 2]])\n                if pred_str == tgt_str:\n                    test_correct += 1\n                test_total += 1\n                predictions.append({\n                    'input_english': src_str,\n                    'actual_tamil': tgt_str,\n                    'predicted_tamil': pred_str\n                })\n    \n    test_accuracy = test_correct / test_total\n    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n    \n    # Save predictions to CSV\n    predictions_df = pd.DataFrame(predictions)\n    predictions_df.to_csv('test_predictions_attention.csv', index=False)\n    print(\"Test predictions saved to 'test_predictions.csv'\")\n    \n    return test_accuracy","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T14:34:30.814195Z","iopub.execute_input":"2025-05-17T14:34:30.814901Z","iopub.status.idle":"2025-05-17T14:34:30.828547Z","shell.execute_reply.started":"2025-05-17T14:34:30.814864Z","shell.execute_reply":"2025-05-17T14:34:30.827949Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"# Get best hyperparameters\ntry:\n    best_params = get_best_hyperparameters()\n    print(\"Best hyperparameters from WandB sweep:\", best_params)\nexcept Exception as e:\n    print(f\"Error retrieving hyperparameters: {e}\")\n    print(\"Using default hyperparameters as fallback\")\n    best_params = {\n        'embed_size': 256,\n        'hidden_size': 512,\n        'cell_type': 'LSTM',\n        'encoder_layers': 2,\n        'decoder_layers': 1,\n        'dropout': 0.2,\n        'beam_width': 5\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T14:34:34.441935Z","iopub.execute_input":"2025-05-17T14:34:34.442512Z","iopub.status.idle":"2025-05-17T14:34:39.824505Z","shell.execute_reply.started":"2025-05-17T14:34:34.442490Z","shell.execute_reply":"2025-05-17T14:34:39.823937Z"}},"outputs":[{"name":"stdout","text":"Best hyperparameters from WandB sweep: {'attention_type': 'bahdanau', 'cell_type': 'GRU', 'embed_size': 128, 'hidden_size': 128, 'dropout': 0.2, 'beam_width': 5}\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"# Create model with best parameters\nmodel = create_model(\n    input_vocab_size=src_vocab.size,\n    output_vocab_size=tgt_vocab.size,\n    embed_size=best_params['embed_size'],\n    hidden_size=best_params['hidden_size'],\n    cell_type=best_params['cell_type'],\n    encoder_layers=1,\n    decoder_layers=1,\n    dropout=best_params['dropout']\n).to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T14:34:44.103436Z","iopub.execute_input":"2025-05-17T14:34:44.104147Z","iopub.status.idle":"2025-05-17T14:34:44.411611Z","shell.execute_reply.started":"2025-05-17T14:34:44.104123Z","shell.execute_reply":"2025-05-17T14:34:44.410846Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T14:34:46.032580Z","iopub.execute_input":"2025-05-17T14:34:46.033197Z","iopub.status.idle":"2025-05-17T14:34:46.039509Z","shell.execute_reply.started":"2025-05-17T14:34:46.033173Z","shell.execute_reply":"2025-05-17T14:34:46.038700Z"}},"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"Seq2Seq(\n  (encoder): EncoderRNN(\n    (embedding): Embedding(30, 128)\n    (rnn): GRU(128, 128, batch_first=True)\n  )\n  (decoder): DecoderRNN(\n    (embedding): Embedding(50, 128)\n    (dropout): Dropout(p=0.2, inplace=False)\n    (rnn): GRU(256, 128, batch_first=True)\n    (attention): Attention(\n      (Wa): Linear(in_features=256, out_features=128, bias=True)\n      (Ua): Linear(in_features=128, out_features=1, bias=False)\n    )\n    (out): Linear(in_features=256, out_features=50, bias=True)\n  )\n)"},"metadata":{}}],"execution_count":29},{"cell_type":"code","source":"# Train and evaluate\ntest_accuracy = train_model(\n    model, train_loader, val_loader, test_loader,\n    num_epochs=30, beam_width=best_params['beam_width']\n)\n\n# Log test accuracy to WandB\nwandb.log({\"test_accuracy\": test_accuracy})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T14:34:48.684761Z","iopub.execute_input":"2025-05-17T14:34:48.685375Z","iopub.status.idle":"2025-05-17T15:26:28.586705Z","shell.execute_reply.started":"2025-05-17T14:34:48.685338Z","shell.execute_reply":"2025-05-17T15:26:28.585919Z"}},"outputs":[{"name":"stdout","text":"Epoch 1, Validation batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 15])\nEpoch 1, Train Loss: 0.7389, Val Loss: 0.0062, Val Accuracy: 0.5625\nEpoch 2, Validation batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 15])\nEpoch 2, Train Loss: 0.4032, Val Loss: 0.0055, Val Accuracy: 0.3750\nEpoch 3, Validation batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 15])\nEpoch 3, Train Loss: 0.3514, Val Loss: 0.0057, Val Accuracy: 0.3125\nEpoch 4, Validation batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 15])\nEpoch 4, Train Loss: 0.3217, Val Loss: 0.0045, Val Accuracy: 0.5938\nEpoch 5, Validation batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 15])\nEpoch 5, Train Loss: 0.2948, Val Loss: 0.0066, Val Accuracy: 0.5625\nEpoch 6, Validation batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 15])\nEpoch 6, Train Loss: 0.2783, Val Loss: 0.0055, Val Accuracy: 0.5312\nEpoch 7, Validation batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 15])\nEpoch 7, Train Loss: 0.2659, Val Loss: 0.0061, Val Accuracy: 0.5625\nEpoch 8, Validation batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 15])\nEpoch 8, Train Loss: 0.2510, Val Loss: 0.0051, Val Accuracy: 0.5625\nEpoch 9, Validation batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 15])\nEpoch 9, Train Loss: 0.2404, Val Loss: 0.0061, Val Accuracy: 0.4062\nEpoch 10, Validation batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 15])\nEpoch 10, Train Loss: 0.2333, Val Loss: 0.0053, Val Accuracy: 0.5625\nEpoch 11, Validation batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 15])\nEpoch 11, Train Loss: 0.2251, Val Loss: 0.0056, Val Accuracy: 0.5625\nEpoch 12, Validation batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 15])\nEpoch 12, Train Loss: 0.2192, Val Loss: 0.0057, Val Accuracy: 0.5938\nEpoch 13, Validation batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 15])\nEpoch 13, Train Loss: 0.2124, Val Loss: 0.0063, Val Accuracy: 0.5000\nEpoch 14, Validation batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 15])\nEpoch 14, Train Loss: 0.2044, Val Loss: 0.0063, Val Accuracy: 0.6250\nEpoch 15, Validation batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 15])\nEpoch 15, Train Loss: 0.2032, Val Loss: 0.0067, Val Accuracy: 0.5625\nEpoch 16, Validation batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 15])\nEpoch 16, Train Loss: 0.1999, Val Loss: 0.0058, Val Accuracy: 0.6250\nEpoch 17, Validation batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 15])\nEpoch 17, Train Loss: 0.1949, Val Loss: 0.0065, Val Accuracy: 0.5938\nEpoch 18, Validation batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 15])\nEpoch 18, Train Loss: 0.1869, Val Loss: 0.0065, Val Accuracy: 0.6250\nEpoch 19, Validation batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 15])\nEpoch 19, Train Loss: 0.1885, Val Loss: 0.0054, Val Accuracy: 0.5938\nEpoch 20, Validation batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 15])\nEpoch 20, Train Loss: 0.1821, Val Loss: 0.0064, Val Accuracy: 0.5938\nEpoch 21, Validation batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 15])\nEpoch 21, Train Loss: 0.1801, Val Loss: 0.0071, Val Accuracy: 0.5000\nEpoch 22, Validation batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 15])\nEpoch 22, Train Loss: 0.1779, Val Loss: 0.0066, Val Accuracy: 0.5625\nEpoch 23, Validation batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 15])\nEpoch 23, Train Loss: 0.1777, Val Loss: 0.0072, Val Accuracy: 0.5938\nEpoch 24, Validation batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 15])\nEpoch 24, Train Loss: 0.1732, Val Loss: 0.0061, Val Accuracy: 0.5938\nEpoch 25, Validation batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 15])\nEpoch 25, Train Loss: 0.1708, Val Loss: 0.0061, Val Accuracy: 0.6250\nEpoch 26, Validation batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 15])\nEpoch 26, Train Loss: 0.1704, Val Loss: 0.0076, Val Accuracy: 0.5938\nEpoch 27, Validation batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 15])\nEpoch 27, Train Loss: 0.1671, Val Loss: 0.0074, Val Accuracy: 0.5312\nEpoch 28, Validation batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 15])\nEpoch 28, Train Loss: 0.1663, Val Loss: 0.0066, Val Accuracy: 0.6250\nEpoch 29, Validation batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 15])\nEpoch 29, Train Loss: 0.1640, Val Loss: 0.0072, Val Accuracy: 0.5938\nEpoch 30, Validation batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 15])\nEpoch 30, Train Loss: 0.1625, Val Loss: 0.0070, Val Accuracy: 0.5938\nTest batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 15])\nTest batch - src shape: torch.Size([32, 23]), tgt shape: torch.Size([32, 19])\nTest batch - src shape: torch.Size([32, 15]), tgt shape: torch.Size([32, 15])\nTest batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 17])\nTest batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 17])\nTest batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 17])\nTest batch - src shape: torch.Size([32, 21]), tgt shape: torch.Size([32, 17])\nTest batch - src shape: torch.Size([32, 18]), tgt shape: torch.Size([32, 19])\nTest batch - src shape: torch.Size([32, 16]), tgt shape: torch.Size([32, 17])\nTest batch - src shape: torch.Size([32, 16]), tgt shape: torch.Size([32, 17])\nTest batch - src shape: torch.Size([32, 17]), tgt shape: torch.Size([32, 14])\nTest batch - src shape: torch.Size([32, 17]), tgt shape: torch.Size([32, 12])\nTest batch - src shape: torch.Size([32, 18]), tgt shape: torch.Size([32, 14])\nTest batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 15])\nTest batch - src shape: torch.Size([32, 18]), tgt shape: torch.Size([32, 15])\nTest batch - src shape: torch.Size([32, 18]), tgt shape: torch.Size([32, 15])\nTest batch - src shape: torch.Size([32, 18]), tgt shape: torch.Size([32, 19])\nTest batch - src shape: torch.Size([32, 17]), tgt shape: torch.Size([32, 16])\nTest batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 19])\nTest batch - src shape: torch.Size([32, 16]), tgt shape: torch.Size([32, 13])\nTest batch - src shape: torch.Size([32, 21]), tgt shape: torch.Size([32, 16])\nTest batch - src shape: torch.Size([32, 22]), tgt shape: torch.Size([32, 19])\nTest batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 17])\nTest batch - src shape: torch.Size([32, 14]), tgt shape: torch.Size([32, 13])\nTest batch - src shape: torch.Size([32, 16]), tgt shape: torch.Size([32, 14])\nTest batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 17])\nTest batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 14])\nTest batch - src shape: torch.Size([32, 14]), tgt shape: torch.Size([32, 13])\nTest batch - src shape: torch.Size([32, 15]), tgt shape: torch.Size([32, 14])\nTest batch - src shape: torch.Size([32, 14]), tgt shape: torch.Size([32, 13])\nTest batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 18])\nTest batch - src shape: torch.Size([32, 17]), tgt shape: torch.Size([32, 18])\nTest batch - src shape: torch.Size([32, 14]), tgt shape: torch.Size([32, 14])\nTest batch - src shape: torch.Size([32, 18]), tgt shape: torch.Size([32, 17])\nTest batch - src shape: torch.Size([32, 17]), tgt shape: torch.Size([32, 18])\nTest batch - src shape: torch.Size([32, 14]), tgt shape: torch.Size([32, 15])\nTest batch - src shape: torch.Size([32, 17]), tgt shape: torch.Size([32, 16])\nTest batch - src shape: torch.Size([32, 18]), tgt shape: torch.Size([32, 16])\nTest batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 14])\nTest batch - src shape: torch.Size([32, 18]), tgt shape: torch.Size([32, 17])\nTest batch - src shape: torch.Size([32, 18]), tgt shape: torch.Size([32, 17])\nTest batch - src shape: torch.Size([32, 16]), tgt shape: torch.Size([32, 15])\nTest batch - src shape: torch.Size([32, 22]), tgt shape: torch.Size([32, 19])\nTest batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 18])\nTest batch - src shape: torch.Size([32, 21]), tgt shape: torch.Size([32, 20])\nTest batch - src shape: torch.Size([32, 21]), tgt shape: torch.Size([32, 18])\nTest batch - src shape: torch.Size([32, 15]), tgt shape: torch.Size([32, 13])\nTest batch - src shape: torch.Size([32, 17]), tgt shape: torch.Size([32, 17])\nTest batch - src shape: torch.Size([32, 22]), tgt shape: torch.Size([32, 21])\nTest batch - src shape: torch.Size([32, 15]), tgt shape: torch.Size([32, 15])\nTest batch - src shape: torch.Size([32, 17]), tgt shape: torch.Size([32, 14])\nTest batch - src shape: torch.Size([32, 21]), tgt shape: torch.Size([32, 16])\nTest batch - src shape: torch.Size([32, 15]), tgt shape: torch.Size([32, 15])\nTest batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 17])\nTest batch - src shape: torch.Size([32, 18]), tgt shape: torch.Size([32, 15])\nTest batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 16])\nTest batch - src shape: torch.Size([32, 13]), tgt shape: torch.Size([32, 12])\nTest batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 17])\nTest batch - src shape: torch.Size([32, 16]), tgt shape: torch.Size([32, 15])\nTest batch - src shape: torch.Size([32, 13]), tgt shape: torch.Size([32, 12])\nTest batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 15])\nTest batch - src shape: torch.Size([32, 14]), tgt shape: torch.Size([32, 13])\nTest batch - src shape: torch.Size([32, 13]), tgt shape: torch.Size([32, 11])\nTest batch - src shape: torch.Size([32, 17]), tgt shape: torch.Size([32, 16])\nTest batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 20])\nTest batch - src shape: torch.Size([32, 13]), tgt shape: torch.Size([32, 12])\nTest batch - src shape: torch.Size([32, 14]), tgt shape: torch.Size([32, 14])\nTest batch - src shape: torch.Size([32, 10]), tgt shape: torch.Size([32, 11])\nTest batch - src shape: torch.Size([32, 15]), tgt shape: torch.Size([32, 15])\nTest batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 20])\nTest batch - src shape: torch.Size([32, 14]), tgt shape: torch.Size([32, 15])\nTest batch - src shape: torch.Size([32, 16]), tgt shape: torch.Size([32, 15])\nTest batch - src shape: torch.Size([32, 9]), tgt shape: torch.Size([32, 8])\nTest batch - src shape: torch.Size([32, 15]), tgt shape: torch.Size([32, 13])\nTest batch - src shape: torch.Size([32, 11]), tgt shape: torch.Size([32, 10])\nTest batch - src shape: torch.Size([32, 12]), tgt shape: torch.Size([32, 10])\nTest batch - src shape: torch.Size([32, 15]), tgt shape: torch.Size([32, 13])\nTest batch - src shape: torch.Size([32, 17]), tgt shape: torch.Size([32, 15])\nTest batch - src shape: torch.Size([32, 16]), tgt shape: torch.Size([32, 14])\nTest batch - src shape: torch.Size([32, 14]), tgt shape: torch.Size([32, 14])\nTest batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 13])\nTest batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 18])\nTest batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 20])\nTest batch - src shape: torch.Size([32, 17]), tgt shape: torch.Size([32, 13])\nTest batch - src shape: torch.Size([32, 12]), tgt shape: torch.Size([32, 12])\nTest batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 18])\nTest batch - src shape: torch.Size([32, 16]), tgt shape: torch.Size([32, 16])\nTest batch - src shape: torch.Size([32, 15]), tgt shape: torch.Size([32, 13])\nTest batch - src shape: torch.Size([32, 14]), tgt shape: torch.Size([32, 13])\nTest batch - src shape: torch.Size([32, 14]), tgt shape: torch.Size([32, 10])\nTest batch - src shape: torch.Size([32, 16]), tgt shape: torch.Size([32, 13])\nTest batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 18])\nTest batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 18])\nTest batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 17])\nTest batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 18])\nTest batch - src shape: torch.Size([32, 22]), tgt shape: torch.Size([32, 19])\nTest batch - src shape: torch.Size([32, 18]), tgt shape: torch.Size([32, 16])\nTest batch - src shape: torch.Size([32, 16]), tgt shape: torch.Size([32, 17])\nTest batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 19])\nTest batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 20])\nTest batch - src shape: torch.Size([32, 22]), tgt shape: torch.Size([32, 14])\nTest batch - src shape: torch.Size([32, 14]), tgt shape: torch.Size([32, 14])\nTest batch - src shape: torch.Size([32, 14]), tgt shape: torch.Size([32, 13])\nTest batch - src shape: torch.Size([32, 16]), tgt shape: torch.Size([32, 15])\nTest batch - src shape: torch.Size([32, 17]), tgt shape: torch.Size([32, 14])\nTest batch - src shape: torch.Size([32, 13]), tgt shape: torch.Size([32, 10])\nTest batch - src shape: torch.Size([32, 9]), tgt shape: torch.Size([32, 10])\nTest batch - src shape: torch.Size([32, 11]), tgt shape: torch.Size([32, 10])\nTest batch - src shape: torch.Size([32, 9]), tgt shape: torch.Size([32, 10])\nTest batch - src shape: torch.Size([32, 10]), tgt shape: torch.Size([32, 11])\nTest batch - src shape: torch.Size([32, 13]), tgt shape: torch.Size([32, 13])\nTest batch - src shape: torch.Size([32, 16]), tgt shape: torch.Size([32, 14])\nTest batch - src shape: torch.Size([32, 21]), tgt shape: torch.Size([32, 18])\nTest batch - src shape: torch.Size([32, 21]), tgt shape: torch.Size([32, 17])\nTest batch - src shape: torch.Size([32, 25]), tgt shape: torch.Size([32, 19])\nTest batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 15])\nTest batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 13])\nTest batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 17])\nTest batch - src shape: torch.Size([32, 17]), tgt shape: torch.Size([32, 13])\nTest batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 15])\nTest batch - src shape: torch.Size([32, 17]), tgt shape: torch.Size([32, 14])\nTest batch - src shape: torch.Size([32, 21]), tgt shape: torch.Size([32, 19])\nTest batch - src shape: torch.Size([32, 24]), tgt shape: torch.Size([32, 23])\nTest batch - src shape: torch.Size([32, 21]), tgt shape: torch.Size([32, 19])\nTest batch - src shape: torch.Size([32, 16]), tgt shape: torch.Size([32, 15])\nTest batch - src shape: torch.Size([32, 17]), tgt shape: torch.Size([32, 16])\nTest batch - src shape: torch.Size([32, 17]), tgt shape: torch.Size([32, 18])\nTest batch - src shape: torch.Size([32, 16]), tgt shape: torch.Size([32, 14])\nTest batch - src shape: torch.Size([32, 18]), tgt shape: torch.Size([32, 16])\nTest batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 16])\nTest batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 16])\nTest batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 15])\nTest batch - src shape: torch.Size([32, 14]), tgt shape: torch.Size([32, 13])\nTest batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 15])\nTest batch - src shape: torch.Size([32, 22]), tgt shape: torch.Size([32, 17])\nTest batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 17])\nTest batch - src shape: torch.Size([32, 15]), tgt shape: torch.Size([32, 15])\nTest batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 19])\nTest batch - src shape: torch.Size([32, 17]), tgt shape: torch.Size([32, 15])\nTest batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 14])\nTest batch - src shape: torch.Size([32, 21]), tgt shape: torch.Size([32, 17])\nTest batch - src shape: torch.Size([32, 14]), tgt shape: torch.Size([32, 14])\nTest batch - src shape: torch.Size([32, 21]), tgt shape: torch.Size([32, 17])\nTest batch - src shape: torch.Size([32, 17]), tgt shape: torch.Size([32, 17])\nTest batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 16])\nTest batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 12])\nTest batch - src shape: torch.Size([32, 16]), tgt shape: torch.Size([32, 15])\nTest batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 19])\nTest batch - src shape: torch.Size([32, 22]), tgt shape: torch.Size([32, 18])\nTest batch - src shape: torch.Size([32, 18]), tgt shape: torch.Size([32, 14])\nTest batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 16])\nTest batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 16])\nTest batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 19])\nTest batch - src shape: torch.Size([32, 14]), tgt shape: torch.Size([32, 11])\nTest batch - src shape: torch.Size([32, 18]), tgt shape: torch.Size([32, 15])\nTest batch - src shape: torch.Size([32, 16]), tgt shape: torch.Size([32, 16])\nTest batch - src shape: torch.Size([32, 21]), tgt shape: torch.Size([32, 13])\nTest batch - src shape: torch.Size([32, 15]), tgt shape: torch.Size([32, 12])\nTest batch - src shape: torch.Size([32, 17]), tgt shape: torch.Size([32, 15])\nTest batch - src shape: torch.Size([32, 18]), tgt shape: torch.Size([32, 16])\nTest batch - src shape: torch.Size([32, 17]), tgt shape: torch.Size([32, 16])\nTest batch - src shape: torch.Size([32, 17]), tgt shape: torch.Size([32, 15])\nTest batch - src shape: torch.Size([32, 18]), tgt shape: torch.Size([32, 16])\nTest batch - src shape: torch.Size([32, 16]), tgt shape: torch.Size([32, 16])\nTest batch - src shape: torch.Size([32, 14]), tgt shape: torch.Size([32, 14])\nTest batch - src shape: torch.Size([32, 17]), tgt shape: torch.Size([32, 14])\nTest batch - src shape: torch.Size([32, 23]), tgt shape: torch.Size([32, 17])\nTest batch - src shape: torch.Size([32, 17]), tgt shape: torch.Size([32, 15])\nTest batch - src shape: torch.Size([32, 23]), tgt shape: torch.Size([32, 24])\nTest batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 15])\nTest batch - src shape: torch.Size([32, 18]), tgt shape: torch.Size([32, 16])\nTest batch - src shape: torch.Size([32, 18]), tgt shape: torch.Size([32, 17])\nTest batch - src shape: torch.Size([32, 13]), tgt shape: torch.Size([32, 9])\nTest batch - src shape: torch.Size([32, 15]), tgt shape: torch.Size([32, 12])\nTest batch - src shape: torch.Size([32, 18]), tgt shape: torch.Size([32, 16])\nTest batch - src shape: torch.Size([32, 18]), tgt shape: torch.Size([32, 13])\nTest batch - src shape: torch.Size([32, 23]), tgt shape: torch.Size([32, 18])\nTest batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 16])\nTest batch - src shape: torch.Size([32, 22]), tgt shape: torch.Size([32, 17])\nTest batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 18])\nTest batch - src shape: torch.Size([32, 16]), tgt shape: torch.Size([32, 14])\nTest batch - src shape: torch.Size([32, 22]), tgt shape: torch.Size([32, 18])\nTest batch - src shape: torch.Size([32, 18]), tgt shape: torch.Size([32, 14])\nTest batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 17])\nTest batch - src shape: torch.Size([32, 16]), tgt shape: torch.Size([32, 13])\nTest batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 16])\nTest batch - src shape: torch.Size([32, 21]), tgt shape: torch.Size([32, 18])\nTest batch - src shape: torch.Size([32, 16]), tgt shape: torch.Size([32, 15])\nTest batch - src shape: torch.Size([32, 13]), tgt shape: torch.Size([32, 14])\nTest batch - src shape: torch.Size([32, 15]), tgt shape: torch.Size([32, 12])\nTest batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 15])\nTest batch - src shape: torch.Size([32, 14]), tgt shape: torch.Size([32, 12])\nTest batch - src shape: torch.Size([32, 11]), tgt shape: torch.Size([32, 9])\nTest batch - src shape: torch.Size([32, 13]), tgt shape: torch.Size([32, 13])\nTest batch - src shape: torch.Size([32, 13]), tgt shape: torch.Size([32, 11])\nTest batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 15])\nTest batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 15])\nTest batch - src shape: torch.Size([32, 15]), tgt shape: torch.Size([32, 13])\nTest batch - src shape: torch.Size([32, 21]), tgt shape: torch.Size([32, 15])\nTest batch - src shape: torch.Size([32, 21]), tgt shape: torch.Size([32, 17])\nTest batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 15])\nTest batch - src shape: torch.Size([32, 14]), tgt shape: torch.Size([32, 13])\nTest batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 16])\nTest batch - src shape: torch.Size([32, 21]), tgt shape: torch.Size([32, 17])\nTest batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 19])\nTest batch - src shape: torch.Size([32, 13]), tgt shape: torch.Size([32, 13])\nTest batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 17])\nTest batch - src shape: torch.Size([32, 24]), tgt shape: torch.Size([32, 20])\nTest batch - src shape: torch.Size([32, 18]), tgt shape: torch.Size([32, 15])\nTest batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 16])\nTest batch - src shape: torch.Size([32, 17]), tgt shape: torch.Size([32, 17])\nTest batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 16])\nTest batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 16])\nTest batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 16])\nTest batch - src shape: torch.Size([16, 9]), tgt shape: torch.Size([16, 8])\nTest Accuracy: 0.5377\nTest predictions saved to 'test_predictions.csv'\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}