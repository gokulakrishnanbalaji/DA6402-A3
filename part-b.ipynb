{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11826703,"sourceType":"datasetVersion","datasetId":7429459}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Question 5 - Attention Network","metadata":{}},{"cell_type":"code","source":"# Importing Libraries\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T18:14:08.146310Z","iopub.execute_input":"2025-05-19T18:14:08.146771Z","iopub.status.idle":"2025-05-19T18:14:12.403799Z","shell.execute_reply.started":"2025-05-19T18:14:08.146745Z","shell.execute_reply":"2025-05-19T18:14:12.403043Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"## preparing dataset for training","metadata":{}},{"cell_type":"code","source":"# Importing Libraries\n\nimport pandas as pd\nimport numpy as np\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch import optim\nfrom collections import Counter\nimport os\nimport math","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T18:14:12.404649Z","iopub.execute_input":"2025-05-19T18:14:12.405007Z","iopub.status.idle":"2025-05-19T18:14:12.692226Z","shell.execute_reply.started":"2025-05-19T18:14:12.404982Z","shell.execute_reply":"2025-05-19T18:14:12.691495Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Vocabulary class to handle character-to-index mapping\nclass Vocabulary:\n    def __init__(self):\n        self.char2idx = {'<PAD>': 0, '<SOS>': 1, '<EOS>': 2, '<UNK>': 3}\n        self.idx2char = {0: '<PAD>', 1: '<SOS>', 2: '<EOS>', 3: '<UNK>'}\n        self.size = 4\n\n    def add_sequence(self, sequence):\n        for char in sequence:\n            if char not in self.char2idx:\n                self.char2idx[char] = self.size\n                self.idx2char[self.size] = char\n                self.size += 1\n\n    def get_indices(self, sequence):\n        indices = [self.char2idx.get(char, self.char2idx['<UNK>']) for char in sequence]\n        return indices","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T18:14:12.693987Z","iopub.execute_input":"2025-05-19T18:14:12.694267Z","iopub.status.idle":"2025-05-19T18:14:12.700189Z","shell.execute_reply.started":"2025-05-19T18:14:12.694251Z","shell.execute_reply":"2025-05-19T18:14:12.699379Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Custom Dataset class\n\nclass DakshinaDataset(Dataset):\n    def __init__(self, data, src_vocab, tgt_vocab):\n        self.data = data\n        self.src_vocab = src_vocab\n        self.tgt_vocab = tgt_vocab\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        src = self.data.iloc[idx, 1]  # English (Latin)\n        tgt = self.data.iloc[idx, 0]  # Tamil\n        src_indices = [self.src_vocab.char2idx['<SOS>']] + self.src_vocab.get_indices(src) + [self.src_vocab.char2idx['<EOS>']]\n        tgt_indices = [self.tgt_vocab.char2idx['<SOS>']] + self.tgt_vocab.get_indices(tgt) + [self.tgt_vocab.char2idx['<EOS>']]\n        return torch.tensor(src_indices, dtype=torch.long), torch.tensor(tgt_indices, dtype=torch.long)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T18:14:12.701015Z","iopub.execute_input":"2025-05-19T18:14:12.701272Z","iopub.status.idle":"2025-05-19T18:14:12.716496Z","shell.execute_reply.started":"2025-05-19T18:14:12.701249Z","shell.execute_reply":"2025-05-19T18:14:12.715775Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Function to load and preprocess data\ndef load_dakshina_data(train_path, val_path, test_path):\n    # Read TSV files without headers\n    train_df = pd.read_csv(train_path, sep='\\t', header=None, usecols=[0, 1])\n    val_df = pd.read_csv(val_path, sep='\\t', header=None, usecols=[0, 1])\n    test_df = pd.read_csv(test_path, sep='\\t', header=None, usecols=[0, 1])\n\n    # Ensure strings\n    train_df[0] = train_df[0].astype(str)\n    train_df[1] = train_df[1].astype(str)\n    val_df[0] = val_df[0].astype(str)\n    val_df[1] = val_df[1].astype(str)\n    test_df[0] = test_df[0].astype(str)\n    test_df[1] = test_df[1].astype(str)\n\n    # Build vocabularies\n    src_vocab = Vocabulary()  # English (Latin)\n    tgt_vocab = Vocabulary()  # Tamil\n\n    # Add characters to vocab from training data\n    for _, row in train_df.iterrows():\n        src_vocab.add_sequence(row[1])\n        tgt_vocab.add_sequence(row[0])\n\n    # Create datasets\n    train_dataset = DakshinaDataset(train_df, src_vocab, tgt_vocab)\n    val_dataset = DakshinaDataset(val_df, src_vocab, tgt_vocab)\n    test_dataset = DakshinaDataset(test_df, src_vocab, tgt_vocab)\n\n    return train_dataset, val_dataset, test_dataset, src_vocab, tgt_vocab","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T18:14:12.717293Z","iopub.execute_input":"2025-05-19T18:14:12.717697Z","iopub.status.idle":"2025-05-19T18:14:12.734143Z","shell.execute_reply.started":"2025-05-19T18:14:12.717673Z","shell.execute_reply":"2025-05-19T18:14:12.733446Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Collate function for DataLoader\ndef collate_fn(batch):\n    src_batch, tgt_batch = zip(*batch)\n    # Pad sequences\n    src_padded = torch.nn.utils.rnn.pad_sequence(src_batch, batch_first=True, padding_value=0)\n    tgt_padded = torch.nn.utils.rnn.pad_sequence(tgt_batch, batch_first=True, padding_value=0)\n    return src_padded, tgt_padded","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T18:14:12.734884Z","iopub.execute_input":"2025-05-19T18:14:12.735140Z","iopub.status.idle":"2025-05-19T18:14:12.754192Z","shell.execute_reply.started":"2025-05-19T18:14:12.735119Z","shell.execute_reply":"2025-05-19T18:14:12.753463Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# Wrapper function for easier access\n\ndef prepare_data_loaders(train_path, val_path, test_path, batch_size=32):\n    train_dataset, val_dataset, test_dataset, src_vocab, tgt_vocab = load_dakshina_data(train_path, val_path, test_path)\n    \n    train_loader = DataLoader(\n        train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn, pin_memory=True\n    )\n    val_loader = DataLoader(\n        val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn, pin_memory=True\n    )\n    test_loader = DataLoader(\n        test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn, pin_memory=True\n    )\n    \n    return train_loader, val_loader, test_loader, src_vocab, tgt_vocab","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T18:14:12.754890Z","iopub.execute_input":"2025-05-19T18:14:12.755139Z","iopub.status.idle":"2025-05-19T18:14:12.768881Z","shell.execute_reply.started":"2025-05-19T18:14:12.755119Z","shell.execute_reply":"2025-05-19T18:14:12.768204Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# Paths to your local TSV files (update as needed)\ntrain_path = '/kaggle/input/dakshina-tamil-b/ta.translit.sampled.train.tsv'\nval_path = '/kaggle/input/dakshina-tamil-b/ta.translit.sampled.dev.tsv'\ntest_path = '/kaggle/input/dakshina-tamil-b/ta.translit.sampled.test.tsv'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T18:14:12.769799Z","iopub.execute_input":"2025-05-19T18:14:12.770032Z","iopub.status.idle":"2025-05-19T18:14:12.792625Z","shell.execute_reply.started":"2025-05-19T18:14:12.770016Z","shell.execute_reply":"2025-05-19T18:14:12.791807Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# Create data loaders\ntrain_loader, val_loader, test_loader, src_vocab, tgt_vocab = prepare_data_loaders(train_path, val_path, test_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T18:14:12.795791Z","iopub.execute_input":"2025-05-19T18:14:12.795982Z","iopub.status.idle":"2025-05-19T18:14:15.475923Z","shell.execute_reply.started":"2025-05-19T18:14:12.795967Z","shell.execute_reply":"2025-05-19T18:14:15.475383Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# Print vocabulary sizes\nprint(f\"Source (English) vocabulary size: {src_vocab.size}\")\nprint(f\"Target (Tamil) vocabulary size: {tgt_vocab.size}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T18:14:15.476537Z","iopub.execute_input":"2025-05-19T18:14:15.476715Z","iopub.status.idle":"2025-05-19T18:14:15.481038Z","shell.execute_reply.started":"2025-05-19T18:14:15.476701Z","shell.execute_reply":"2025-05-19T18:14:15.480365Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Source (English) vocabulary size: 30\nTarget (Tamil) vocabulary size: 50\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"## defining models","metadata":{}},{"cell_type":"code","source":"class Attention(nn.Module):\n    def __init__(self, hidden_size, attention_type='bahdanau'):\n        super(Attention, self).__init__()\n        self.hidden_size = hidden_size\n        self.attention_type = attention_type.lower()\n        \n        if self.attention_type == 'bahdanau':\n            self.Wa = nn.Linear(hidden_size * 2, hidden_size)\n            self.Ua = nn.Linear(hidden_size, 1, bias=False)\n        elif self.attention_type == 'dot':\n            pass  # Dot-product attention uses no additional parameters\n        else:\n            raise ValueError(\"Unsupported attention type. Use 'bahdanau' or 'dot'.\")\n\n    def forward(self, decoder_hidden, encoder_outputs):\n        # decoder_hidden: (num_layers, batch_size, hidden_size) or tuple for LSTM\n        # encoder_outputs: (batch_size, seq_len, hidden_size)\n        batch_size = encoder_outputs.size(0)\n        seq_len = encoder_outputs.size(1)\n        \n        # Validate encoder_outputs shape\n        assert encoder_outputs.dim() == 3, f\"Expected encoder_outputs to be 3D, got {encoder_outputs.shape}\"\n        assert encoder_outputs.size(2) == self.hidden_size, f\"Expected encoder_outputs hidden_size {self.hidden_size}, got {encoder_outputs.size(2)}\"\n        \n        # Extract the last layer of decoder hidden state\n        if isinstance(decoder_hidden, tuple):  # LSTM case\n            decoder_hidden = decoder_hidden[0]  # Take hidden state, not cell state\n        decoder_hidden = decoder_hidden[-1]  # (batch_size, hidden_size)\n        \n        assert decoder_hidden.dim() == 2, f\"Expected decoder_hidden to be 2D, got {decoder_hidden.shape}\"\n        assert decoder_hidden.size(1) == self.hidden_size, f\"Expected decoder_hidden hidden_size {self.hidden_size}, got {decoder_hidden.size(1)}\"\n        \n        if self.attention_type == 'bahdanau':\n            # Repeat decoder hidden to match seq_len\n            decoder_hidden = decoder_hidden.unsqueeze(1).repeat(1, seq_len, 1)  # (batch_size, seq_len, hidden_size)\n            # Combine with encoder outputs\n            combined = torch.cat((decoder_hidden, encoder_outputs), dim=2)  # (batch_size, seq_len, hidden_size*2)\n            # Compute energy\n            energy = torch.tanh(self.Wa(combined))  # (batch_size, seq_len, hidden_size)\n            attention_scores = self.Ua(energy).squeeze(2)  # (batch_size, seq_len)\n        else:  # dot\n            # Compute dot-product attention\n            decoder_hidden = decoder_hidden.unsqueeze(1)  # (batch_size, 1, hidden_size)\n            encoder_outputs_t = encoder_outputs.transpose(1, 2)  # (batch_size, hidden_size, seq_len)\n            # Verify shapes before bmm\n            assert decoder_hidden.shape == (batch_size, 1, self.hidden_size), f\"Expected decoder_hidden (batch_size, 1, hidden_size), got {decoder_hidden.shape}\"\n            assert encoder_outputs_t.shape == (batch_size, self.hidden_size, seq_len), f\"Expected encoder_outputs_t (batch_size, hidden_size, seq_len), got {encoder_outputs_t.shape}\"\n            attention_scores = torch.bmm(decoder_hidden, encoder_outputs_t).squeeze(1)  # (batch_size, seq_len)\n        \n        # Softmax to get attention weights\n        attention_weights = F.softmax(attention_scores, dim=1)  # (batch_size, seq_len)\n        # Compute context vector\n        context = torch.bmm(attention_weights.unsqueeze(1), encoder_outputs).squeeze(1)  # (batch_size, hidden_size)\n        \n        return context, attention_weights","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T18:14:15.481851Z","iopub.execute_input":"2025-05-19T18:14:15.482047Z","iopub.status.idle":"2025-05-19T18:14:15.499074Z","shell.execute_reply.started":"2025-05-19T18:14:15.482033Z","shell.execute_reply":"2025-05-19T18:14:15.498386Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"class EncoderRNN(nn.Module):\n    def __init__(self, input_size, embed_size, hidden_size, cell_type='RNN', num_layers=1, dropout=0.0):\n        super(EncoderRNN, self).__init__()\n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n        self.embedding = nn.Embedding(input_size, embed_size)\n        self.cell_type = cell_type.upper()\n        \n        rnn_class = {'RNN': nn.RNN, 'LSTM': nn.LSTM, 'GRU': nn.GRU}[self.cell_type]\n        self.rnn = rnn_class(\n            input_size=embed_size,\n            hidden_size=hidden_size,\n            num_layers=num_layers,\n            batch_first=True,\n            dropout=dropout if num_layers > 1 else 0.0\n        )\n\n    def forward(self, input_seq):\n        embedded = self.embedding(input_seq)\n        if self.cell_type == 'LSTM':\n            outputs, (hidden, cell) = self.rnn(embedded)\n            return outputs, (hidden, cell)\n        else:\n            outputs, hidden = self.rnn(embedded)\n            return outputs, hidden","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T18:14:15.499804Z","iopub.execute_input":"2025-05-19T18:14:15.499984Z","iopub.status.idle":"2025-05-19T18:14:15.518937Z","shell.execute_reply.started":"2025-05-19T18:14:15.499962Z","shell.execute_reply":"2025-05-19T18:14:15.518223Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"class DecoderRNN(nn.Module):\n    def __init__(self, output_size, embed_size, hidden_size, cell_type='RNN', num_layers=1, dropout=0.0, attention_type='bahdanau'):\n        super(DecoderRNN, self).__init__()\n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n        self.embedding = nn.Embedding(output_size, embed_size)\n        self.dropout = nn.Dropout(dropout)\n        self.cell_type = cell_type.upper()\n        \n        rnn_class = {'RNN': nn.RNN, 'LSTM': nn.LSTM, 'GRU': nn.GRU}[self.cell_type]\n        self.rnn = rnn_class(\n            input_size=embed_size + hidden_size,  # Input includes context vector\n            hidden_size=hidden_size,\n            num_layers=num_layers,\n            batch_first=True,\n            dropout=dropout if num_layers > 1 else 0.0\n        )\n        self.attention = Attention(hidden_size, attention_type)\n        self.out = nn.Linear(hidden_size * 2, output_size)  # Combine RNN output and context\n\n    def forward(self, input_char, hidden, encoder_outputs):\n        embedded = self.embedding(input_char).unsqueeze(1)  # (batch_size, 1, embed_size)\n        embedded = self.dropout(embedded)\n        \n        # Compute attention\n        context, attention_weights = self.attention(hidden, encoder_outputs)  # context: (batch_size, hidden_size)\n        \n        # Concatenate context with embedded input\n        rnn_input = torch.cat((embedded, context.unsqueeze(1)), dim=2)  # (batch_size, 1, embed_size + hidden_size)\n        \n        if self.cell_type == 'LSTM':\n            output, (hidden, cell) = self.rnn(rnn_input, hidden)\n            output = output.squeeze(1)  # (batch_size, hidden_size)\n            output = torch.cat((output, context), dim=1)  # (batch_size, hidden_size * 2)\n            output = self.out(output)  # (batch_size, output_size)\n            return output, (hidden, cell), attention_weights\n        else:\n            output, hidden = self.rnn(rnn_input, hidden)\n            output = output.squeeze(1)\n            output = torch.cat((output, context), dim=1)\n            output = self.out(output)\n            return output, hidden, attention_weights\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T18:14:15.519738Z","iopub.execute_input":"2025-05-19T18:14:15.519926Z","iopub.status.idle":"2025-05-19T18:14:15.538449Z","shell.execute_reply.started":"2025-05-19T18:14:15.519905Z","shell.execute_reply":"2025-05-19T18:14:15.537803Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"class Seq2Seq(nn.Module):\n    def __init__(self, encoder, decoder):\n        super(Seq2Seq, self).__init__()\n        self.encoder = encoder\n        self.decoder = decoder\n\n    def forward(self, source, target, teacher_forcing_ratio=0.5):\n        batch_size = source.size(0)\n        target_len = target.size(1)\n        outputs = torch.zeros(batch_size, target_len, self.decoder.out.out_features).to(source.device)\n        \n        encoder_outputs, hidden = self.encoder(source)\n        \n        decoder_input = target[:, 0]\n        \n        # Handle differing encoder/decoder layers\n        if self.encoder.cell_type == 'LSTM':\n            hidden, cell = hidden\n            if self.encoder.num_layers != self.decoder.num_layers:\n                factor = self.decoder.num_layers // self.encoder.num_layers + 1\n                hidden = hidden.repeat(factor, 1, 1)[:self.decoder.num_layers]\n                cell = cell.repeat(factor, 1, 1)[:self.decoder.num_layers]\n            hidden = (hidden, cell)\n        else:\n            if self.encoder.num_layers != self.decoder.num_layers:\n                factor = self.decoder.num_layers // self.encoder.num_layers + 1\n                hidden = hidden.repeat(factor, 1, 1)[:self.decoder.num_layers]\n        \n        for t in range(1, target_len):\n            output, hidden, _ = self.decoder(decoder_input, hidden, encoder_outputs)\n            outputs[:, t, :] = output\n            teacher_force = torch.rand(1).item() < teacher_forcing_ratio\n            top1 = output.argmax(1)\n            decoder_input = target[:, t] if teacher_force else top1\n\n        return outputs\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T18:14:15.539431Z","iopub.execute_input":"2025-05-19T18:14:15.539668Z","iopub.status.idle":"2025-05-19T18:14:15.556863Z","shell.execute_reply.started":"2025-05-19T18:14:15.539651Z","shell.execute_reply":"2025-05-19T18:14:15.556092Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"def create_model(input_vocab_size, output_vocab_size, embed_size=256, hidden_size=512, \n                 cell_type='RNN', encoder_layers=1, decoder_layers=1, dropout=0.0, attention_type='bahdanau'):\n    encoder = EncoderRNN(input_vocab_size, embed_size, hidden_size, cell_type, encoder_layers, dropout)\n    decoder = DecoderRNN(output_vocab_size, embed_size, hidden_size, cell_type, decoder_layers, dropout, attention_type)\n    model = Seq2Seq(encoder, decoder)\n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T18:14:15.557452Z","iopub.execute_input":"2025-05-19T18:14:15.557602Z","iopub.status.idle":"2025-05-19T18:14:15.580054Z","shell.execute_reply.started":"2025-05-19T18:14:15.557589Z","shell.execute_reply":"2025-05-19T18:14:15.579539Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":"## setting up wandb","metadata":{}},{"cell_type":"code","source":"!pip install wandb -q","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T18:14:15.580698Z","iopub.execute_input":"2025-05-19T18:14:15.580928Z","iopub.status.idle":"2025-05-19T18:14:19.416248Z","shell.execute_reply.started":"2025-05-19T18:14:15.580909Z","shell.execute_reply":"2025-05-19T18:14:19.415478Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"import wandb","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T18:14:19.417177Z","iopub.execute_input":"2025-05-19T18:14:19.417416Z","iopub.status.idle":"2025-05-19T18:14:22.007758Z","shell.execute_reply.started":"2025-05-19T18:14:19.417384Z","shell.execute_reply":"2025-05-19T18:14:22.007203Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_value_0 = user_secrets.get_secret(\"wandb\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T18:14:22.008475Z","iopub.execute_input":"2025-05-19T18:14:22.008810Z","iopub.status.idle":"2025-05-19T18:14:22.162126Z","shell.execute_reply.started":"2025-05-19T18:14:22.008793Z","shell.execute_reply":"2025-05-19T18:14:22.161446Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"wandb.login(key=secret_value_0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T18:14:22.162853Z","iopub.execute_input":"2025-05-19T18:14:22.163073Z","iopub.status.idle":"2025-05-19T18:14:28.445598Z","shell.execute_reply.started":"2025-05-19T18:14:22.163049Z","shell.execute_reply":"2025-05-19T18:14:28.445013Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mda24m007\u001b[0m (\u001b[33mda24m007-iit-madras\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":19},{"cell_type":"markdown","source":"## Running wandb sweep","metadata":{}},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T18:14:28.446212Z","iopub.execute_input":"2025-05-19T18:14:28.446629Z","iopub.status.idle":"2025-05-19T18:14:28.505725Z","shell.execute_reply.started":"2025-05-19T18:14:28.446602Z","shell.execute_reply":"2025-05-19T18:14:28.505060Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"# Beam search decoding (adapted for attention)\ndef beam_search_decode(model, src, max_len, beam_width, sos_idx, eos_idx):\n    model.eval()\n    src = src.to(device)\n    batch_size = src.size(0)\n    encoder_outputs, hidden = model.encoder(src)\n    \n    if model.encoder.cell_type == 'LSTM':\n        hidden, cell = hidden\n        if model.encoder.num_layers != model.decoder.num_layers:\n            factor = model.decoder.num_layers // model.encoder.num_layers\n            if factor > 1:\n                hidden = hidden.repeat(factor, 1, 1)\n                cell = cell.repeat(factor, 1, 1)\n            else:\n                hidden = hidden[-model.decoder.num_layers:]\n                cell = cell[-model.decoder.num_layers:]\n        hidden = (hidden, cell)\n    else:\n        if model.encoder.num_layers != model.decoder.num_layers:\n            factor = model.decoder.num_layers // model.encoder.num_layers\n            if factor > 1:\n                hidden = hidden.repeat(factor, 1, 1)\n            else:\n                hidden = hidden[-model.decoder.num_layers:]\n    \n    beams = [(torch.tensor([sos_idx], device=device), hidden, 0.0)]\n    completed = []\n    \n    for _ in range(max_len):\n        new_beams = []\n        for seq, hid, score in beams:\n            if seq[-1].item() == eos_idx:\n                completed.append((seq, score))\n                continue\n            output, new_hidden, _ = model.decoder(seq[-1].unsqueeze(0), hid, encoder_outputs)\n            probs = torch.softmax(output, dim=-1)\n            top_probs, top_idx = probs.topk(beam_width)\n            \n            for i in range(beam_width):\n                new_seq = torch.cat([seq, top_idx[:, i]])\n                new_score = score - math.log(top_probs[:, i].item())\n                new_beams.append((new_seq, new_hidden, new_score))\n        \n        new_beams = sorted(new_beams, key=lambda x: x[2])[:beam_width]\n        beams = new_beams\n        \n        if len(completed) >= beam_width:\n            break\n    \n    completed = sorted(completed, key=lambda x: x[1])\n    if completed:\n        return completed[0][0]\n    return beams[0][0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T18:14:28.506483Z","iopub.execute_input":"2025-05-19T18:14:28.506762Z","iopub.status.idle":"2025-05-19T18:14:28.525303Z","shell.execute_reply.started":"2025-05-19T18:14:28.506739Z","shell.execute_reply":"2025-05-19T18:14:28.524649Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"# Training and evaluation function\ndef train_and_evaluate():\n    wandb.init()\n    config = wandb.config\n    \n    # Create model with sweep parameters\n    model = create_model(\n        input_vocab_size=src_vocab.size,\n        output_vocab_size=tgt_vocab.size,\n        embed_size=config.embed_size,\n        hidden_size=config.hidden_size,\n        cell_type=config.cell_type,\n        encoder_layers=1,  # Single layer\n        decoder_layers=1,  # Single layer\n        dropout=config.dropout,\n        attention_type=config.attention_type\n    ).to(device)\n    \n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n    criterion = nn.CrossEntropyLoss(ignore_index=0)\n    \n    for epoch in range(10):\n        model.train()\n        train_loss = 0\n        for src, tgt in train_loader:\n            src, tgt = src.to(device), tgt.to(device)\n            optimizer.zero_grad()\n            output = model(src, tgt, teacher_forcing_ratio=0.5)\n            output = output[:, 1:].reshape(-1, output.size(-1))\n            tgt_flat = tgt[:, 1:].reshape(-1)\n            loss = criterion(output, tgt_flat)\n            loss.backward()\n            optimizer.step()\n            train_loss += loss.item()\n        \n        # Compute training accuracy on one batch\n        model.eval()\n        train_correct = 0\n        train_total = 0\n        with torch.no_grad():\n            for src, tgt in train_loader:\n                src, tgt = src.to(device), tgt.to(device)\n                for i in range(src.size(0)):\n                    pred = beam_search_decode(\n                        model, src[i:i+1], max_len=50,\n                        beam_width=config.beam_width,\n                        sos_idx=tgt_vocab.char2idx['<SOS>'],\n                        eos_idx=tgt_vocab.char2idx['<EOS>']\n                    )\n                    pred_str = ''.join([tgt_vocab.idx2char[idx.item()] for idx in pred if idx.item() not in [0, 1, 2]])\n                    tgt_seq = tgt[i]\n                    tgt_str = ''.join([tgt_vocab.idx2char[idx.item()] for idx in tgt_seq[1:] if idx.item() not in [0, 1, 2]])\n                    if pred_str == tgt_str:\n                        train_correct += 1\n                    train_total += 1\n                break\n        \n        # Compute validation loss and accuracy\n        val_loss = 0\n        val_correct = 0\n        val_total = 0\n        with torch.no_grad():\n            for src, tgt in val_loader:\n                src, tgt = src.to(device), tgt.to(device)\n                output = model(src, tgt, teacher_forcing_ratio=0.0)\n                output = output[:, 1:].reshape(-1, output.size(-1))\n                tgt_flat = tgt[:, 1:].reshape(-1)\n                loss = criterion(output, tgt_flat)\n                val_loss += loss.item()\n            \n            # Validation accuracy on one batch\n            for src, tgt in val_loader:\n                src, tgt = src.to(device), tgt.to(device)\n                for i in range(src.size(0)):\n                    pred = beam_search_decode(\n                        model, src[i:i+1], max_len=50,\n                        beam_width=config.beam_width,\n                        sos_idx=tgt_vocab.char2idx['<SOS>'],\n                        eos_idx=tgt_vocab.char2idx['<EOS>']\n                    )\n                    pred_str = ''.join([tgt_vocab.idx2char[idx.item()] for idx in pred if idx.item() not in [0, 1, 2]])\n                    tgt_seq = tgt[i]\n                    tgt_str = ''.join([tgt_vocab.idx2char[idx.item()] for idx in tgt_seq[1:] if idx.item() not in [0, 1, 2]])\n                    if pred_str == tgt_str:\n                        val_correct += 1\n                    val_total += 1\n                break\n        \n        # Log metrics to WandB\n        wandb.log({\n            \"epoch\": epoch,\n            \"train_loss\": train_loss / len(train_loader),\n            \"val_loss\": val_loss / len(val_loader),\n            \"train_accuracy\": train_correct / train_total,\n            \"val_accuracy\": val_correct / val_total\n        })\n        print(f\"Epoch {epoch+1}, Train Loss: {train_loss / len(train_loader):.4f}, Val Accuracy: {val_correct / val_total:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T18:14:28.526082Z","iopub.execute_input":"2025-05-19T18:14:28.526435Z","iopub.status.idle":"2025-05-19T18:14:28.548739Z","shell.execute_reply.started":"2025-05-19T18:14:28.526409Z","shell.execute_reply":"2025-05-19T18:14:28.548212Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"# WandB sweep configuration\nsweep_config = {\n    'method': 'bayes',\n    'metric': {\n        'name': 'val_accuracy',\n        'goal': 'maximize'\n    },\n    'parameters': {\n        'embed_size': {\n            'values': [32, 64, 128, 256, 512]\n        },\n        'hidden_size': {\n            'values': [32,64,128, 256, 512]\n        },\n        'cell_type': {\n            'values': ['RNN', 'GRU', 'LSTM']\n        },\n        'dropout': {\n            'values': [0.2, 0.3]\n        },\n        'beam_width': {\n            'values': [1, 3, 5]\n        },\n        'attention_type': {\n            'values': ['bahdanau', 'dot']\n        }\n    }\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T18:14:28.549479Z","iopub.execute_input":"2025-05-19T18:14:28.549707Z","iopub.status.idle":"2025-05-19T18:14:28.567401Z","shell.execute_reply.started":"2025-05-19T18:14:28.549687Z","shell.execute_reply":"2025-05-19T18:14:28.566907Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"# Initialize and run sweep\nsweep_id = wandb.sweep(sweep_config, project=\"DL-A3\")\nwandb.agent(sweep_id, function=train_and_evaluate, count=20)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-15T17:53:57.185185Z","iopub.execute_input":"2025-05-15T17:53:57.185394Z","execution_failed":"2025-05-15T17:57:35.974Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Training with best set of hyperparameters","metadata":{}},{"cell_type":"code","source":"wandb.init(project=\"DL-A3\", name=\"final_model_training_with_attention_v2\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T18:14:56.293280Z","iopub.execute_input":"2025-05-19T18:14:56.294003Z","iopub.status.idle":"2025-05-19T18:15:02.850247Z","shell.execute_reply.started":"2025-05-19T18:14:56.293972Z","shell.execute_reply":"2025-05-19T18:15:02.849558Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250519_181456-xiabr9kk</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/da24m007-iit-madras/DL-A3/runs/xiabr9kk' target=\"_blank\">final_model_training_with_attention_v2</a></strong> to <a href='https://wandb.ai/da24m007-iit-madras/DL-A3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/da24m007-iit-madras/DL-A3' target=\"_blank\">https://wandb.ai/da24m007-iit-madras/DL-A3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/da24m007-iit-madras/DL-A3/runs/xiabr9kk' target=\"_blank\">https://wandb.ai/da24m007-iit-madras/DL-A3/runs/xiabr9kk</a>"},"metadata":{}},{"execution_count":24,"output_type":"execute_result","data":{"text/html":"<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/da24m007-iit-madras/DL-A3/runs/xiabr9kk?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>","text/plain":"<wandb.sdk.wandb_run.Run at 0x7e390e54fb50>"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"# Function to retrieve best hyperparameters from WandB sweep\ndef get_best_hyperparameters(project_name=\"DL-A3\"):\n    api = wandb.Api()\n    runs = api.runs(project_name)\n    best_run = None\n    best_val_accuracy = -float('inf')\n    \n    for run in runs:\n        if 'val_accuracy' in run.summary and run.summary['val_accuracy'] > best_val_accuracy:\n            best_val_accuracy = run.summary['val_accuracy']\n            best_run = run\n    \n    if best_run is None:\n        raise ValueError(\"No runs found with val_accuracy in WandB project\")\n    \n    # Extract hyperparameters\n    config = best_run.config\n    return {\n            'attention_type': config['attention_type'],\n                'cell_type': config['cell_type'],\n                'embed_size': config['embed_size'],\n                'hidden_size': config['hidden_size'],\n                'dropout': config['dropout'],\n                'beam_width': config['beam_width']\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T18:15:12.054186Z","iopub.execute_input":"2025-05-19T18:15:12.054830Z","iopub.status.idle":"2025-05-19T18:15:12.062519Z","shell.execute_reply.started":"2025-05-19T18:15:12.054801Z","shell.execute_reply":"2025-05-19T18:15:12.061698Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"# Training and evaluation function\ndef train_model(model, train_loader, val_loader, test_loader, num_epochs=30, beam_width=3):\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n    criterion = nn.CrossEntropyLoss(ignore_index=0)\n    \n    for epoch in range(num_epochs):\n        model.train()\n        train_loss = 0\n        for src, tgt in train_loader:\n            src, tgt = src.to(device), tgt.to(device)\n            optimizer.zero_grad()\n            output = model(src, tgt, teacher_forcing_ratio=0.5)\n            output = output[:, 1:].reshape(-1, output.size(-1))\n            tgt_flat = tgt[:, 1:].reshape(-1)\n            loss = criterion(output, tgt_flat)\n            loss.backward()\n            optimizer.step()\n            train_loss += loss.item()\n        \n        # Compute validation loss and accuracy (one batch for speed)\n        model.eval()\n        val_loss = 0\n        val_correct = 0\n        val_total = 0\n        with torch.no_grad():\n            for src, tgt in val_loader:\n                src, tgt = src.to(device), tgt.to(device)\n                output = model(src, tgt, teacher_forcing_ratio=0.0)\n                output = output[:, 1:].reshape(-1, output.size(-1))\n                tgt_flat = tgt[:, 1:].reshape(-1)\n                loss = criterion(output, tgt_flat)\n                val_loss += loss.item()\n                \n                # Compute accuracy on one batch\n                print(f\"Epoch {epoch+1}, Validation batch - src shape: {src.shape}, tgt shape: {tgt.shape}\")\n                for i in range(src.size(0)):\n                    pred = beam_search_decode(\n                        model, src[i:i+1], max_len=50,\n                        beam_width=beam_width,\n                        sos_idx=tgt_vocab.char2idx['<SOS>'],\n                        eos_idx=tgt_vocab.char2idx['<EOS>']\n                    )\n                    pred_str = ''.join([tgt_vocab.idx2char[idx.item()] for idx in pred if idx.item() not in [0, 1, 2]])\n                    tgt_seq = tgt[i]\n                    tgt_str = ''.join([tgt_vocab.idx2char[idx.item()] for idx in tgt_seq[1:] if idx.item() not in [0, 1, 2]])\n                    if pred_str == tgt_str:\n                        val_correct += 1\n                    val_total += 1\n                break  # Process only one batch for validation accuracy\n        \n        # Log metrics to WandB\n        wandb.log({\n            \"epoch\": epoch,\n            \"train_loss\": train_loss / len(train_loader),\n            \"val_loss\": val_loss / len(val_loader),\n            \"val_accuracy\": val_correct / val_total\n        })\n        print(f\"Epoch {epoch+1}, Train Loss: {train_loss / len(train_loader):.4f}, Val Loss: {val_loss / len(val_loader):.4f}, Val Accuracy: {val_correct / val_total:.4f}\")\n    \n    # Compute test accuracy and save predictions\n    test_correct = 0\n    test_total = 0\n    predictions = []\n    with torch.no_grad():\n        for src, tgt in test_loader:\n            src, tgt = src.to(device), tgt.to(device)\n            print(f\"Test batch - src shape: {src.shape}, tgt shape: {tgt.shape}\")\n            for i in range(src.size(0)):\n                pred = beam_search_decode(\n                    model, src[i:i+1], max_len=50,\n                    beam_width=beam_width,\n                    sos_idx=tgt_vocab.char2idx['<SOS>'],\n                    eos_idx=tgt_vocab.char2idx['<EOS>']\n                )\n                pred_str = ''.join([tgt_vocab.idx2char[idx.item()] for idx in pred if idx.item() not in [0, 1, 2]])\n                tgt_seq = tgt[i]\n                tgt_str = ''.join([tgt_vocab.idx2char[idx.item()] for idx in tgt_seq[1:] if idx.item() not in [0, 1, 2]])\n                src_str = ''.join([src_vocab.idx2char[idx.item()] for idx in src[i, 1:] if idx.item() not in [0, 1, 2]])\n                if pred_str == tgt_str:\n                    test_correct += 1\n                test_total += 1\n                predictions.append({\n                    'input_english': src_str,\n                    'actual_tamil': tgt_str,\n                    'predicted_tamil': pred_str\n                })\n    \n    test_accuracy = test_correct / test_total\n    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n    \n    # Save predictions to CSV\n    predictions_df = pd.DataFrame(predictions)\n    predictions_df.to_csv('test_predictions_attention.csv', index=False)\n    print(\"Test predictions saved to 'test_predictions.csv'\")\n    \n    return test_accuracy","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T18:15:19.491217Z","iopub.execute_input":"2025-05-19T18:15:19.491918Z","iopub.status.idle":"2025-05-19T18:15:19.505483Z","shell.execute_reply.started":"2025-05-19T18:15:19.491885Z","shell.execute_reply":"2025-05-19T18:15:19.504770Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"# Get best hyperparameters\ntry:\n    best_params = get_best_hyperparameters()\n    print(\"Best hyperparameters from WandB sweep:\", best_params)\nexcept Exception as e:\n    print(f\"Error retrieving hyperparameters: {e}\")\n    print(\"Using default hyperparameters as fallback\")\n    best_params = {\n        'embed_size': 256,\n        'hidden_size': 512,\n        'cell_type': 'LSTM',\n        'encoder_layers': 2,\n        'decoder_layers': 1,\n        'dropout': 0.2,\n        'beam_width': 5\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T18:15:23.413838Z","iopub.execute_input":"2025-05-19T18:15:23.414106Z","iopub.status.idle":"2025-05-19T18:15:25.610779Z","shell.execute_reply.started":"2025-05-19T18:15:23.414086Z","shell.execute_reply":"2025-05-19T18:15:25.610178Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Best hyperparameters from WandB sweep: {'attention_type': 'bahdanau', 'cell_type': 'GRU', 'embed_size': 128, 'hidden_size': 128, 'dropout': 0.2, 'beam_width': 5}\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"# Create model with best parameters\nmodel = create_model(\n    input_vocab_size=src_vocab.size,\n    output_vocab_size=tgt_vocab.size,\n    embed_size=best_params['embed_size'],\n    hidden_size=best_params['hidden_size'],\n    cell_type=best_params['cell_type'],\n    encoder_layers=1,\n    decoder_layers=1,\n    dropout=best_params['dropout']\n).to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T18:15:29.004089Z","iopub.execute_input":"2025-05-19T18:15:29.004740Z","iopub.status.idle":"2025-05-19T18:15:29.293615Z","shell.execute_reply.started":"2025-05-19T18:15:29.004717Z","shell.execute_reply":"2025-05-19T18:15:29.292879Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T18:15:30.985812Z","iopub.execute_input":"2025-05-19T18:15:30.986074Z","iopub.status.idle":"2025-05-19T18:15:30.992274Z","shell.execute_reply.started":"2025-05-19T18:15:30.986052Z","shell.execute_reply":"2025-05-19T18:15:30.991506Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"Seq2Seq(\n  (encoder): EncoderRNN(\n    (embedding): Embedding(30, 128)\n    (rnn): GRU(128, 128, batch_first=True)\n  )\n  (decoder): DecoderRNN(\n    (embedding): Embedding(50, 128)\n    (dropout): Dropout(p=0.2, inplace=False)\n    (rnn): GRU(256, 128, batch_first=True)\n    (attention): Attention(\n      (Wa): Linear(in_features=256, out_features=128, bias=True)\n      (Ua): Linear(in_features=128, out_features=1, bias=False)\n    )\n    (out): Linear(in_features=256, out_features=50, bias=True)\n  )\n)"},"metadata":{}}],"execution_count":29},{"cell_type":"code","source":"# Train and evaluate\ntest_accuracy = train_model(\n    model, train_loader, val_loader, test_loader,\n    num_epochs=5, beam_width=best_params['beam_width']\n)\n\n# Log test accuracy to WandB\nwandb.log({\"test_accuracy\": test_accuracy})\nwandb.finish()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T18:15:46.872261Z","iopub.execute_input":"2025-05-19T18:15:46.872560Z","iopub.status.idle":"2025-05-19T18:27:53.148925Z","shell.execute_reply.started":"2025-05-19T18:15:46.872541Z","shell.execute_reply":"2025-05-19T18:27:53.148375Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Epoch 1, Validation batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 15])\nEpoch 1, Train Loss: 0.7290, Val Loss: 0.0062, Val Accuracy: 0.5625\nEpoch 2, Validation batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 15])\nEpoch 2, Train Loss: 0.4081, Val Loss: 0.0053, Val Accuracy: 0.5938\nEpoch 3, Validation batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 15])\nEpoch 3, Train Loss: 0.3601, Val Loss: 0.0051, Val Accuracy: 0.5938\nEpoch 4, Validation batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 15])\nEpoch 4, Train Loss: 0.3240, Val Loss: 0.0055, Val Accuracy: 0.6250\nEpoch 5, Validation batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 15])\nEpoch 5, Train Loss: 0.3000, Val Loss: 0.0049, Val Accuracy: 0.6250\nTest batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 15])\nTest batch - src shape: torch.Size([32, 23]), tgt shape: torch.Size([32, 19])\nTest batch - src shape: torch.Size([32, 15]), tgt shape: torch.Size([32, 15])\nTest batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 17])\nTest batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 17])\nTest batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 17])\nTest batch - src shape: torch.Size([32, 21]), tgt shape: torch.Size([32, 17])\nTest batch - src shape: torch.Size([32, 18]), tgt shape: torch.Size([32, 19])\nTest batch - src shape: torch.Size([32, 16]), tgt shape: torch.Size([32, 17])\nTest batch - src shape: torch.Size([32, 16]), tgt shape: torch.Size([32, 17])\nTest batch - src shape: torch.Size([32, 17]), tgt shape: torch.Size([32, 14])\nTest batch - src shape: torch.Size([32, 17]), tgt shape: torch.Size([32, 12])\nTest batch - src shape: torch.Size([32, 18]), tgt shape: torch.Size([32, 14])\nTest batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 15])\nTest batch - src shape: torch.Size([32, 18]), tgt shape: torch.Size([32, 15])\nTest batch - src shape: torch.Size([32, 18]), tgt shape: torch.Size([32, 15])\nTest batch - src shape: torch.Size([32, 18]), tgt shape: torch.Size([32, 19])\nTest batch - src shape: torch.Size([32, 17]), tgt shape: torch.Size([32, 16])\nTest batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 19])\nTest batch - src shape: torch.Size([32, 16]), tgt shape: torch.Size([32, 13])\nTest batch - src shape: torch.Size([32, 21]), tgt shape: torch.Size([32, 16])\nTest batch - src shape: torch.Size([32, 22]), tgt shape: torch.Size([32, 19])\nTest batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 17])\nTest batch - src shape: torch.Size([32, 14]), tgt shape: torch.Size([32, 13])\nTest batch - src shape: torch.Size([32, 16]), tgt shape: torch.Size([32, 14])\nTest batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 17])\nTest batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 14])\nTest batch - src shape: torch.Size([32, 14]), tgt shape: torch.Size([32, 13])\nTest batch - src shape: torch.Size([32, 15]), tgt shape: torch.Size([32, 14])\nTest batch - src shape: torch.Size([32, 14]), tgt shape: torch.Size([32, 13])\nTest batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 18])\nTest batch - src shape: torch.Size([32, 17]), tgt shape: torch.Size([32, 18])\nTest batch - src shape: torch.Size([32, 14]), tgt shape: torch.Size([32, 14])\nTest batch - src shape: torch.Size([32, 18]), tgt shape: torch.Size([32, 17])\nTest batch - src shape: torch.Size([32, 17]), tgt shape: torch.Size([32, 18])\nTest batch - src shape: torch.Size([32, 14]), tgt shape: torch.Size([32, 15])\nTest batch - src shape: torch.Size([32, 17]), tgt shape: torch.Size([32, 16])\nTest batch - src shape: torch.Size([32, 18]), tgt shape: torch.Size([32, 16])\nTest batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 14])\nTest batch - src shape: torch.Size([32, 18]), tgt shape: torch.Size([32, 17])\nTest batch - src shape: torch.Size([32, 18]), tgt shape: torch.Size([32, 17])\nTest batch - src shape: torch.Size([32, 16]), tgt shape: torch.Size([32, 15])\nTest batch - src shape: torch.Size([32, 22]), tgt shape: torch.Size([32, 19])\nTest batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 18])\nTest batch - src shape: torch.Size([32, 21]), tgt shape: torch.Size([32, 20])\nTest batch - src shape: torch.Size([32, 21]), tgt shape: torch.Size([32, 18])\nTest batch - src shape: torch.Size([32, 15]), tgt shape: torch.Size([32, 13])\nTest batch - src shape: torch.Size([32, 17]), tgt shape: torch.Size([32, 17])\nTest batch - src shape: torch.Size([32, 22]), tgt shape: torch.Size([32, 21])\nTest batch - src shape: torch.Size([32, 15]), tgt shape: torch.Size([32, 15])\nTest batch - src shape: torch.Size([32, 17]), tgt shape: torch.Size([32, 14])\nTest batch - src shape: torch.Size([32, 21]), tgt shape: torch.Size([32, 16])\nTest batch - src shape: torch.Size([32, 15]), tgt shape: torch.Size([32, 15])\nTest batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 17])\nTest batch - src shape: torch.Size([32, 18]), tgt shape: torch.Size([32, 15])\nTest batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 16])\nTest batch - src shape: torch.Size([32, 13]), tgt shape: torch.Size([32, 12])\nTest batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 17])\nTest batch - src shape: torch.Size([32, 16]), tgt shape: torch.Size([32, 15])\nTest batch - src shape: torch.Size([32, 13]), tgt shape: torch.Size([32, 12])\nTest batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 15])\nTest batch - src shape: torch.Size([32, 14]), tgt shape: torch.Size([32, 13])\nTest batch - src shape: torch.Size([32, 13]), tgt shape: torch.Size([32, 11])\nTest batch - src shape: torch.Size([32, 17]), tgt shape: torch.Size([32, 16])\nTest batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 20])\nTest batch - src shape: torch.Size([32, 13]), tgt shape: torch.Size([32, 12])\nTest batch - src shape: torch.Size([32, 14]), tgt shape: torch.Size([32, 14])\nTest batch - src shape: torch.Size([32, 10]), tgt shape: torch.Size([32, 11])\nTest batch - src shape: torch.Size([32, 15]), tgt shape: torch.Size([32, 15])\nTest batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 20])\nTest batch - src shape: torch.Size([32, 14]), tgt shape: torch.Size([32, 15])\nTest batch - src shape: torch.Size([32, 16]), tgt shape: torch.Size([32, 15])\nTest batch - src shape: torch.Size([32, 9]), tgt shape: torch.Size([32, 8])\nTest batch - src shape: torch.Size([32, 15]), tgt shape: torch.Size([32, 13])\nTest batch - src shape: torch.Size([32, 11]), tgt shape: torch.Size([32, 10])\nTest batch - src shape: torch.Size([32, 12]), tgt shape: torch.Size([32, 10])\nTest batch - src shape: torch.Size([32, 15]), tgt shape: torch.Size([32, 13])\nTest batch - src shape: torch.Size([32, 17]), tgt shape: torch.Size([32, 15])\nTest batch - src shape: torch.Size([32, 16]), tgt shape: torch.Size([32, 14])\nTest batch - src shape: torch.Size([32, 14]), tgt shape: torch.Size([32, 14])\nTest batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 13])\nTest batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 18])\nTest batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 20])\nTest batch - src shape: torch.Size([32, 17]), tgt shape: torch.Size([32, 13])\nTest batch - src shape: torch.Size([32, 12]), tgt shape: torch.Size([32, 12])\nTest batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 18])\nTest batch - src shape: torch.Size([32, 16]), tgt shape: torch.Size([32, 16])\nTest batch - src shape: torch.Size([32, 15]), tgt shape: torch.Size([32, 13])\nTest batch - src shape: torch.Size([32, 14]), tgt shape: torch.Size([32, 13])\nTest batch - src shape: torch.Size([32, 14]), tgt shape: torch.Size([32, 10])\nTest batch - src shape: torch.Size([32, 16]), tgt shape: torch.Size([32, 13])\nTest batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 18])\nTest batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 18])\nTest batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 17])\nTest batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 18])\nTest batch - src shape: torch.Size([32, 22]), tgt shape: torch.Size([32, 19])\nTest batch - src shape: torch.Size([32, 18]), tgt shape: torch.Size([32, 16])\nTest batch - src shape: torch.Size([32, 16]), tgt shape: torch.Size([32, 17])\nTest batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 19])\nTest batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 20])\nTest batch - src shape: torch.Size([32, 22]), tgt shape: torch.Size([32, 14])\nTest batch - src shape: torch.Size([32, 14]), tgt shape: torch.Size([32, 14])\nTest batch - src shape: torch.Size([32, 14]), tgt shape: torch.Size([32, 13])\nTest batch - src shape: torch.Size([32, 16]), tgt shape: torch.Size([32, 15])\nTest batch - src shape: torch.Size([32, 17]), tgt shape: torch.Size([32, 14])\nTest batch - src shape: torch.Size([32, 13]), tgt shape: torch.Size([32, 10])\nTest batch - src shape: torch.Size([32, 9]), tgt shape: torch.Size([32, 10])\nTest batch - src shape: torch.Size([32, 11]), tgt shape: torch.Size([32, 10])\nTest batch - src shape: torch.Size([32, 9]), tgt shape: torch.Size([32, 10])\nTest batch - src shape: torch.Size([32, 10]), tgt shape: torch.Size([32, 11])\nTest batch - src shape: torch.Size([32, 13]), tgt shape: torch.Size([32, 13])\nTest batch - src shape: torch.Size([32, 16]), tgt shape: torch.Size([32, 14])\nTest batch - src shape: torch.Size([32, 21]), tgt shape: torch.Size([32, 18])\nTest batch - src shape: torch.Size([32, 21]), tgt shape: torch.Size([32, 17])\nTest batch - src shape: torch.Size([32, 25]), tgt shape: torch.Size([32, 19])\nTest batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 15])\nTest batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 13])\nTest batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 17])\nTest batch - src shape: torch.Size([32, 17]), tgt shape: torch.Size([32, 13])\nTest batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 15])\nTest batch - src shape: torch.Size([32, 17]), tgt shape: torch.Size([32, 14])\nTest batch - src shape: torch.Size([32, 21]), tgt shape: torch.Size([32, 19])\nTest batch - src shape: torch.Size([32, 24]), tgt shape: torch.Size([32, 23])\nTest batch - src shape: torch.Size([32, 21]), tgt shape: torch.Size([32, 19])\nTest batch - src shape: torch.Size([32, 16]), tgt shape: torch.Size([32, 15])\nTest batch - src shape: torch.Size([32, 17]), tgt shape: torch.Size([32, 16])\nTest batch - src shape: torch.Size([32, 17]), tgt shape: torch.Size([32, 18])\nTest batch - src shape: torch.Size([32, 16]), tgt shape: torch.Size([32, 14])\nTest batch - src shape: torch.Size([32, 18]), tgt shape: torch.Size([32, 16])\nTest batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 16])\nTest batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 16])\nTest batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 15])\nTest batch - src shape: torch.Size([32, 14]), tgt shape: torch.Size([32, 13])\nTest batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 15])\nTest batch - src shape: torch.Size([32, 22]), tgt shape: torch.Size([32, 17])\nTest batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 17])\nTest batch - src shape: torch.Size([32, 15]), tgt shape: torch.Size([32, 15])\nTest batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 19])\nTest batch - src shape: torch.Size([32, 17]), tgt shape: torch.Size([32, 15])\nTest batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 14])\nTest batch - src shape: torch.Size([32, 21]), tgt shape: torch.Size([32, 17])\nTest batch - src shape: torch.Size([32, 14]), tgt shape: torch.Size([32, 14])\nTest batch - src shape: torch.Size([32, 21]), tgt shape: torch.Size([32, 17])\nTest batch - src shape: torch.Size([32, 17]), tgt shape: torch.Size([32, 17])\nTest batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 16])\nTest batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 12])\nTest batch - src shape: torch.Size([32, 16]), tgt shape: torch.Size([32, 15])\nTest batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 19])\nTest batch - src shape: torch.Size([32, 22]), tgt shape: torch.Size([32, 18])\nTest batch - src shape: torch.Size([32, 18]), tgt shape: torch.Size([32, 14])\nTest batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 16])\nTest batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 16])\nTest batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 19])\nTest batch - src shape: torch.Size([32, 14]), tgt shape: torch.Size([32, 11])\nTest batch - src shape: torch.Size([32, 18]), tgt shape: torch.Size([32, 15])\nTest batch - src shape: torch.Size([32, 16]), tgt shape: torch.Size([32, 16])\nTest batch - src shape: torch.Size([32, 21]), tgt shape: torch.Size([32, 13])\nTest batch - src shape: torch.Size([32, 15]), tgt shape: torch.Size([32, 12])\nTest batch - src shape: torch.Size([32, 17]), tgt shape: torch.Size([32, 15])\nTest batch - src shape: torch.Size([32, 18]), tgt shape: torch.Size([32, 16])\nTest batch - src shape: torch.Size([32, 17]), tgt shape: torch.Size([32, 16])\nTest batch - src shape: torch.Size([32, 17]), tgt shape: torch.Size([32, 15])\nTest batch - src shape: torch.Size([32, 18]), tgt shape: torch.Size([32, 16])\nTest batch - src shape: torch.Size([32, 16]), tgt shape: torch.Size([32, 16])\nTest batch - src shape: torch.Size([32, 14]), tgt shape: torch.Size([32, 14])\nTest batch - src shape: torch.Size([32, 17]), tgt shape: torch.Size([32, 14])\nTest batch - src shape: torch.Size([32, 23]), tgt shape: torch.Size([32, 17])\nTest batch - src shape: torch.Size([32, 17]), tgt shape: torch.Size([32, 15])\nTest batch - src shape: torch.Size([32, 23]), tgt shape: torch.Size([32, 24])\nTest batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 15])\nTest batch - src shape: torch.Size([32, 18]), tgt shape: torch.Size([32, 16])\nTest batch - src shape: torch.Size([32, 18]), tgt shape: torch.Size([32, 17])\nTest batch - src shape: torch.Size([32, 13]), tgt shape: torch.Size([32, 9])\nTest batch - src shape: torch.Size([32, 15]), tgt shape: torch.Size([32, 12])\nTest batch - src shape: torch.Size([32, 18]), tgt shape: torch.Size([32, 16])\nTest batch - src shape: torch.Size([32, 18]), tgt shape: torch.Size([32, 13])\nTest batch - src shape: torch.Size([32, 23]), tgt shape: torch.Size([32, 18])\nTest batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 16])\nTest batch - src shape: torch.Size([32, 22]), tgt shape: torch.Size([32, 17])\nTest batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 18])\nTest batch - src shape: torch.Size([32, 16]), tgt shape: torch.Size([32, 14])\nTest batch - src shape: torch.Size([32, 22]), tgt shape: torch.Size([32, 18])\nTest batch - src shape: torch.Size([32, 18]), tgt shape: torch.Size([32, 14])\nTest batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 17])\nTest batch - src shape: torch.Size([32, 16]), tgt shape: torch.Size([32, 13])\nTest batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 16])\nTest batch - src shape: torch.Size([32, 21]), tgt shape: torch.Size([32, 18])\nTest batch - src shape: torch.Size([32, 16]), tgt shape: torch.Size([32, 15])\nTest batch - src shape: torch.Size([32, 13]), tgt shape: torch.Size([32, 14])\nTest batch - src shape: torch.Size([32, 15]), tgt shape: torch.Size([32, 12])\nTest batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 15])\nTest batch - src shape: torch.Size([32, 14]), tgt shape: torch.Size([32, 12])\nTest batch - src shape: torch.Size([32, 11]), tgt shape: torch.Size([32, 9])\nTest batch - src shape: torch.Size([32, 13]), tgt shape: torch.Size([32, 13])\nTest batch - src shape: torch.Size([32, 13]), tgt shape: torch.Size([32, 11])\nTest batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 15])\nTest batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 15])\nTest batch - src shape: torch.Size([32, 15]), tgt shape: torch.Size([32, 13])\nTest batch - src shape: torch.Size([32, 21]), tgt shape: torch.Size([32, 15])\nTest batch - src shape: torch.Size([32, 21]), tgt shape: torch.Size([32, 17])\nTest batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 15])\nTest batch - src shape: torch.Size([32, 14]), tgt shape: torch.Size([32, 13])\nTest batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 16])\nTest batch - src shape: torch.Size([32, 21]), tgt shape: torch.Size([32, 17])\nTest batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 19])\nTest batch - src shape: torch.Size([32, 13]), tgt shape: torch.Size([32, 13])\nTest batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 17])\nTest batch - src shape: torch.Size([32, 24]), tgt shape: torch.Size([32, 20])\nTest batch - src shape: torch.Size([32, 18]), tgt shape: torch.Size([32, 15])\nTest batch - src shape: torch.Size([32, 20]), tgt shape: torch.Size([32, 16])\nTest batch - src shape: torch.Size([32, 17]), tgt shape: torch.Size([32, 17])\nTest batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 16])\nTest batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 16])\nTest batch - src shape: torch.Size([32, 19]), tgt shape: torch.Size([32, 16])\nTest batch - src shape: torch.Size([16, 9]), tgt shape: torch.Size([16, 8])\nTest Accuracy: 0.5421\nTest predictions saved to 'test_predictions.csv'\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▃▅▆█</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>train_loss</td><td>█▃▂▁▁</td></tr><tr><td>val_accuracy</td><td>▁▅▅██</td></tr><tr><td>val_loss</td><td>█▃▂▄▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>4</td></tr><tr><td>test_accuracy</td><td>0.5421</td></tr><tr><td>train_loss</td><td>0.30005</td></tr><tr><td>val_accuracy</td><td>0.625</td></tr><tr><td>val_loss</td><td>0.00494</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">final_model_training_with_attention_v2</strong> at: <a href='https://wandb.ai/da24m007-iit-madras/DL-A3/runs/xiabr9kk' target=\"_blank\">https://wandb.ai/da24m007-iit-madras/DL-A3/runs/xiabr9kk</a><br> View project at: <a href='https://wandb.ai/da24m007-iit-madras/DL-A3' target=\"_blank\">https://wandb.ai/da24m007-iit-madras/DL-A3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250519_181456-xiabr9kk/logs</code>"},"metadata":{}}],"execution_count":30},{"cell_type":"markdown","source":"## Attention heatmaps","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport torch\nimport numpy as np\nimport os\nfrom matplotlib import font_manager","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T18:37:05.604602Z","iopub.execute_input":"2025-05-19T18:37:05.604851Z","iopub.status.idle":"2025-05-19T18:37:05.609570Z","shell.execute_reply.started":"2025-05-19T18:37:05.604827Z","shell.execute_reply":"2025-05-19T18:37:05.608822Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"def inference_with_attention(model, src_tensor, src_vocab, tgt_vocab, max_len=50, device='cuda'):\n    \"\"\"\n    Perform inference on a single source sequence, collecting attention weights.\n    \n    Args:\n        model: Trained Seq2Seq model\n        src_tensor: Source tensor of shape (1, src_len)\n        src_vocab: Source vocabulary\n        tgt_vocab: Target vocabulary\n        max_len: Maximum length of the output sequence\n        device: Device to run the model on\n    \n    Returns:\n        predicted_tokens: List of predicted token indices\n        attention_weights: List of attention weight matrices for each decoding step\n    \"\"\"\n    model.eval()\n    src_tensor = src_tensor.to(device)\n    batch_size = 1\n    \n    with torch.no_grad():\n        # Encoder\n        encoder_outputs, hidden = model.encoder(src_tensor)\n        \n        # Initialize decoder input with <SOS>\n        decoder_input = torch.tensor([tgt_vocab.char2idx['<SOS>']], device=device)\n        predicted_tokens = []\n        attention_weights = []\n        \n        if model.decoder.cell_type == 'LSTM':\n            hidden = (hidden[0], hidden[1])\n        \n        for _ in range(max_len):\n            output, hidden, attn_weights = model.decoder(decoder_input, hidden, encoder_outputs)\n            attention_weights.append(attn_weights.squeeze(0).cpu().numpy())  # (seq_len,)\n            \n            # Get the predicted token\n            _, topi = output.topk(1)\n            decoder_input = topi.squeeze(-1).detach()  # (batch_size,)\n            predicted_token = decoder_input.item()\n            predicted_tokens.append(predicted_token)\n            \n            if predicted_token == tgt_vocab.char2idx['<EOS>']:\n                break\n                \n    return predicted_tokens, attention_weights","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T18:28:43.186358Z","iopub.execute_input":"2025-05-19T18:28:43.187255Z","iopub.status.idle":"2025-05-19T18:28:43.193214Z","shell.execute_reply.started":"2025-05-19T18:28:43.187229Z","shell.execute_reply":"2025-05-19T18:28:43.192572Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"def plot_attention_heatmaps(model, test_loader, src_vocab, tgt_vocab, device='cuda', num_samples=9):\n    \"\"\"\n    Plot a 3x3 grid of attention heatmaps for the specified number of test samples and log to WandB.\n    \n    Args:\n        model: Trained Seq2Seq model\n        test_loader: DataLoader for test data\n        src_vocab: Source vocabulary\n        tgt_vocab: Target vocabulary\n        device: Device to run the model on\n        num_samples: Number of samples to plot (default 9 for 3x3 grid)\n        project_name: WandB project name for initialization\n    \n    Returns:\n        None (saves the plot to a file and logs to WandB)\n    \"\"\"\n    \n    # Set up Tamil font\n    try:\n        # Check if Noto Sans Tamil is available\n        font_path = \"/usr/share/fonts/truetype/noto/NotoSansTamil-Regular.ttf\"  # Common path in Linux/Kaggle\n        eng_font_path = \"/usr/share/fonts/truetype/noto/NotoSans-Black.ttf\"\n        if os.path.exists(font_path):\n            font_manager.fontManager.addfont(font_path)\n            tamil_font = font_manager.FontProperties(fname=font_path)\n            plt.rcParams['font.family'] = tamil_font.get_name()\n        else:\n            # Fallback to a generic sans-serif font and warn about Tamil rendering\n            font_manager.fontManager.addfont(eng_font_path)\n            eng_font = font_manager.FontProperties(fname=eng_font_path)\n            plt.rcParams['font.family'] = eng_font.get_name()\n            print(\"Warning: Noto Sans Tamil font not found. Tamil characters may not render correctly.\")\n    except Exception as e:\n        print(f\"Error setting Tamil font: {e}. Tamil characters may not render correctly.\")\n        plt.rcParams['font.family'] = 'sans-serif'\n\n    model.eval()\n    samples = []\n    \n    # Collect samples from test_loader\n    for src, tgt in test_loader:\n        for i in range(src.size(0)):\n            samples.append((src[i:i+1], tgt[i:i+1]))\n            if len(samples) >= num_samples:\n                break\n        if len(samples) >= num_samples:\n            break\n    \n    # Set up the 3x3 grid\n    fig, axes = plt.subplots(3, 3, figsize=(15, 15))\n    axes = axes.flatten()\n    \n    for idx, (src_tensor, tgt_tensor) in enumerate(samples[:num_samples]):\n        # Run inference\n        predicted_tokens, attention_weights = inference_with_attention(\n            model, src_tensor, src_vocab, tgt_vocab, device=device\n        )\n        \n        # Convert source and target tokens to characters\n        src_chars = [src_vocab.idx2char[idx.item()] for idx in src_tensor[0] if idx.item() != src_vocab.char2idx['<PAD>']]\n        pred_chars = [tgt_vocab.idx2char[idx] for idx in predicted_tokens if idx != tgt_vocab.char2idx['<PAD>']]\n        \n        # Stack attention weights into a matrix (tgt_len, src_len)\n        attention_matrix = np.stack(attention_weights, axis=0)  # (tgt_len, src_len)\n        \n        # Plot heatmap\n        sns.heatmap(\n            attention_matrix,\n            ax=axes[idx],\n            xticklabels=src_chars,\n            yticklabels=pred_chars,\n            cmap='viridis',\n            cbar=False\n        )\n        axes[idx].set_title(f\"Sample {idx+1}\")\n        axes[idx].set_xlabel(\"Source Sequence\")\n        axes[idx].set_ylabel(\"Predicted Sequence\")\n    \n    plt.tight_layout()\n    plt.show()\n    \n    # Save the plot\n    plot_path = 'attention_heatmaps.png'\n    plt.savefig(plot_path, bbox_inches='tight')\n    \n    # Log the plot to WandB\n    try:\n        wandb.log({\"attention_heatmaps\": wandb.Image(plot_path)})\n        print(\"Attention heatmaps logged to WandB\")\n    except Exception as e:\n        print(f\"Failed to log to WandB: {e}\")\n    \n    plt.close()\n    \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T19:08:08.760713Z","iopub.execute_input":"2025-05-19T19:08:08.761422Z","iopub.status.idle":"2025-05-19T19:08:08.775163Z","shell.execute_reply.started":"2025-05-19T19:08:08.761381Z","shell.execute_reply":"2025-05-19T19:08:08.774374Z"}},"outputs":[],"execution_count":64},{"cell_type":"code","source":"#wandb.init(project=\"DL-A3\", name=\"Attention heatmap v2\")\nplot_attention_heatmaps(model, test_loader, src_vocab, tgt_vocab, device=device)\n#wandb.finish()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T19:08:11.983969Z","iopub.execute_input":"2025-05-19T19:08:11.984243Z","iopub.status.idle":"2025-05-19T19:08:14.557674Z","shell.execute_reply.started":"2025-05-19T19:08:11.984222Z","shell.execute_reply":"2025-05-19T19:08:14.556818Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 108 (l) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 112 (p) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 83 (S) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 79 (O) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 102 (f) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 97 (a) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 114 (r) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 109 (m) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 69 (E) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 80 (P) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 114 (r) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 101 (e) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 100 (d) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 105 (i) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 99 (c) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 116 (t) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 83 (S) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 113 (q) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 117 (u) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 110 (n) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 108 (l) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 112 (p) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 97 (a) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 109 (m) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 79 (O) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 102 (f) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 69 (E) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 111 (o) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 83 (S) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 79 (O) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 102 (f) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 97 (a) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 114 (r) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 109 (m) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 69 (E) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 111 (o) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 117 (u) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 99 (c) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 101 (e) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 113 (q) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 110 (n) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 80 (P) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 100 (d) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 105 (i) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 116 (t) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 112 (p) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 108 (l) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 83 (S) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 79 (O) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 102 (f) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 97 (a) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 114 (r) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 109 (m) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 69 (E) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 111 (o) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 117 (u) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 99 (c) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 101 (e) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 113 (q) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 110 (n) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 80 (P) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 100 (d) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 105 (i) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 116 (t) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 112 (p) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 108 (l) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 104 (h) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 83 (S) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 79 (O) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 102 (f) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 97 (a) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 114 (r) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 109 (m) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 69 (E) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 111 (o) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 117 (u) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 99 (c) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 101 (e) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 113 (q) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 110 (n) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 80 (P) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 100 (d) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 105 (i) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 116 (t) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 112 (p) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 108 (l) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 104 (h) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 83 (S) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 79 (O) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 102 (f) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 97 (a) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 114 (r) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 109 (m) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 69 (E) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 111 (o) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 117 (u) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 99 (c) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 101 (e) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 113 (q) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 110 (n) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 80 (P) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 100 (d) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 105 (i) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 116 (t) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 112 (p) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 108 (l) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 104 (h) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 115 (s) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 83 (S) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 79 (O) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 102 (f) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 97 (a) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 114 (r) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 109 (m) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 69 (E) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 111 (o) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 117 (u) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 99 (c) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 101 (e) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 113 (q) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 110 (n) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 80 (P) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 100 (d) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 105 (i) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 116 (t) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 112 (p) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 108 (l) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 104 (h) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 115 (s) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 83 (S) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 79 (O) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 102 (f) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 97 (a) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 114 (r) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 109 (m) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 69 (E) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 111 (o) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 117 (u) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 99 (c) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 101 (e) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 113 (q) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 110 (n) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 80 (P) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 100 (d) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 105 (i) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 116 (t) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 112 (p) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 108 (l) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 104 (h) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 115 (s) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 83 (S) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 79 (O) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 102 (f) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 97 (a) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 114 (r) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 109 (m) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 69 (E) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 111 (o) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 117 (u) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 99 (c) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 101 (e) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 113 (q) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 110 (n) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 80 (P) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 100 (d) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 105 (i) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 116 (t) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 112 (p) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 108 (l) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 104 (h) missing from current font.\n  fig.canvas.draw()\n/usr/local/lib/python3.11/dist-packages/seaborn/utils.py:80: UserWarning: Glyph 115 (s) missing from current font.\n  fig.canvas.draw()\n/tmp/ipykernel_35/1229350593.py:79: UserWarning: Glyph 83 (S) missing from current font.\n  plt.tight_layout()\n/tmp/ipykernel_35/1229350593.py:79: UserWarning: Glyph 97 (a) missing from current font.\n  plt.tight_layout()\n/tmp/ipykernel_35/1229350593.py:79: UserWarning: Glyph 109 (m) missing from current font.\n  plt.tight_layout()\n/tmp/ipykernel_35/1229350593.py:79: UserWarning: Glyph 112 (p) missing from current font.\n  plt.tight_layout()\n/tmp/ipykernel_35/1229350593.py:79: UserWarning: Glyph 108 (l) missing from current font.\n  plt.tight_layout()\n/tmp/ipykernel_35/1229350593.py:79: UserWarning: Glyph 101 (e) missing from current font.\n  plt.tight_layout()\n/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 108 (l) missing from current font.\n  fig.canvas.print_figure(bytes_io, **kw)\n/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 112 (p) missing from current font.\n  fig.canvas.print_figure(bytes_io, **kw)\n/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 69 (E) missing from current font.\n  fig.canvas.print_figure(bytes_io, **kw)\n/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 79 (O) missing from current font.\n  fig.canvas.print_figure(bytes_io, **kw)\n/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 83 (S) missing from current font.\n  fig.canvas.print_figure(bytes_io, **kw)\n/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 80 (P) missing from current font.\n  fig.canvas.print_figure(bytes_io, **kw)\n/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 114 (r) missing from current font.\n  fig.canvas.print_figure(bytes_io, **kw)\n/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 101 (e) missing from current font.\n  fig.canvas.print_figure(bytes_io, **kw)\n/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 100 (d) missing from current font.\n  fig.canvas.print_figure(bytes_io, **kw)\n/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 105 (i) missing from current font.\n  fig.canvas.print_figure(bytes_io, **kw)\n/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 99 (c) missing from current font.\n  fig.canvas.print_figure(bytes_io, **kw)\n/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 116 (t) missing from current font.\n  fig.canvas.print_figure(bytes_io, **kw)\n/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 113 (q) missing from current font.\n  fig.canvas.print_figure(bytes_io, **kw)\n/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 117 (u) missing from current font.\n  fig.canvas.print_figure(bytes_io, **kw)\n/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 110 (n) missing from current font.\n  fig.canvas.print_figure(bytes_io, **kw)\n/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 97 (a) missing from current font.\n  fig.canvas.print_figure(bytes_io, **kw)\n/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 109 (m) missing from current font.\n  fig.canvas.print_figure(bytes_io, **kw)\n/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 102 (f) missing from current font.\n  fig.canvas.print_figure(bytes_io, **kw)\n/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 111 (o) missing from current font.\n  fig.canvas.print_figure(bytes_io, **kw)\n/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 104 (h) missing from current font.\n  fig.canvas.print_figure(bytes_io, **kw)\n/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 115 (s) missing from current font.\n  fig.canvas.print_figure(bytes_io, **kw)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1500x1500 with 9 Axes>","image/png":"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\n"},"metadata":{}},{"name":"stdout","text":"Failed to log to WandB: You must call wandb.init() before wandb.log()\n","output_type":"stream"}],"execution_count":65},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}